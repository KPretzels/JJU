{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2e46434a",
   "metadata": {
    "id": "2e46434a"
   },
   "source": [
    "# OpenAIEmbeddings\n",
    "\n",
    "문서 임베딩은 문서의 내용을 수치적인 벡터로 변환하는 과정입니다.\n",
    "\n",
    "이 과정을 통해 문서의 의미를 수치화하고, 다양한 자연어 처리 작업에 활용할 수 있습니다. 대표적인 사전 학습된 언어 모델로는 BERT와 GPT가 있으며, 이러한 모델들은 문맥적 정보를 포착하여 문서의 의미를 인코딩합니다.\n",
    "\n",
    "문서 임베딩은 토큰화된 문서를 모델에 입력하여 임베딩 벡터를 생성하고, 이를 평균하여 전체 문서의 벡터를 생성합니다. 이 벡터는 문서 분류, 감성 분석, 문서 간 유사도 계산 등에 활용될 수 있습니다.\n",
    "\n",
    "[더 알아보기](https://platform.openai.com/docs/guides/embeddings/embedding-models)\n",
    "\n",
    "https://github.com/Atipico1/Kor-IR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8748488",
   "metadata": {
    "id": "d8748488"
   },
   "source": [
    "## 설정\n",
    "\n",
    "먼저 langchain-openai를 설치하고 필요한 환경 변수를 설정합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36b37773",
   "metadata": {
    "id": "36b37773"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"\"\n",
    "\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = \"\"\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_ENDPOINT\"] = \"https://api.smith.langchain.com\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"08-01\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ce3fe79",
   "metadata": {
    "id": "3ce3fe79"
   },
   "source": [
    "지원되는 모델 목록\n",
    "\n",
    "| MODEL                  | PAGES PER DOLLAR | PERFORMANCE ON MTEB EVAL | MAX INPUT |\n",
    "|------------------------|------------------|---------------------------|-----------|\n",
    "| text-embedding-3-small | 62,500           | 62.3%                     | 8191      |\n",
    "| text-embedding-3-large | 9,615            | 64.6%                     | 8191      |\n",
    "| text-embedding-ada-002 | 12,500           | 61.0%                     | 8191      |\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "yLbOVZ98dYeb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6271,
     "status": "ok",
     "timestamp": 1737070327816,
     "user": {
      "displayName": "Chang Jun Lee",
      "userId": "07449846774346066151"
     },
     "user_tz": -540
    },
    "id": "yLbOVZ98dYeb",
    "outputId": "057a56be-9490-48b2-bf12-69e011a45281"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain-openai\n",
      "  Downloading langchain_openai-0.3.0-py3-none-any.whl.metadata (2.7 kB)\n",
      "Requirement already satisfied: langchain-core<0.4.0,>=0.3.29 in /usr/local/lib/python3.11/dist-packages (from langchain-openai) (0.3.29)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.58.1 in /usr/local/lib/python3.11/dist-packages (from langchain-openai) (1.59.6)\n",
      "Collecting tiktoken<1,>=0.7 (from langchain-openai)\n",
      "  Downloading tiktoken-0.8.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.29->langchain-openai) (6.0.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.29->langchain-openai) (1.33)\n",
      "Requirement already satisfied: langsmith<0.3,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.29->langchain-openai) (0.2.10)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.29->langchain-openai) (24.2)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.5.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.29->langchain-openai) (2.10.5)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.29->langchain-openai) (9.0.0)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.29->langchain-openai) (4.12.2)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.58.1->langchain-openai) (3.7.1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.58.1->langchain-openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.58.1->langchain-openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.58.1->langchain-openai) (0.8.2)\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.58.1->langchain-openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.58.1->langchain-openai) (4.67.1)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken<1,>=0.7->langchain-openai) (2024.11.6)\n",
      "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from tiktoken<1,>=0.7->langchain-openai) (2.32.3)\n",
      "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.58.1->langchain-openai) (3.10)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.58.1->langchain-openai) (2024.12.14)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.58.1->langchain-openai) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.58.1->langchain-openai) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.29->langchain-openai) (3.0.0)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.3,>=0.1.125->langchain-core<0.4.0,>=0.3.29->langchain-openai) (3.10.14)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.3,>=0.1.125->langchain-core<0.4.0,>=0.3.29->langchain-openai) (1.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4.0,>=0.3.29->langchain-openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4.0,>=0.3.29->langchain-openai) (2.27.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain-openai) (3.4.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain-openai) (2.3.0)\n",
      "Downloading langchain_openai-0.3.0-py3-none-any.whl (54 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.2/54.2 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tiktoken-0.8.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: tiktoken, langchain-openai\n",
      "Successfully installed langchain-openai-0.3.0 tiktoken-0.8.0\n"
     ]
    }
   ],
   "source": [
    "!pip install -qU langchain-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23453c6a",
   "metadata": {
    "id": "23453c6a"
   },
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "# OpenAI의 \"text-embedding-3-small\" 모델을 사용하여 임베딩을 생성합니다.\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00541ca6",
   "metadata": {
    "id": "00541ca6"
   },
   "outputs": [],
   "source": [
    "text = \"임베딩 테스트를 하기 위한 샘플 문장입니다.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "758fbebb",
   "metadata": {
    "id": "758fbebb"
   },
   "source": [
    "## 쿼리 임베딩\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "brpNA92Vz3yM",
   "metadata": {
    "id": "brpNA92Vz3yM"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "08285a94",
   "metadata": {
    "id": "08285a94"
   },
   "source": [
    "`embeddings.embed_query(text)`는 주어진 텍스트를 임베딩 벡터로 변환하는 함수입니다.\n",
    "\n",
    "이 함수는 텍스트를 벡터 공간에 매핑하여 의미적으로 유사한 텍스트를 찾거나 텍스트 간의 유사도를 계산하는 데 사용될 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "973c5ca7",
   "metadata": {
    "id": "973c5ca7"
   },
   "outputs": [],
   "source": [
    "# 텍스트를 임베딩하여 쿼리 결과를 생성합니다.\n",
    "query_result = embeddings.embed_query(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9c80557",
   "metadata": {
    "id": "a9c80557"
   },
   "source": [
    "`query_result[:5]`는 `query_result` 리스트의 처음 5개 요소를 슬라이싱(slicing)하여 선택합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "zjysBOBoe8B7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 403,
     "status": "ok",
     "timestamp": 1737070732809,
     "user": {
      "displayName": "Chang Jun Lee",
      "userId": "07449846774346066151"
     },
     "user_tz": -540
    },
    "id": "zjysBOBoe8B7",
    "outputId": "5c1225ed-11a8-43e0-ff37-923eaff126bc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1536"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(query_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3af37ee3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 569,
     "status": "ok",
     "timestamp": 1737070394380,
     "user": {
      "displayName": "Chang Jun Lee",
      "userId": "07449846774346066151"
     },
     "user_tz": -540
    },
    "id": "3af37ee3",
    "outputId": "e8dbe3a1-ad5f-4918-ec58-2d6de46eaaec"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.00776276458054781,\n",
       " 0.03680367395281792,\n",
       " 0.019545823335647583,\n",
       " -0.0196656696498394,\n",
       " 0.017203375697135925]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 쿼리 결과의 처음 5개 항목을 선택합니다.\n",
    "query_result[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f93f8fbc",
   "metadata": {
    "id": "f93f8fbc"
   },
   "source": [
    "## Document 임베딩\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "766fcf40",
   "metadata": {
    "id": "766fcf40"
   },
   "source": [
    "`embeddings.embed_documents()` 함수를 사용하여 텍스트 문서를 임베딩합니다.\n",
    "\n",
    "- `[text]`를 인자로 전달하여 단일 문서를 리스트 형태로 임베딩 함수에 전달합니다.\n",
    "- 함수 호출 결과로 반환된 임베딩 벡터를 `doc_result` 변수에 할당합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3f5d387",
   "metadata": {
    "id": "e3f5d387"
   },
   "outputs": [],
   "source": [
    "doc_result = embeddings.embed_documents(\n",
    "    [text, text, text, text]\n",
    ")  # 텍스트를 임베딩하여 문서 벡터를 생성합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aafdee91",
   "metadata": {
    "id": "aafdee91"
   },
   "source": [
    "`doc_result[0][:5]`는 `doc_result` 리스트의 첫 번째 요소에서 처음 5개의 문자를 슬라이싱하여 선택합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c13b154",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 402,
     "status": "ok",
     "timestamp": 1737070753348,
     "user": {
      "displayName": "Chang Jun Lee",
      "userId": "07449846774346066151"
     },
     "user_tz": -540
    },
    "id": "6c13b154",
    "outputId": "7f5475dd-67db-439a-ae8a-bc3d47695817"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(doc_result)  # 문서 벡터의 길이를 확인합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7565438",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 537,
     "status": "ok",
     "timestamp": 1737070773307,
     "user": {
      "displayName": "Chang Jun Lee",
      "userId": "07449846774346066151"
     },
     "user_tz": -540
    },
    "id": "d7565438",
    "outputId": "5838abae-aa85-4f00-b8f6-3fabafe6c6c8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.007760151289403439,\n",
       " 0.036729928106069565,\n",
       " 0.019531168043613434,\n",
       " -0.019727351143956184,\n",
       " 0.01720966212451458]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 문서 결과의 첫 번째 요소에서 처음 5개 항목을 선택합니다.\n",
    "doc_result[0][:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d79f47ff",
   "metadata": {
    "id": "d79f47ff"
   },
   "source": [
    "## 차원 지정\n",
    "\n",
    "`text-embedding-3` 모델 클래스를 사용하면 반환되는 임베딩의 크기를 지정할 수 있습니다.\n",
    "\n",
    "예를 들어, 기본적으로 `text-embedding-3-small`는 1536 차원의 임베딩을 반환합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb82bb0f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 572,
     "status": "ok",
     "timestamp": 1737070781039,
     "user": {
      "displayName": "Chang Jun Lee",
      "userId": "07449846774346066151"
     },
     "user_tz": -540
    },
    "id": "bb82bb0f",
    "outputId": "547faf89-9110-4efb-e226-cc1e38377810"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1536"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 문서 결과의 첫 번째 요소의 길이를 반환합니다.\n",
    "len(doc_result[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d60da32",
   "metadata": {
    "id": "4d60da32"
   },
   "source": [
    "### 차원(dimensions) 조정\n",
    "\n",
    "하지만 `dimensions=1024`를 전달함으로써 임베딩의 크기를 1024로 줄일 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdfa8cb2",
   "metadata": {
    "id": "fdfa8cb2"
   },
   "outputs": [],
   "source": [
    "# OpenAI의 \"text-embedding-3-small\" 모델을 사용하여 1024차원의 임베딩을 생성하는 객체를 초기화합니다.\n",
    "embeddings_1024 = OpenAIEmbeddings(model=\"text-embedding-3-small\", dimensions=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3fbcdaa",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1930,
     "status": "ok",
     "timestamp": 1737070795084,
     "user": {
      "displayName": "Chang Jun Lee",
      "userId": "07449846774346066151"
     },
     "user_tz": -540
    },
    "id": "e3fbcdaa",
    "outputId": "edb984e7-e9b6-4e07-a748-8891a60d86c9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1024"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 주어진 텍스트를 임베딩하고 첫 번째 임베딩 벡터의 길이를 반환합니다.\n",
    "len(embeddings_1024.embed_documents([text])[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66a8ca34",
   "metadata": {
    "id": "66a8ca34"
   },
   "source": [
    "## 유사도 계산\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dddbb423",
   "metadata": {
    "id": "dddbb423"
   },
   "outputs": [],
   "source": [
    "sentence1 = \"안녕하세요? 반갑습니다.\"\n",
    "sentence2 = \"안녕하세요? 반갑습니다!\"\n",
    "sentence3 = \"안녕하세요? 만나서 반가워요.\"\n",
    "sentence4 = \"Hi, nice to meet you.\"\n",
    "sentence5 = \"I like to eat apples.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8662aafb",
   "metadata": {
    "id": "8662aafb"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "sentences = [sentence1, sentence2, sentence3, sentence4, sentence5]\n",
    "embedded_sentences = embeddings_1024.embed_documents(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nGvKEZX7fWwH",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 413,
     "status": "ok",
     "timestamp": 1737070864404,
     "user": {
      "displayName": "Chang Jun Lee",
      "userId": "07449846774346066151"
     },
     "user_tz": -540
    },
    "id": "nGvKEZX7fWwH",
    "outputId": "883049ed-3d74-450d-f6ca-d7f034f34de5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1024"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(embedded_sentences[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d9e24a4",
   "metadata": {
    "id": "5d9e24a4"
   },
   "outputs": [],
   "source": [
    "def similarity(a, b):\n",
    "    return cosine_similarity([a], [b])[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58fbf371",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 410,
     "status": "ok",
     "timestamp": 1737070900545,
     "user": {
      "displayName": "Chang Jun Lee",
      "userId": "07449846774346066151"
     },
     "user_tz": -540
    },
    "id": "58fbf371",
    "outputId": "f24a6511-5939-47e7-d77a-824eb685e3a1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[유사도 0.9644] 안녕하세요? 반갑습니다. \t <=====> \t 안녕하세요? 반갑습니다!\n",
      "[유사도 0.8376] 안녕하세요? 반갑습니다. \t <=====> \t 안녕하세요? 만나서 반가워요.\n",
      "[유사도 0.5042] 안녕하세요? 반갑습니다. \t <=====> \t Hi, nice to meet you.\n",
      "[유사도 0.1362] 안녕하세요? 반갑습니다. \t <=====> \t I like to eat apples.\n",
      "[유사도 0.8142] 안녕하세요? 반갑습니다! \t <=====> \t 안녕하세요? 만나서 반가워요.\n",
      "[유사도 0.4790] 안녕하세요? 반갑습니다! \t <=====> \t Hi, nice to meet you.\n",
      "[유사도 0.1318] 안녕하세요? 반갑습니다! \t <=====> \t I like to eat apples.\n",
      "[유사도 0.5128] 안녕하세요? 만나서 반가워요. \t <=====> \t Hi, nice to meet you.\n",
      "[유사도 0.1409] 안녕하세요? 만나서 반가워요. \t <=====> \t I like to eat apples.\n",
      "[유사도 0.2249] Hi, nice to meet you. \t <=====> \t I like to eat apples.\n"
     ]
    }
   ],
   "source": [
    "# sentence1 = \"안녕하세요? 반갑습니다.\"\n",
    "# sentence2 = \"안녕하세요? 만나서 반가워요.\"\n",
    "# sentence3 = \"Hi, nice to meet you.\"\n",
    "# sentence4 = \"I like to eat apples.\"\n",
    "\n",
    "for i, sentence in enumerate(embedded_sentences):\n",
    "    for j, other_sentence in enumerate(embedded_sentences):\n",
    "        if i < j:\n",
    "            print(\n",
    "                f\"[유사도 {similarity(sentence, other_sentence):.4f}] {sentences[i]} \\t <=====> \\t {sentences[j]}\"\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "jQK56BSjHtIY",
   "metadata": {
    "id": "jQK56BSjHtIY"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "tkpwZAsbfor9",
   "metadata": {
    "id": "tkpwZAsbfor9"
   },
   "source": [
    "Jun---\n",
    "- 과제: 한글/영문이 유사도가 높지 않음. 어떻게 하면 해결할지..."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "py-test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
