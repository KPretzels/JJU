{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2cjpen-3xMlG"
   },
   "source": [
    "# Ollama\n",
    "\n",
    "Jun--\n",
    "- 이 코는 반드시 로컬 환경에 수행하야 함.\n",
    "- (나는 Python 3.9.6사용)\n",
    "\n",
    "\n",
    "Ollama는 로컬 환경에서 대규모 언어 모델(LLM)을 쉽게 실행할 수 있게 해주는 오픈소스 프로젝트입니다. 이 도구는 다양한 LLM을 간단한 명령어로 다운로드하고 실행할 수 있게 해주며, 개발자들이 AI 모델을 자신의 컴퓨터에서 직접 실험하고 사용할 수 있도록 지원합니다. Ollama는 사용자 친화적인 인터페이스와 빠른 성능으로, AI 개발 및 실험을 더욱 접근하기 쉽고 효율적으로 만들어주는 도구입니다.\n",
    "\n",
    "Jun---\n",
    "- 주의사항: Windows 사용자는 재시동 필요\n",
    "- Ollama Embedding모델 다운로드\n",
    "- local model... langSmith에 아무것도 안찍히는것 확인\n",
    "\n",
    "- [공식 웹사이트/설치](https://ollama.com/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 986,
     "status": "ok",
     "timestamp": 1737164302982,
     "user": {
      "displayName": "Chang Jun Lee",
      "userId": "07449846774346066151"
     },
     "user_tz": -540
    },
    "id": "j8g7foSYxMlI"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"\"\n",
    "\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = \"6\"\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_ENDPOINT\"] = \"https://api.smith.langchain.com\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"08-05\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 1027,
     "status": "ok",
     "timestamp": 1737164306672,
     "user": {
      "displayName": "Chang Jun Lee",
      "userId": "07449846774346066151"
     },
     "user_tz": -540
    },
    "id": "6cAFx2SExMlJ"
   },
   "outputs": [],
   "source": [
    "texts = [\n",
    "    \"안녕, 만나서 반가워.\",\n",
    "    \"LangChain simplifies the process of building applications with large language models\",\n",
    "    \"랭체인 한국어 튜토리얼은 LangChain의 공식 문서, cookbook 및 다양한 실용 예제를 바탕으로 하여 사용자가 LangChain을 더 쉽고 효과적으로 활용할 수 있도록 구성되어 있습니다. \",\n",
    "    \"LangChain은 초거대 언어모델로 애플리케이션을 구축하는 과정을 단순화합니다.\",\n",
    "    \"Retrieval-Augmented Generation (RAG) is an effective technique for improving AI responses.\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ywj3cpRsxMlK"
   },
   "source": [
    "**지원되는 임베딩 모델 확인**\n",
    "\n",
    "- https://ollama.com/library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0Rb7bIT_xMlK"
   },
   "source": [
    "`ollama pull nomic-embed-text`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 3218,
     "status": "ok",
     "timestamp": 1737164313483,
     "user": {
      "displayName": "Chang Jun Lee",
      "userId": "07449846774346066151"
     },
     "user_tz": -540
    },
    "id": "a70MMJGpxgYB"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49m/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -qU langchain_community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49m/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -qU langchain_community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1091,
     "status": "ok",
     "timestamp": 1737164315829,
     "user": {
      "displayName": "Chang Jun Lee",
      "userId": "07449846774346066151"
     },
     "user_tz": -540
    },
    "id": "d-uUaDhLxMlK",
    "outputId": "2265a6a9-9dcc-4788-dacf-b6b3d453e8ae"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/71/f9c9056j43gdbc53twm7ly_00000gn/T/ipykernel_42469/704369228.py:3: LangChainDeprecationWarning: The class `OllamaEmbeddings` was deprecated in LangChain 0.3.1 and will be removed in 1.0.0. An updated version of the class exists in the :class:`~langchain-ollama package and should be used instead. To use it run `pip install -U :class:`~langchain-ollama` and import as `from :class:`~langchain_ollama import OllamaEmbeddings``.\n",
      "  ollama_embeddings = OllamaEmbeddings(\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "\n",
    "ollama_embeddings = OllamaEmbeddings(\n",
    "    model=\"nomic-embed-text\",\n",
    "    # model=\"chatfire/bge-m3:q8_0\" # BGE-M3\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2eWTymg9xMlK"
   },
   "source": [
    "`Query` 를 임베딩 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 828
    },
    "executionInfo": {
     "elapsed": 557,
     "status": "error",
     "timestamp": 1737164320235,
     "user": {
      "displayName": "Chang Jun Lee",
      "userId": "07449846774346066151"
     },
     "user_tz": -540
    },
    "id": "V6dAJuS8xMlK",
    "outputId": "9adf5438-9164-4ce2-dc43-867fe8069f9e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "768"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 쿼리 임베딩\n",
    "embedded_query = ollama_embeddings.embed_query(\"LangChain 에 대해서 상세히 알려주세요.\")\n",
    "# 임베딩 차원 출력\n",
    "len(embedded_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r9FvNI19xMlK"
   },
   "source": [
    "문서를 임베딩 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "lkdhT0JWxMlL"
   },
   "outputs": [],
   "source": [
    "# 문서 임베딩\n",
    "embedded_documents = ollama_embeddings.embed_documents(texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_2vdYjKYxMlL"
   },
   "source": [
    "유사도 계산 결과를 출력합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "W2vxPp4kxMlL"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Query] LangChain 에 대해서 알려주세요.\n",
      "====================================\n",
      "[0] 유사도: 399.646 | LangChain은 초거대 언어모델로 애플리케이션을 구축하는 과정을 단순화합니다.\n",
      "\n",
      "[1] 유사도: 356.516 | 랭체인 한국어 튜토리얼은 LangChain의 공식 문서, cookbook 및 다양한 실용 예제를 바탕으로 하여 사용자가 LangChain을 더 쉽고 효과적으로 활용할 수 있도록 구성되어 있습니다. \n",
      "\n",
      "[2] 유사도: 322.365 | LangChain simplifies the process of building applications with large language models\n",
      "\n",
      "[3] 유사도: 321.083 | 안녕, 만나서 반가워.\n",
      "\n",
      "[4] 유사도: 224.864 | Retrieval-Augmented Generation (RAG) is an effective technique for improving AI responses.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 질문(embedded_query): LangChain 에 대해서 알려주세요.\n",
    "similarity = np.array(embedded_query) @ np.array(embedded_documents).T\n",
    "\n",
    "# 유사도 기준 내림차순 정렬\n",
    "sorted_idx = (np.array(embedded_query) @ np.array(embedded_documents).T).argsort()[::-1]\n",
    "\n",
    "# 결과 출력\n",
    "print(\"[Query] LangChain 에 대해서 알려주세요.\\n====================================\")\n",
    "for i, idx in enumerate(sorted_idx):\n",
    "    print(f\"[{i}] 유사도: {similarity[idx]:.3f} | {texts[idx]}\")\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
