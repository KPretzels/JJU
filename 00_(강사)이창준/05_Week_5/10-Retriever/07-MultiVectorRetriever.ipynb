{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d96a9939",
   "metadata": {
    "id": "d96a9939"
   },
   "source": [
    "# 다중 벡터저장소 검색기(MultiVectorRetriever)\n",
    "\n",
    "LangChain에서는 문서를 다양한 상황에서 효율적으로 쿼리할 수 있는 특별한 기능, 바로 `MultiVectorRetriever`를 제공합니다. 이 기능을 사용하면 문서를 여러 벡터로 저장하고 관리할 수 있어, 정보 검색의 정확도와 효율성을 대폭 향상시킬 수 있습니다.\n",
    "\n",
    "`MultiVectorRetriever`를 활용해 문서당 여러 벡터를 생성하는 몇 가지 방법을 살펴보겠습니다.\n",
    "\n",
    "**문서당 여러 벡터 생성 방법 소개**\n",
    "\n",
    "1. **작은 청크 생성**: 문서를 더 작은 단위로 나눈 후, 각 청크에 대해 별도의 임베딩을 생성합니다. 이 방식을 사용하면 문서의 특정 부분에 좀 더 세심한 주의를 기울일 수 있습니다. 이 과정은 `ParentDocumentRetriever`를 통해 구현할 수 있어, 세부 정보에 대한 탐색이 용이해집니다.\n",
    "\n",
    "2. **요약 임베딩**: 각 문서의 요약을 생성하고, 이 요약으로부터 임베딩을 만듭니다. 이 요약 임베딩은 문서의 핵심 내용을 신속하게 파악하는 데 큰 도움이 됩니다. 문서 전체를 분석하는 대신 핵심적인 요약 부분만을 활용하여 효율성을 극대화할 수 있습니다.\n",
    "\n",
    "3. **가설 질문 활용**: 각 문서에 대해 적합한 가설 질문을 만들고, 이 질문에 기반한 임베딩을 생성합니다. 특정 주제나 내용에 대해 깊이 있는 탐색을 원할 때 이 방법이 유용합니다. 가설 질문은 문서의 내용을 다양한 관점에서 접근하게 해주며, 더 광범위한 이해를 가능하게 합니다.\n",
    "\n",
    "4. **수동 추가 방식**: 사용자가 문서 검색 시 고려해야 할 특정 질문이나 쿼리를 직접 추가할 수 있습니다. 이 방법을 통해 사용자는 검색 과정에서 보다 세밀한 제어를 할 수 있으며, 자신의 요구 사항에 맞춘 맞춤형 검색이 가능해집니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3645c156",
   "metadata": {
    "id": "3645c156"
   },
   "source": [
    "## 실습에 활용한 문서\n",
    "\n",
    "소프트웨어정책연구소(SPRi) - 2023년 12월호\n",
    "\n",
    "- 저자: 유재흥(AI정책연구실 책임연구원), 이지수(AI정책연구실 위촉연구원)\n",
    "- 링크: https://spri.kr/posts/view/23669\n",
    "- 파일명: `SPRI_AI_Brief_2023년12월호_F.pdf`\n",
    "\n",
    "**참고**: 위의 파일은 `data` 폴더 내에 다운로드 받으세요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "18a2a1b0",
   "metadata": {
    "executionInfo": {
     "elapsed": 498,
     "status": "ok",
     "timestamp": 1737459133718,
     "user": {
      "displayName": "Chang Jun Lee",
      "userId": "07449846774346066151"
     },
     "user_tz": -540
    },
    "id": "18a2a1b0"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"\"\n",
    "\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = \"\"\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_ENDPOINT\"] = \"https://api.smith.langchain.com\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"10-03\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b574ec5",
   "metadata": {
    "id": "1b574ec5"
   },
   "source": [
    "텍스트 파일에서 데이터를 로드하고, 로드된 문서들을 지정된 크기로 분할하는 전처리 과정을 수행합니다.\n",
    "\n",
    "분할된 문서들은 추후 벡터화 및 검색 등의 작업에 사용될 수 있습니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c8lHDwudoo0G",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 34263,
     "status": "ok",
     "timestamp": 1737459208906,
     "user": {
      "displayName": "Chang Jun Lee",
      "userId": "07449846774346066151"
     },
     "user_tz": -540
    },
    "id": "c8lHDwudoo0G",
    "outputId": "8307d703-6b3a-4741-b4e4-76b93b6e5db8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/67.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
      "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
      "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m35.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.3/54.3 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m628.3/628.3 kB\u001b[0m \u001b[31m35.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m65.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.8/94.8 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m48.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m412.2/412.2 kB\u001b[0m \u001b[31m27.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m53.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m278.6/278.6 kB\u001b[0m \u001b[31m19.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m64.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.6/49.6 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.8/94.8 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.3/13.3 MB\u001b[0m \u001b[31m74.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.8/55.8 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.8/69.8 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.2/73.2 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m64.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.3/62.3 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m459.8/459.8 kB\u001b[0m \u001b[31m33.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m319.7/319.7 kB\u001b[0m \u001b[31m25.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.0/4.0 MB\u001b[0m \u001b[31m85.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m452.6/452.6 kB\u001b[0m \u001b[31m32.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "transformers 4.47.1 requires tokenizers<0.22,>=0.21, but you have tokenizers 0.20.3 which is incompatible.\n",
      "tensorflow 2.17.1 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3, but you have protobuf 5.29.3 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -qU langchain_community langchain_openai langchain_chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "KnURgmzVpF-x",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5380,
     "status": "ok",
     "timestamp": 1737459314262,
     "user": {
      "displayName": "Chang Jun Lee",
      "userId": "07449846774346066151"
     },
     "user_tz": -540
    },
    "id": "KnURgmzVpF-x",
    "outputId": "60fb6cd9-6ec8-48db-aa36-37865a9da4c3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.0/20.0 MB\u001b[0m \u001b[31m69.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "!pip install -qU pymupdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0d6c52a3",
   "metadata": {
    "executionInfo": {
     "elapsed": 579,
     "status": "ok",
     "timestamp": 1737459321547,
     "user": {
      "displayName": "Chang Jun Lee",
      "userId": "07449846774346066151"
     },
     "user_tz": -540
    },
    "id": "0d6c52a3"
   },
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyMuPDFLoader\n",
    "\n",
    "loader = PyMuPDFLoader(\"/content/appendix-keywords.txt\")\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "453afd1e",
   "metadata": {
    "id": "453afd1e"
   },
   "source": [
    "데이터로부터 로드한 원본 도큐먼트는 `docs` 변수에 담았습니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "12a50910",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 379,
     "status": "ok",
     "timestamp": 1737459326401,
     "user": {
      "displayName": "Chang Jun Lee",
      "userId": "07449846774346066151"
     },
     "user_tz": -540
    },
    "id": "12a50910",
    "outputId": "24381189-73d4-4164-a478-5e9a9168db2b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "판다스 (Pandas)\n",
      "정의: 판다스는 파이썬 프로그래밍 언어를 위한 데이터 분석 및 조\n",
      "작 도구를 제공하는 라이브러리입니다. 이는 데이터 분석 작업을\n",
      "효율적으로 수행할 수 있게 합니다.\n",
      "예시: 판다스를 사용하여 CSV 파일을 읽고, 데이터를 정제하며,\n",
      "다양한 분석을 수행할 수 있습니다.\n",
      "연관키워드: 데이터 분석, 파이썬, 데이터 처리\n",
      "GPT (Generative Pretrained Transformer)\n",
      "정의: GPT는 대규모의 데이터셋으로 사전 훈련된 생성적 언어 모델\n",
      "로, 다양한 텍스트 기반 작업에 활용됩니다. 이는 입력된 텍스트에\n",
      "기반하여 자연스러운 언어를 생성할 수 있습니다.\n",
      "예시: 사용자가 제공한 질문에 대해 자세한 답변을 생성하는 챗봇\n",
      "은 GPT 모델을 사용할 수 있습니다.\n",
      "연관키워드: 자연어 처리, 텍스트 생성, 딥러닝\n",
      "InstructGPT\n",
      "정의: InstructGPT는 사용자의 지시에 따라 특정한 작업을 수행\n",
      "하기 위해 최적화된 GPT 모델입니다. 이 모델은 보다 정\n"
     ]
    }
   ],
   "source": [
    "print(docs[5].page_content[:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b671d6e",
   "metadata": {
    "id": "1b671d6e"
   },
   "source": [
    "## Chunk + 원본 문서 검색\n",
    "\n",
    "대용량 정보를 검색하는 경우, 더 작은 단위로 정보를 임베딩하는 것이 유용할 수 있습니다.\n",
    "\n",
    "`MultiVectorRetriever` 를 통해 문서를 여러 벡터로 저장하고 관리할 수 있습니다.\n",
    "\n",
    "`docstore` 에 원본 문서를 저장하고, `vectorstore` 에 임베딩된 문서를 저장합니다.\n",
    "\n",
    "이로써 문서를 더 작은 단위로 나누어 더 정확한 검색이 가능해집니다. 때에 따라서는 원본 문서의 내용을 조회할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8bc51c01",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3166,
     "status": "ok",
     "timestamp": 1737459334147,
     "user": {
      "displayName": "Chang Jun Lee",
      "userId": "07449846774346066151"
     },
     "user_tz": -540
    },
    "id": "8bc51c01",
    "outputId": "7287adfc-dd03-4689-bbff-63fe85c274f7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['c7a853ae-5d73-4282-9844-69ec2c9287d2',\n",
       " 'a9556ca6-261a-4004-b4b3-19fadfa7436e',\n",
       " '6d50ebe5-9cbb-4bb0-8efc-aa6b317e60d0',\n",
       " '5c808bb6-fb35-4974-96c2-936389f30305',\n",
       " '81a15d38-5423-44a5-ad1f-315051a90405',\n",
       " '736523c5-246d-44ef-a2d4-10023628eae4',\n",
       " '87ad5548-f271-4fcd-9be8-086c42b34cea']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 자식 청크를 인덱싱하는 데 사용할 벡터 저장소\n",
    "import uuid\n",
    "from langchain.storage import InMemoryStore\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain.retrievers.multi_vector import MultiVectorRetriever\n",
    "\n",
    "vectorstore = Chroma(\n",
    "    collection_name=\"small_bigger_chunks\",\n",
    "    embedding_function=OpenAIEmbeddings(model=\"text-embedding-3-small\"),\n",
    ")\n",
    "# 부모 문서의 저장소 계층\n",
    "store = InMemoryStore()\n",
    "\n",
    "id_key = \"doc_id\"\n",
    "\n",
    "# 검색기 (시작 시 비어 있음)\n",
    "retriever = MultiVectorRetriever(\n",
    "    vectorstore=vectorstore,\n",
    "    byte_store=store,\n",
    "    id_key=id_key,\n",
    ")\n",
    "\n",
    "# 문서 ID를 생성합니다.\n",
    "doc_ids = [str(uuid.uuid4()) for _ in docs]\n",
    "\n",
    "# 두개의 생성된 id를 확인합니다.\n",
    "doc_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aa3e771",
   "metadata": {
    "id": "0aa3e771"
   },
   "source": [
    "여기서 큰 청크로 분할하기 위한 `parent_text_splitter`\n",
    "\n",
    "더 작은 청크로 분할하기 위한 `child_text_splitter` 를 정의합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3bc95363",
   "metadata": {
    "executionInfo": {
     "elapsed": 295,
     "status": "ok",
     "timestamp": 1737459337876,
     "user": {
      "displayName": "Chang Jun Lee",
      "userId": "07449846774346066151"
     },
     "user_tz": -540
    },
    "id": "3bc95363"
   },
   "outputs": [],
   "source": [
    "# RecursiveCharacterTextSplitter 객체를 생성합니다.\n",
    "parent_text_splitter = RecursiveCharacterTextSplitter(chunk_size=600)\n",
    "\n",
    "# 더 작은 청크를 생성하는 데 사용할 분할기\n",
    "child_text_splitter = RecursiveCharacterTextSplitter(chunk_size=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8e48a98",
   "metadata": {
    "id": "f8e48a98"
   },
   "source": [
    "더 큰 Chunk인 Parent 문서를 생성합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f4437c9e",
   "metadata": {
    "executionInfo": {
     "elapsed": 318,
     "status": "ok",
     "timestamp": 1737459341540,
     "user": {
      "displayName": "Chang Jun Lee",
      "userId": "07449846774346066151"
     },
     "user_tz": -540
    },
    "id": "f4437c9e"
   },
   "outputs": [],
   "source": [
    "parent_docs = []\n",
    "\n",
    "for i, doc in enumerate(docs):\n",
    "    # 현재 문서의 ID를 가져옵니다.\n",
    "    _id = doc_ids[i]\n",
    "    # 현재 문서를 하위 문서로 분할\n",
    "    parent_doc = parent_text_splitter.split_documents([doc])\n",
    "\n",
    "    for _doc in parent_doc:\n",
    "        # metadata에 문서 ID 를 저장\n",
    "        _doc.metadata[id_key] = _id\n",
    "    parent_docs.extend(parent_doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6c5b0e5",
   "metadata": {
    "id": "e6c5b0e5"
   },
   "source": [
    "`parent_docs` 에 기입된 `doc_id` 를 확인합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f8d7ff8b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 443,
     "status": "ok",
     "timestamp": 1737459344488,
     "user": {
      "displayName": "Chang Jun Lee",
      "userId": "07449846774346066151"
     },
     "user_tz": -540
    },
    "id": "f8d7ff8b",
    "outputId": "ead3033c-e4e6-48cc-a43f-244ca35a1bc9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'producer': '',\n",
       " 'creator': '',\n",
       " 'creationdate': '',\n",
       " 'source': '/content/appendix-keywords.txt',\n",
       " 'file_path': '/content/appendix-keywords.txt',\n",
       " 'total_pages': 7,\n",
       " 'format': 'Tex',\n",
       " 'title': '',\n",
       " 'author': '',\n",
       " 'subject': '',\n",
       " 'keywords': '',\n",
       " 'moddate': '',\n",
       " 'trapped': '',\n",
       " 'encryption': '',\n",
       " 'page': 0,\n",
       " 'doc_id': 'c7a853ae-5d73-4282-9844-69ec2c9287d2'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 생성된 Parent 문서의 메타데이터를 확인합니다.\n",
    "parent_docs[0].metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f680da0",
   "metadata": {
    "id": "3f680da0"
   },
   "source": [
    "상대적으로 더 작은 Chunk인 Child 문서를 생성합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e56afe1a",
   "metadata": {
    "executionInfo": {
     "elapsed": 286,
     "status": "ok",
     "timestamp": 1737459348873,
     "user": {
      "displayName": "Chang Jun Lee",
      "userId": "07449846774346066151"
     },
     "user_tz": -540
    },
    "id": "e56afe1a"
   },
   "outputs": [],
   "source": [
    "child_docs = []\n",
    "for i, doc in enumerate(docs):\n",
    "    # 현재 문서의 ID를 가져옵니다.\n",
    "    _id = doc_ids[i]\n",
    "    # 현재 문서를 하위 문서로 분할\n",
    "    child_doc = child_text_splitter.split_documents([doc])\n",
    "    for _doc in child_doc:\n",
    "        # metadata에 문서 ID 를 저장\n",
    "        _doc.metadata[id_key] = _id\n",
    "    child_docs.extend(child_doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bafe5cb5",
   "metadata": {
    "id": "bafe5cb5"
   },
   "source": [
    "`child_docs` 에 기입된 `doc_id` 를 확인합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "80857992",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 390,
     "status": "ok",
     "timestamp": 1737459364155,
     "user": {
      "displayName": "Chang Jun Lee",
      "userId": "07449846774346066151"
     },
     "user_tz": -540
    },
    "id": "80857992",
    "outputId": "ad8c9fb0-acf3-44b2-a3f9-fa1569b3126c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'producer': '',\n",
       " 'creator': '',\n",
       " 'creationdate': '',\n",
       " 'source': '/content/appendix-keywords.txt',\n",
       " 'file_path': '/content/appendix-keywords.txt',\n",
       " 'total_pages': 7,\n",
       " 'format': 'Tex',\n",
       " 'title': '',\n",
       " 'author': '',\n",
       " 'subject': '',\n",
       " 'keywords': '',\n",
       " 'moddate': '',\n",
       " 'trapped': '',\n",
       " 'encryption': '',\n",
       " 'page': 0,\n",
       " 'doc_id': 'c7a853ae-5d73-4282-9844-69ec2c9287d2'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 생성된 Child 문서의 메타데이터를 확인합니다.\n",
    "child_docs[0].metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a346a79",
   "metadata": {
    "id": "8a346a79"
   },
   "source": [
    "각각 분할된 청크의 수를 확인합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6dfd9565",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 278,
     "status": "ok",
     "timestamp": 1737459367603,
     "user": {
      "displayName": "Chang Jun Lee",
      "userId": "07449846774346066151"
     },
     "user_tz": -540
    },
    "id": "6dfd9565",
    "outputId": "31f1379e-0c4e-4430-e0e1-2b8780b0adba"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "분할된 parent_docs의 개수: 13\n",
      "분할된 child_docs의 개수: 129\n"
     ]
    }
   ],
   "source": [
    "print(f\"분할된 parent_docs의 개수: {len(parent_docs)}\")\n",
    "print(f\"분할된 child_docs의 개수: {len(child_docs)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6da6ab64",
   "metadata": {
    "id": "6da6ab64"
   },
   "source": [
    "벡터저장소에 새롭게 생성한 작게 쪼개진 하위문서 집합을 추가합니다.\n",
    "\n",
    "다음으로는 상위 문서는 생성한 UUID 와 맵핑하여 `docstore` 에 추가합니다.\n",
    "\n",
    "- `mset()` 메서드를 통해 문서 ID와 문서 내용을 key-value 쌍으로 문서 저장소에 저장합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a291a760",
   "metadata": {
    "executionInfo": {
     "elapsed": 3817,
     "status": "ok",
     "timestamp": 1737459374103,
     "user": {
      "displayName": "Chang Jun Lee",
      "userId": "07449846774346066151"
     },
     "user_tz": -540
    },
    "id": "a291a760"
   },
   "outputs": [],
   "source": [
    "# 벡터 저장소에 parent + child 문서를 추가\n",
    "retriever.vectorstore.add_documents(parent_docs)\n",
    "retriever.vectorstore.add_documents(child_docs)\n",
    "\n",
    "# docstore 에 원본 문서를 저장\n",
    "retriever.docstore.mset(list(zip(doc_ids, docs)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92a644c1",
   "metadata": {
    "id": "92a644c1"
   },
   "source": [
    "유사도 검색을 수행합니다. 가장 유사도가 높은 첫 번째 문서 조각을 출력합니다.\n",
    "\n",
    "여기서 `retriever.vectorstore.similarity_search` 메서드는 child + parent 문서 chunk 내에서 검색을 수행합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a0d9ba0c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 698,
     "status": "ok",
     "timestamp": 1737459378498,
     "user": {
      "displayName": "Chang Jun Lee",
      "userId": "07449846774346066151"
     },
     "user_tz": -540
    },
    "id": "a0d9ba0c",
    "outputId": "ab1a1f4b-6fb2-4302-f1b3-e48f88eec503"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "검색된 문서의 개수: 4\n"
     ]
    }
   ],
   "source": [
    "# vectorstore의 유사도 검색을 수행합니다.\n",
    "relevant_chunks = retriever.vectorstore.similarity_search(\n",
    "    \"삼성전자가 만든 생성형 AI 의 이름은?\"\n",
    ")\n",
    "print(f\"검색된 문서의 개수: {len(relevant_chunks)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e5eb7fc2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 271,
     "status": "ok",
     "timestamp": 1737459383774,
     "user": {
      "displayName": "Chang Jun Lee",
      "userId": "07449846774346066151"
     },
     "user_tz": -540
    },
    "id": "e5eb7fc2",
    "outputId": "8a352832-bbfe-47fe-89ea-bc6ca4428cc5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FAISS (Facebook AI Similarity Search)\n",
      "정의: FAISS는 페이스북에서 개발한 고속 유사성 검색 라이브러리\n",
      "로, 특히 대규모 벡터 집합에서 유사 벡터를 효과적으로 검색할 수\n",
      "있도록 설계되었습니다.\n",
      "예시: 수백만 개의 이미지 벡터 중에서 비슷한 이미지를 빠르게 찾\n",
      "는 데 FAISS가 사용될 수 있습니다.\n",
      "\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "\n",
      "련성 높은 결과를 생성하도록 설계되었습니다.\n",
      "예시: 사용자가 \"이메일 초안 작성\"과 같은 특정 지시를 제공하면,\n",
      "InstructGPT는 관련 내용을 기반으로 이메일을 작성합니다.\n",
      "연관키워드: 인공지능, 자연어 이해, 명령 기반 처리\n",
      "Keyword Search\n",
      "정의: 키워드 검색은 사용자가 입력한 키워드를 기반으로 정보를\n",
      "\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "\n",
      "연관키워드: 자연어 처리, 딥러닝, 텍스트 생성\n",
      "FAISS (Facebook AI Similarity Search)\n",
      "정의: FAISS는 페이스북에서 개발한 고속 유사성 검색 라이브러리\n",
      "로, 특히 대규모 벡터 집합에서 유사 벡터를 효과적으로 검색할 수\n",
      "있도록 설계되었습니다.\n",
      "예시: 수백만 개의 이미지 벡터 중에서 비슷한 이미지를 빠르게 찾\n",
      "\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "\n",
      "정의: HuggingFace는 자연어 처리를 위한 다양한 사전 훈련된 모\n",
      "델과 도구를 제공하는 라이브러리입니다. 이는 연구자와 개발자들이\n",
      "쉽게 NLP 작업을 수행할 수 있도록 돕습니다.\n",
      "예시: HuggingFace의 Transformers 라이브러리를 사용하여 감\n",
      "정 분석, 텍스트 생성 등의 작업을 수행할 수 있습니다.\n",
      "\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for chunk in relevant_chunks:\n",
    "    print(chunk.page_content, end=\"\\n\\n\")\n",
    "    print(\">\" * 100, end=\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "598f6f1a",
   "metadata": {
    "id": "598f6f1a"
   },
   "source": [
    "이번에는 `retriever.invoke()` 메서드를 사용하여 쿼리를 실행합니다.\n",
    "\n",
    "`retriever.invoke()` 메서드는 원본 문서의 전체 내용을 검색합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1a29f9b4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 310,
     "status": "ok",
     "timestamp": 1737459388748,
     "user": {
      "displayName": "Chang Jun Lee",
      "userId": "07449846774346066151"
     },
     "user_tz": -540
    },
    "id": "1a29f9b4",
    "outputId": "dcc20213-63db-4cea-e5a8-e553adf3aef8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "검색된 문서의 개수: 3\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "연관키워드: 자연어 처리, 딥러닝, 텍스트 생성\n",
      "FAISS (Facebook AI Similarity Search)\n",
      "정의: FAISS는 페이스북에서 개발한 고속 유사성 검색 라이브러리\n",
      "로, 특히 대규모 벡터 집합에서 유사 벡터를 효과적으로 검색할 수\n",
      "있도록 설계되었습니다.\n",
      "예시: 수백만 개의 이미지 벡터 중에서 비슷한 이미지를 빠르게 찾\n",
      "는 데 FAISS가 사용될 수 있습니다.\n",
      "연관키워드: 벡터 검색, 머신러닝, 데이터베이스 최적화\n",
      "Open Source\n",
      "정의: 오픈 소스는 소스 코드가 공개되어 누구나 자유롭게 사용,\n",
      "수정, 배포할 수 있는 소프트웨어를 의미합니다. 이는 협업과 혁신\n",
      "을 촉진하는 데 중요한 역할을 합니다.\n",
      "예시: 리눅스 운영 체제는 대표적인 오픈 소스 프로젝트입니다.\n",
      "연관키워드: 소프트웨어 개발, 커뮤니티, 기술 협업\n",
      "Structured Data\n",
      "정의: 구조화된 데이터는 정해진 형식이나 스키마에 따라 조직된\n",
      "데이터입니다. 이는 데이터베이스, 스프레드시트 등에서 쉽게 검색\n",
      "하고 분석할 수 있습니다.\n",
      "예시: 관계형 데이터베이스에 저장된 고객 정보 테이블은 구조화된\n",
      "데이터의 예입니다.\n",
      "연관키워드: 데이터베이스, 데이터 분석, 데이터 모델링\n",
      "Parser\n",
      "정의: 파서는 주어진 데이터(문자열, 파일 등)를 분석하여 구조화\n",
      "된 형태로 변환하는 도구입니다. 이는 프로그래밍 언어의 구문 분\n",
      "석이나 파일 데이터 처리에 사용됩니다.\n",
      "예시: HTML 문서를 구문 분석하여 웹 페이지의 DOM 구조를 생성하\n",
      "는 것은 파싱의 한 예입니다.\n",
      "연관키워드: 구문 분석, 컴파일러, 데이터 처리\n",
      "TF-IDF (Term Frequency-Inverse Document Frequency)\n",
      "정의: TF-IDF는 문서 내에서 단어의 중요도를 평가하는 데 사용되\n"
     ]
    }
   ],
   "source": [
    "relevant_docs = retriever.invoke(\"삼성전자가 만든 생성형 AI 의 이름은?\")\n",
    "print(f\"검색된 문서의 개수: {len(relevant_docs)}\", end=\"\\n\\n\")\n",
    "print(\"=\" * 100, end=\"\\n\\n\")\n",
    "print(relevant_docs[0].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acc30896",
   "metadata": {
    "id": "acc30896"
   },
   "source": [
    "리트리버(retriever)가 벡터 데이터베이스에서 기본적으로 수행하는 검색 유형은 유사도 검색입니다.\n",
    "\n",
    "LangChain Vector Stores는 [Max Marginal Relevance](https://api.python.langchain.com/en/latest/vectorstores/langchain_core.vectorstores.VectorStore.html#langchain_core.vectorstores.VectorStore.max_marginal_relevance_search)를 통한 검색도 지원하므로, 이를 대신 사용하고 싶다면 다음과 같이 `search_type` 속성을 설정하면 됩니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac718689",
   "metadata": {
    "id": "ac718689"
   },
   "source": [
    "- `retriever` 객체의 `search_type` 속성을 `SearchType.mmr`로 설정합니다.\n",
    "  - 이는 검색 시 MMR(Maximal Marginal Relevance) 알고리즘을 사용하도록 지정하는 것입니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c545fc19",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2592,
     "status": "ok",
     "timestamp": 1737459396968,
     "user": {
      "displayName": "Chang Jun Lee",
      "userId": "07449846774346066151"
     },
     "user_tz": -540
    },
    "id": "c545fc19",
    "outputId": "81230b70-35b9-44d1-c232-e0bd692c268e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "연관키워드: 자연어 처리, 딥러닝, 텍스트 생성\n",
      "FAISS (Facebook AI Similarity Search)\n",
      "정의: FAISS는 페이스북에서 개발한 고속 유사성 검색 라이브러리\n",
      "로, 특히 대규모 벡터 집합에서 유사 벡터를 효과적으로 검색할 수\n",
      "있도록 설계되었습니다.\n",
      "예시: 수백만 개의 이미지 벡터 중에서 비슷한 이미지를 빠르게 찾\n",
      "는 데 FAISS가 사용될 수 있습니다.\n",
      "연관키워드: 벡터 검색, 머신러닝, 데이터베이스 최적화\n",
      "Open Source\n",
      "정의: 오픈 소스는 소스 코드가 공개되어 누구나 자유롭게 사용,\n",
      "수정, 배포할 수 있는 소프트웨어를 의미합니다. 이는 협업과 혁신\n",
      "을 촉진하는 데 중요한 역할을 합니다.\n",
      "예시: 리눅스 운영 체제는 대표적인 오픈 소스 프로젝트입니다.\n",
      "연관키워드: 소프트웨어 개발, 커뮤니티, 기술 협업\n",
      "Structured Data\n",
      "정의: 구조화된 데이터는 정해진 형식이나 스키마에 따라 조직된\n",
      "데이터입니다. 이는 데이터베이스, 스프레드시트 등에서 쉽게 검색\n",
      "하고 분석할 수 있습니다.\n",
      "예시: 관계형 데이터베이스에 저장된 고객 정보 테이블은 구조화된\n",
      "데이터의 예입니다.\n",
      "연관키워드: 데이터베이스, 데이터 분석, 데이터 모델링\n",
      "Parser\n",
      "정의: 파서는 주어진 데이터(문자열, 파일 등)를 분석하여 구조화\n",
      "된 형태로 변환하는 도구입니다. 이는 프로그래밍 언어의 구문 분\n",
      "석이나 파일 데이터 처리에 사용됩니다.\n",
      "예시: HTML 문서를 구문 분석하여 웹 페이지의 DOM 구조를 생성하\n",
      "는 것은 파싱의 한 예입니다.\n",
      "연관키워드: 구문 분석, 컴파일러, 데이터 처리\n",
      "TF-IDF (Term Frequency-Inverse Document Frequency)\n",
      "정의: TF-IDF는 문서 내에서 단어의 중요도를 평가하는 데 사용되\n"
     ]
    }
   ],
   "source": [
    "from langchain.retrievers.multi_vector import SearchType\n",
    "\n",
    "# 검색 유형을 MMR(Maximal Marginal Relevance)로 설정\n",
    "retriever.search_type = SearchType.mmr\n",
    "\n",
    "# 관련 문서 전체를 검색\n",
    "print(retriever.invoke(\"삼성전자가 만든 생성형 AI 의 이름은?\")[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "xH_eeRdqp3m4",
   "metadata": {
    "executionInfo": {
     "elapsed": 3336,
     "status": "ok",
     "timestamp": 1737459476347,
     "user": {
      "displayName": "Chang Jun Lee",
      "userId": "07449846774346066151"
     },
     "user_tz": -540
    },
    "id": "xH_eeRdqp3m4"
   },
   "outputs": [],
   "source": [
    "!pip install -qU langchain_core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "07d08019",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 632,
     "status": "ok",
     "timestamp": 1737459484763,
     "user": {
      "displayName": "Chang Jun Lee",
      "userId": "07449846774346066151"
     },
     "user_tz": -540
    },
    "id": "07d08019",
    "outputId": "6efdd264-5b47-4dc4-eb30-e4f36010db97"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:langchain_core.vectorstores.base:No relevant docs were retrieved using the relevance score threshold 0.3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.retrievers.multi_vector import SearchType\n",
    "\n",
    "# 검색 유형을 similarity_score_threshold로 설정\n",
    "retriever.search_type = SearchType.similarity_score_threshold\n",
    "retriever.search_kwargs = {\"score_threshold\": 0.3}\n",
    "\n",
    "# 관련 문서 전체를 검색\n",
    "retriever.invoke(\"삼성전자가 만든 생성형 AI 의 이름은?\")\n",
    "# print(retriever.invoke(\"삼성전자가 만든 생성형 AI 의 이름은?\")[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d203555f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 624,
     "status": "ok",
     "timestamp": 1737459500208,
     "user": {
      "displayName": "Chang Jun Lee",
      "userId": "07449846774346066151"
     },
     "user_tz": -540
    },
    "id": "d203555f",
    "outputId": "7d6c0325-14db-49ad-9bc1-a916596749a2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "from langchain.retrievers.multi_vector import SearchType\n",
    "\n",
    "# 검색 유형을 similarity로 설정, k값을 1로 설정\n",
    "retriever.search_type = SearchType.similarity\n",
    "retriever.search_kwargs = {\"k\": 1}\n",
    "\n",
    "# 관련 문서 전체를 검색\n",
    "print(len(retriever.invoke(\"삼성전자가 만든 생성형 AI 의 이름은?\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d961b6c",
   "metadata": {
    "id": "4d961b6c"
   },
   "source": [
    "## 요약본(summary)을 벡터저장소에 저장\n",
    "\n",
    "요약은 종종 청크(chunk)의 내용을 보다 정확하게 추출할 수 있어 더 나은 검색 결과를 얻을 수 있습니다.\n",
    "\n",
    "여기서는 요약을 생성하는 방법과 이를 임베딩하는 방법에 대해 설명합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "KGdiQimfqKCv",
   "metadata": {
    "executionInfo": {
     "elapsed": 4110,
     "status": "ok",
     "timestamp": 1737459558420,
     "user": {
      "displayName": "Chang Jun Lee",
      "userId": "07449846774346066151"
     },
     "user_tz": -540
    },
    "id": "KGdiQimfqKCv"
   },
   "outputs": [],
   "source": [
    "!pip install -qU pymupdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e7c44d7a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 309,
     "status": "ok",
     "timestamp": 1737459586341,
     "user": {
      "displayName": "Chang Jun Lee",
      "userId": "07449846774346066151"
     },
     "user_tz": -540
    },
    "id": "e7c44d7a",
    "outputId": "7b3e06ed-7058-422a-9a1e-20e305433852"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "분할된 문서의 개수: 13\n"
     ]
    }
   ],
   "source": [
    "# PDF 파일을 로드하고 텍스트를 분할하기 위한 라이브러리 임포트\n",
    "from langchain_community.document_loaders import PyMuPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "# PDF 파일 로더 초기화\n",
    "loader = PyMuPDFLoader(\"/content/appendix-keywords.txt\")\n",
    "\n",
    "# 텍스트 분할\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=600, chunk_overlap=50)\n",
    "\n",
    "# PDF 파일 로드 및 텍스트 분할 실행\n",
    "split_docs = loader.load_and_split(text_splitter)\n",
    "\n",
    "# 분할된 문서의 개수 출력\n",
    "print(f\"분할된 문서의 개수: {len(split_docs)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a161ea24",
   "metadata": {
    "executionInfo": {
     "elapsed": 276,
     "status": "ok",
     "timestamp": 1737459590627,
     "user": {
      "displayName": "Chang Jun Lee",
      "userId": "07449846774346066151"
     },
     "user_tz": -540
    },
    "id": "a161ea24"
   },
   "outputs": [],
   "source": [
    "from langchain_core.documents import Document\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "\n",
    "summary_chain = (\n",
    "    {\"doc\": lambda x: x.page_content}\n",
    "    # 문서 요약을 위한 프롬프트 템플릿 생성\n",
    "    | ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\"system\", \"You are an expert in summarizing documents in Korean.\"),\n",
    "            (\n",
    "                \"user\",\n",
    "                \"Summarize the following documents in 3 sentences in bullet points format.\\n\\n{doc}\",\n",
    "            ),\n",
    "        ]\n",
    "    )\n",
    "    # OpenAI의 ChatGPT 모델을 사용하여 요약 생성\n",
    "    | ChatOpenAI(temperature=0, model=\"gpt-4o-mini\")\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16b79165",
   "metadata": {
    "id": "16b79165"
   },
   "source": [
    "`chain.batch` 메서드를 사용하여 `docs` 리스트의 문서들을 일괄 요약합니다.\n",
    "- 여기서 `max_concurrency` 매개변수를 10 으로 설정하여 최대 10개의 문서를 동시에 처리할 수 있도록 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f7fe3a63",
   "metadata": {
    "executionInfo": {
     "elapsed": 4539,
     "status": "ok",
     "timestamp": 1737459599485,
     "user": {
      "displayName": "Chang Jun Lee",
      "userId": "07449846774346066151"
     },
     "user_tz": -540
    },
    "id": "f7fe3a63"
   },
   "outputs": [],
   "source": [
    "# 문서 배치 처리\n",
    "summaries = summary_chain.batch(split_docs, {\"max_concurrency\": 10})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "45363e96",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 344,
     "status": "ok",
     "timestamp": 1737459602715,
     "user": {
      "displayName": "Chang Jun Lee",
      "userId": "07449846774346066151"
     },
     "user_tz": -540
    },
    "id": "45363e96",
    "outputId": "7f815b3f-f797-4d95-d038-07e0a5c6bfd6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(summaries)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1a11208",
   "metadata": {
    "id": "d1a11208"
   },
   "source": [
    "요약된 내용을 출력하여 결과를 확인합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "436bd00a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 300,
     "status": "ok",
     "timestamp": 1737459655987,
     "user": {
      "displayName": "Chang Jun Lee",
      "userId": "07449846774346066151"
     },
     "user_tz": -540
    },
    "id": "436bd00a",
    "outputId": "388d50e2-878d-4710-a017-e544b4f8d2cf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "판다스 (Pandas)\n",
      "정의: 판다스는 파이썬 프로그래밍 언어를 위한 데이터 분석 및 조\n",
      "작 도구를 제공하는 라이브러리입니다. 이는 데이터 분석 작업을\n",
      "효율적으로 수행할 수 있게 합니다.\n",
      "예시: 판다스를 사용하여 CSV 파일을 읽고, 데이터를 정제하며,\n",
      "다양한 분석을 수행할 수 있습니다.\n",
      "연관키워드: 데이터 분석, 파이썬, 데이터 처리\n",
      "GPT (Generative Pretrained Transformer)\n",
      "정의: GPT는 대규모의 데이터셋으로 사전 훈련된 생성적 언어 모델\n",
      "로, 다양한 텍스트 기반 작업에 활용됩니다. 이는 입력된 텍스트에\n",
      "기반하여 자연스러운 언어를 생성할 수 있습니다.\n",
      "예시: 사용자가 제공한 질문에 대해 자세한 답변을 생성하는 챗봇\n",
      "은 GPT 모델을 사용할 수 있습니다.\n",
      "연관키워드: 자연어 처리, 텍스트 생성, 딥러닝\n",
      "InstructGPT\n",
      "정의: InstructGPT는 사용자의 지시에 따라 특정한 작업을 수행\n",
      "하기 위해 최적화된 GPT 모델입니다. 이 모델은 보다 정확하고 관\n",
      "련성 높은 결과를 생성하도록 설계되었습니다.\n",
      "예시: 사용자가 \"이메일 초안 작성\"과 같은 특정 지시를 제공하면,\n",
      "\n",
      "[요약]\n",
      "- 판다스는 파이썬을 위한 데이터 분석 및 조작 라이브러리로, CSV 파일 읽기, 데이터 정제 및 다양한 분석 작업을 효율적으로 수행할 수 있게 해줍니다.\n",
      "- GPT는 대규모 데이터셋으로 사전 훈련된 생성적 언어 모델로, 입력된 텍스트에 기반하여 자연스러운 언어를 생성하며, 챗봇과 같은 텍스트 기반 작업에 활용됩니다.\n",
      "- InstructGPT는 사용자의 지시에 따라 특정 작업을 수행하도록 최적화된 GPT 모델로, 보다 정확하고 관련성 높은 결과를 생성하는 데 중점을 두고 설계되었습니다.\n"
     ]
    }
   ],
   "source": [
    "# 원본 문서의 내용을 출력합니다.\n",
    "print(split_docs[10].page_content, end=\"\\n\\n\")\n",
    "# 요약을 출력합니다.\n",
    "print(\"[요약]\")\n",
    "print(summaries[10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04da5865",
   "metadata": {
    "id": "04da5865"
   },
   "source": [
    "`Chroma` 벡터 저장소를 초기화하여 자식 청크(child chunks)를 인덱싱합니다. 이때 `OpenAIEmbeddings`를 임베딩 함수로 사용합니다.\n",
    "\n",
    "- 문서 ID를 나타내는 키로 `\"doc_id\"`를 사용합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "bbe2f51a",
   "metadata": {
    "executionInfo": {
     "elapsed": 315,
     "status": "ok",
     "timestamp": 1737459668519,
     "user": {
      "displayName": "Chang Jun Lee",
      "userId": "07449846774346066151"
     },
     "user_tz": -540
    },
    "id": "bbe2f51a"
   },
   "outputs": [],
   "source": [
    "import uuid\n",
    "\n",
    "# 요약 정보를 저장할 벡터 저장소를 생성합니다.\n",
    "summary_vectorstore = Chroma(\n",
    "    collection_name=\"summaries\",\n",
    "    embedding_function=OpenAIEmbeddings(model=\"text-embedding-3-small\"),\n",
    ")\n",
    "\n",
    "# 부모 문서를 저장할 저장소를 생성합니다.\n",
    "store = InMemoryStore()\n",
    "\n",
    "# 문서 ID를 저장할 키 이름을 지정합니다.\n",
    "id_key = \"doc_id\"\n",
    "\n",
    "# 검색기를 초기화합니다. (시작 시 비어 있음)\n",
    "retriever = MultiVectorRetriever(\n",
    "    vectorstore=summary_vectorstore,  # 벡터 저장소\n",
    "    byte_store=store,  # 바이트 저장소\n",
    "    id_key=id_key,  # 문서 ID 키\n",
    ")\n",
    "# 문서 ID를 생성합니다.\n",
    "doc_ids = [str(uuid.uuid4()) for _ in split_docs]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9d0e2c6",
   "metadata": {
    "id": "e9d0e2c6"
   },
   "source": [
    "요약된 문서와 메타데이터(여기서는 생성한 요약본에 대한 `Document ID` 입니다)를 저장합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "cec99148",
   "metadata": {
    "executionInfo": {
     "elapsed": 333,
     "status": "ok",
     "timestamp": 1737459674738,
     "user": {
      "displayName": "Chang Jun Lee",
      "userId": "07449846774346066151"
     },
     "user_tz": -540
    },
    "id": "cec99148"
   },
   "outputs": [],
   "source": [
    "summary_docs = [\n",
    "    # 요약된 내용을 페이지 콘텐츠로 하고, 문서 ID를 메타데이터로 포함하는 Document 객체를 생성합니다.\n",
    "    Document(page_content=s, metadata={id_key: doc_ids[i]})\n",
    "    for i, s in enumerate(summaries)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bb07ac1",
   "metadata": {
    "id": "1bb07ac1"
   },
   "source": [
    "요약본의 문서의 개수는 원본 문서의 개수와 일치합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d36e4d50",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 266,
     "status": "ok",
     "timestamp": 1737459676340,
     "user": {
      "displayName": "Chang Jun Lee",
      "userId": "07449846774346066151"
     },
     "user_tz": -540
    },
    "id": "d36e4d50",
    "outputId": "22dea13b-cd39-4ef6-ce3a-53ea1271aa29"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 요약본의 문서의 개수\n",
    "len(summary_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4400de8c",
   "metadata": {
    "id": "4400de8c"
   },
   "source": [
    "- `retriever.vectorstore.add_documents(summary_docs)`를 통해 `summary_docs`를 벡터 저장소에 추가합니다.\n",
    "- `retriever.docstore.mset(list(zip(doc_ids, docs)))`를 사용하여 `doc_ids`와 `docs`를 매핑하여 문서 저장소에 저장합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "df7ce3a2",
   "metadata": {
    "executionInfo": {
     "elapsed": 910,
     "status": "ok",
     "timestamp": 1737459679132,
     "user": {
      "displayName": "Chang Jun Lee",
      "userId": "07449846774346066151"
     },
     "user_tz": -540
    },
    "id": "df7ce3a2"
   },
   "outputs": [],
   "source": [
    "retriever.vectorstore.add_documents(\n",
    "    summary_docs\n",
    ")  # 요약된 문서를 벡터 저장소에 추가합니다.\n",
    "\n",
    "# 문서 ID와 문서를 매핑하여 문서 저장소에 저장합니다.\n",
    "retriever.docstore.mset(list(zip(doc_ids, split_docs)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9158831",
   "metadata": {
    "id": "f9158831"
   },
   "source": [
    "`vectorstore` 객체의 `similarity_search` 메서드를 사용하여 유사도 검색을 수행합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "89e3d643",
   "metadata": {
    "executionInfo": {
     "elapsed": 594,
     "status": "ok",
     "timestamp": 1737459681552,
     "user": {
      "displayName": "Chang Jun Lee",
      "userId": "07449846774346066151"
     },
     "user_tz": -540
    },
    "id": "89e3d643"
   },
   "outputs": [],
   "source": [
    "# 유사도 검색을 수행합니다.\n",
    "result_docs = summary_vectorstore.similarity_search(\n",
    "    \"삼성전자가 만든 생성형 AI 의 이름은?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ae7cb5a7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 291,
     "status": "ok",
     "timestamp": 1737459682973,
     "user": {
      "displayName": "Chang Jun Lee",
      "userId": "07449846774346066151"
     },
     "user_tz": -540
    },
    "id": "ae7cb5a7",
    "outputId": "62bcec96-6785-4c0a-b069-fa75be8bf5d4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- HuggingFace는 자연어 처리를 위한 다양한 사전 훈련된 모델과 도구를 제공하는 라이브러리로, 연구자와 개발자들이 NLP 작업을 쉽게 수행할 수 있도록 돕습니다.\n",
      "- 디지털 변환은 기술을 활용하여 기업의 서비스, 문화, 운영을 혁신하고 비즈니스 모델을 개선하여 경쟁력을 높이는 과정입니다.\n",
      "- 크롤링은 자동화된 방식으로 웹 페이지를 방문하여 데이터를 수집하는 과정으로, 주로 검색 엔진 최적화나 데이터 분석에 사용됩니다.\n"
     ]
    }
   ],
   "source": [
    "# 1개의 결과 문서를 출력합니다.\n",
    "print(result_docs[0].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bd64a80",
   "metadata": {
    "id": "7bd64a80"
   },
   "source": [
    "`retriever` 객체의 `invoke()` 사용하여 질문과 관련된 문서를 검색합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c5a9c432",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 644,
     "status": "ok",
     "timestamp": 1737459685535,
     "user": {
      "displayName": "Chang Jun Lee",
      "userId": "07449846774346066151"
     },
     "user_tz": -540
    },
    "id": "c5a9c432",
    "outputId": "6a5962f6-0492-4c68-c44a-1ed6775bdf12"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정의: HuggingFace는 자연어 처리를 위한 다양한 사전 훈련된 모\n",
      "델과 도구를 제공하는 라이브러리입니다. 이는 연구자와 개발자들이\n",
      "쉽게 NLP 작업을 수행할 수 있도록 돕습니다.\n",
      "예시: HuggingFace의 Transformers 라이브러리를 사용하여 감\n",
      "정 분석, 텍스트 생성 등의 작업을 수행할 수 있습니다.\n",
      "연관키워드: 자연어 처리, 딥러닝, 라이브러리\n",
      "Digital Transformation\n",
      "정의: 디지털 변환은 기술을 활용하여 기업의 서비스, 문화, 운영\n",
      "을 혁신하는 과정입니다. 이는 비즈니스 모델을 개선하고 디지털\n",
      "기술을 통해 경쟁력을 높이는 데 중점을 둡니다.\n",
      "예시: 기업이 클라우드 컴퓨팅을 도입하여 데이터 저장과 처리를\n",
      "혁신하는 것은 디지털 변환의 예입니다.\n",
      "연관키워드: 혁신, 기술, 비즈니스 모델\n",
      "Crawling\n",
      "정의: 크롤링은 자동화된 방식으로 웹 페이지를 방문하여 데이터를\n",
      "수집하는 과정입니다. 이는 검색 엔진 최적화나 데이터 분석에 자\n",
      "주 사용됩니다.\n",
      "예시: 구글 검색 엔진이 인터넷 상의 웹사이트를 방문하여 콘텐츠\n",
      "를 수집하고 인덱싱하는 것이 크롤링입니다.\n",
      "연관키워드: 데이터 수집, 웹 스크래핑, 검색 엔진\n",
      "Word2Vec\n"
     ]
    }
   ],
   "source": [
    "# 관련된 문서를 검색하여 가져옵니다.\n",
    "retrieved_docs = retriever.invoke(\"삼성전자가 만든 생성형 AI 의 이름은?\")\n",
    "print(retrieved_docs[0].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e3d5f1b",
   "metadata": {
    "id": "3e3d5f1b"
   },
   "source": [
    "## 가설 쿼리(Hypothetical Queries) 를 활용하여 문서 내용 탐색\n",
    "\n",
    "LLM은 특정 문서에 대해 가정할 수 있는 질문 목록을 생성하는 데에도 사용될 수 있습니다.\n",
    "\n",
    "이렇게 생성된 질문들은 임베딩(embedding)될 수 있으며, 이를 통해 문서의 내용을 더욱 깊이 있게 탐색하고 이해할 수 있습니다.\n",
    "\n",
    "가정 질문 생성은 문서의 주요 주제와 개념을 파악하는 데 도움이 되며, 독자들이 문서 내용에 대해 더 많은 궁금증을 갖도록 유도할 수 있습니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7933e03",
   "metadata": {
    "id": "b7933e03"
   },
   "source": [
    "아래는 `Function Calling` 을 활용하여 가설 질문을 생성하는 예제입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5baf8ff9",
   "metadata": {
    "executionInfo": {
     "elapsed": 301,
     "status": "ok",
     "timestamp": 1737459692536,
     "user": {
      "displayName": "Chang Jun Lee",
      "userId": "07449846774346066151"
     },
     "user_tz": -540
    },
    "id": "5baf8ff9"
   },
   "outputs": [],
   "source": [
    "functions = [\n",
    "    {\n",
    "        \"name\": \"hypothetical_questions\",  # 함수의 이름을 지정합니다.\n",
    "        \"description\": \"Generate hypothetical questions\",  # 함수에 대한 설명을 작성합니다.\n",
    "        \"parameters\": {  # 함수의 매개변수를 정의합니다.\n",
    "            \"type\": \"object\",  # 매개변수의 타입을 객체로 지정합니다.\n",
    "            \"properties\": {  # 객체의 속성을 정의합니다.\n",
    "                \"questions\": {  # 'questions' 속성을 정의합니다.\n",
    "                    \"type\": \"array\",  # 'questions'의 타입을 배열로 지정합니다.\n",
    "                    \"items\": {\n",
    "                        \"type\": \"string\"\n",
    "                    },  # 배열의 요소 타입을 문자열로 지정합니다.\n",
    "                },\n",
    "            },\n",
    "            \"required\": [\"questions\"],  # 필수 매개변수로 'questions'를 지정합니다.\n",
    "        },\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64aa557a",
   "metadata": {
    "id": "64aa557a"
   },
   "source": [
    "`ChatPromptTemplate`을 사용하여 주어진 문서를 기반으로 3개의 가상 질문을 생성하는 프롬프트 템플릿을 정의합니다.\n",
    "\n",
    "- `functions`와 `function_call`을 설정하여 가상 질문 생성 함수를 호출합니다.\n",
    "- `JsonKeyOutputFunctionsParser`를 사용하여 생성된 가상 질문을 파싱하고, `questions` 키에 해당하는 값을 추출합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7cb4be57",
   "metadata": {
    "executionInfo": {
     "elapsed": 349,
     "status": "ok",
     "timestamp": 1737459697729,
     "user": {
      "displayName": "Chang Jun Lee",
      "userId": "07449846774346066151"
     },
     "user_tz": -540
    },
    "id": "7cb4be57"
   },
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.output_parsers.openai_functions import JsonKeyOutputFunctionsParser\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "hypothetical_query_chain = (\n",
    "    {\"doc\": lambda x: x.page_content}\n",
    "    # 아래 문서를 사용하여 답변할 수 있는 가상의 질문을 정확히 3개 생성하도록 요청합니다. 이 숫자는 조정될 수 있습니다.\n",
    "    | ChatPromptTemplate.from_template(\n",
    "        \"Generate a list of exactly 3 hypothetical questions that the below document could be used to answer. \"\n",
    "        \"Potential users are those interested in the AI industry. Create questions that they would be interested in. \"\n",
    "        \"Output should be written in Korean:\\n\\n{doc}\"\n",
    "    )\n",
    "    | ChatOpenAI(max_retries=0, model=\"gpt-4o-mini\").bind(\n",
    "        functions=functions, function_call={\"name\": \"hypothetical_questions\"}\n",
    "    )\n",
    "    # 출력에서 \"questions\" 키에 해당하는 값을 추출합니다.\n",
    "    | JsonKeyOutputFunctionsParser(key_name=\"questions\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b789211",
   "metadata": {
    "id": "3b789211"
   },
   "source": [
    "문서에 대한 답변을 출력합니다.\n",
    "\n",
    "- 출력은 생성한 3개의 가설 쿼리(Hypothetical Queries) 가 담겨 있습니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a9cda3be",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1999,
     "status": "ok",
     "timestamp": 1737459712773,
     "user": {
      "displayName": "Chang Jun Lee",
      "userId": "07449846774346066151"
     },
     "user_tz": -540
    },
    "id": "a9cda3be",
    "outputId": "a8a28700-51e6-4496-d5d6-705434c867c4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['판다스를 사용하여 데이터 분석 작업을 더 효율적으로 수행할 수 있는 방법은 무엇인가요?',\n",
       " 'GPT 모델이 챗봇 개발에 어떻게 활용될 수 있는지 구체적인 예를 들어 설명할 수 있나요?',\n",
       " 'InstructGPT을 활용하여 특정한 작업을 빠르고 정확하게 수행하기 위한 전략은 무엇인가요?']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 주어진 문서에 대해 체인을 실행합니다.\n",
    "hypothetical_query_chain.invoke(split_docs[10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "853ff912",
   "metadata": {
    "id": "853ff912"
   },
   "source": [
    "`chain.batch` 메서드를 사용하여 `split_docs` 데이터에 대해 동시에 여러 개의 요청을 처리합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ac642190",
   "metadata": {
    "executionInfo": {
     "elapsed": 3757,
     "status": "ok",
     "timestamp": 1737459719896,
     "user": {
      "displayName": "Chang Jun Lee",
      "userId": "07449846774346066151"
     },
     "user_tz": -540
    },
    "id": "ac642190"
   },
   "outputs": [],
   "source": [
    "# 문서 목록에 대해 가설 질문을 배치 생성\n",
    "hypothetical_questions = hypothetical_query_chain.batch(\n",
    "    split_docs, {\"max_concurrency\": 10}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "02840bcd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 364,
     "status": "ok",
     "timestamp": 1737459725921,
     "user": {
      "displayName": "Chang Jun Lee",
      "userId": "07449846774346066151"
     },
     "user_tz": -540
    },
    "id": "02840bcd",
    "outputId": "83f18244-1a3e-442a-abaf-d77703a6df88"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['판다스를 사용하여 데이터 분석을 수행할 때 주요 이점은 무엇인가요?',\n",
       " 'GPT 모델이 실제 산업에서 어떻게 활용될 수 있습니까?',\n",
       " 'InstructGPT의 사용이 기존 GPT 모델에 비해 가지는 장점은 무엇인가요?']"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hypothetical_questions[10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f364ded0",
   "metadata": {
    "id": "f364ded0"
   },
   "source": [
    "아래는 이전에 진행했던 방식과 동일하게 생성한 가설 쿼리(Hypothetical Queries) 를 벡터저장소에 저장하는 과정입니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c44404c6",
   "metadata": {
    "executionInfo": {
     "elapsed": 489,
     "status": "ok",
     "timestamp": 1737459729834,
     "user": {
      "displayName": "Chang Jun Lee",
      "userId": "07449846774346066151"
     },
     "user_tz": -540
    },
    "id": "c44404c6"
   },
   "outputs": [],
   "source": [
    "# 자식 청크를 인덱싱하는 데 사용할 벡터 저장소\n",
    "hypothetical_vectorstore = Chroma(\n",
    "    collection_name=\"hypo-questions\", embedding_function=OpenAIEmbeddings()\n",
    ")\n",
    "# 부모 문서의 저장소 계층\n",
    "store = InMemoryStore()\n",
    "\n",
    "id_key = \"doc_id\"\n",
    "# 검색기 (시작 시 비어 있음)\n",
    "retriever = MultiVectorRetriever(\n",
    "    vectorstore=hypothetical_vectorstore,\n",
    "    byte_store=store,\n",
    "    id_key=id_key,\n",
    ")\n",
    "doc_ids = [str(uuid.uuid4()) for _ in split_docs]  # 문서 ID 생성"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8f8a6b7",
   "metadata": {
    "id": "a8f8a6b7"
   },
   "source": [
    "`question_docs` 리스트에 메타데이터(문서 ID) 를 추가합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a7cbb65e",
   "metadata": {
    "executionInfo": {
     "elapsed": 261,
     "status": "ok",
     "timestamp": 1737459733203,
     "user": {
      "displayName": "Chang Jun Lee",
      "userId": "07449846774346066151"
     },
     "user_tz": -540
    },
    "id": "a7cbb65e"
   },
   "outputs": [],
   "source": [
    "question_docs = []\n",
    "# hypothetical_questions 저장\n",
    "for i, question_list in enumerate(hypothetical_questions):\n",
    "    question_docs.extend(\n",
    "        # 질문 리스트의 각 질문에 대해 Document 객체를 생성하고, 메타데이터에 해당 질문의 문서 ID를 포함시킵니다.\n",
    "        [Document(page_content=s, metadata={id_key: doc_ids[i]}) for s in question_list]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "480a8e5f",
   "metadata": {
    "id": "480a8e5f"
   },
   "source": [
    "가설 쿼리를 문서에 추가하고, 원본 문서를 `docstore` 에 추가합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "105ecf34",
   "metadata": {
    "executionInfo": {
     "elapsed": 1118,
     "status": "ok",
     "timestamp": 1737459736654,
     "user": {
      "displayName": "Chang Jun Lee",
      "userId": "07449846774346066151"
     },
     "user_tz": -540
    },
    "id": "105ecf34"
   },
   "outputs": [],
   "source": [
    "# hypothetical_questions 문서를 벡터 저장소에 추가합니다.\n",
    "retriever.vectorstore.add_documents(question_docs)\n",
    "\n",
    "# 문서 ID와 문서를 매핑하여 문서 저장소에 저장합니다.\n",
    "retriever.docstore.mset(list(zip(doc_ids, split_docs)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "badb5835",
   "metadata": {
    "id": "badb5835"
   },
   "source": [
    "`vectorstore` 객체의 `similarity_search` 메서드를 사용하여 유사도 검색을 수행합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ca9afb0a",
   "metadata": {
    "executionInfo": {
     "elapsed": 360,
     "status": "ok",
     "timestamp": 1737459738584,
     "user": {
      "displayName": "Chang Jun Lee",
      "userId": "07449846774346066151"
     },
     "user_tz": -540
    },
    "id": "ca9afb0a"
   },
   "outputs": [],
   "source": [
    "# 유사한 문서를 벡터 저장소에서 검색합니다.\n",
    "result_docs = hypothetical_vectorstore.similarity_search(\n",
    "    \"삼성전자가 만든 생성형 AI 의 이름은?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2ce41e6",
   "metadata": {
    "id": "f2ce41e6"
   },
   "source": [
    "아래는 유사도 검색 결과입니다.\n",
    "\n",
    "여기서는 생성한 가설 쿼리만 추가해 놓은 상태이기 때문에, 생성한 가설 쿼리 중 유사도가 가장 높은 문서를 반환합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "10c33bb4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 266,
     "status": "ok",
     "timestamp": 1737459741162,
     "user": {
      "displayName": "Chang Jun Lee",
      "userId": "07449846774346066151"
     },
     "user_tz": -540
    },
    "id": "10c33bb4",
    "outputId": "bb31a447-778b-4fe9-b2fc-dc8ddbb41798"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "벡터스토어를 활용하여 AI 모델의 검색 효율성을 높이는 방법은 무엇인가요?\n",
      "{'doc_id': '2070586e-482d-44a1-82e7-6730f1620df2'}\n",
      "사용자가 입력한 키워드에 따라 인공지능이 정보를 더 잘 식별하고 제공하기 위해 어떤 방법들이 사용될 수 있을까요?\n",
      "{'doc_id': '6a68eb12-b8b8-4480-801e-3bcdadb196e6'}\n",
      "자연어 처리와 벡터스토어의 결합이 AI 산업에 미치는 영향은 어떤 것들이 있을까요?\n",
      "{'doc_id': '2070586e-482d-44a1-82e7-6730f1620df2'}\n",
      "인공지능을 활용한 자연어 처리 기술의 발전이 검색 엔진의 결과 순위에 미치는 영향은 무엇인가요?\n",
      "{'doc_id': '6a68eb12-b8b8-4480-801e-3bcdadb196e6'}\n"
     ]
    }
   ],
   "source": [
    "# 유사도 검색 결과를 출력합니다.\n",
    "for doc in result_docs:\n",
    "    print(doc.page_content)\n",
    "    print(doc.metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b88722c7",
   "metadata": {
    "id": "b88722c7"
   },
   "source": [
    "`retriever` 객체의 `invoke` 메서드를 사용하여 쿼리와 관련된 문서를 검색합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d106a8d0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 280,
     "status": "ok",
     "timestamp": 1737459743954,
     "user": {
      "displayName": "Chang Jun Lee",
      "userId": "07449846774346066151"
     },
     "user_tz": -540
    },
    "id": "d106a8d0",
    "outputId": "812082f5-0eac-496f-9296-74cffa23b827"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예시: 사용자가 \"이메일 초안 작성\"과 같은 특정 지시를 제공하면,\n",
      "InstructGPT는 관련 내용을 기반으로 이메일을 작성합니다.\n",
      "연관키워드: 인공지능, 자연어 이해, 명령 기반 처리\n",
      "Keyword Search\n",
      "정의: 키워드 검색은 사용자가 입력한 키워드를 기반으로 정보를\n",
      "찾는 과정입니다. 이는 대부분의 검색 엔진과 데이터베이스 시스템\n",
      "에서 기본적인 검색 방식으로 사용됩니다.\n",
      "예시: 사용자가 \"커피숍 서울\"이라고 검색하면, 관련된 커피숍 목\n",
      "록을 반환합니다.\n",
      "연관키워드: 검색 엔진, 데이터 검색, 정보 검색\n",
      "Page Rank\n",
      "정의: 페이지 랭크는 웹 페이지의 중요도를 평가하는 알고리즘으\n",
      "로, 주로 검색 엔진 결과의 순위를 결정하는 데 사용됩니다. 이는\n",
      "데이터의 예입니다.\n",
      "연관키워드: 데이터베이스, 데이터 분석, 데이터 모델링\n",
      "Parser\n",
      "정의: 파서는 주어진 데이터(문자열, 파일 등)를 분석하여 구조화\n",
      "된 형태로 변환하는 도구입니다. 이는 프로그래밍 언어의 구문 분\n",
      "석이나 파일 데이터 처리에 사용됩니다.\n",
      "예시: HTML 문서를 구문 분석하여 웹 페이지의 DOM 구조를 생성하\n",
      "는 것은 파싱의 한 예입니다.\n",
      "연관키워드: 구문 분석, 컴파일러, 데이터 처리\n",
      "TF-IDF (Term Frequency-Inverse Document Frequency)\n",
      "정의: TF-IDF는 문서 내에서 단어의 중요도를 평가하는 데 사용되\n",
      "다. 이는 자연어 처리에서 데이터를 전처리하는 데 사용됩니다.\n",
      "예시: \"I love programming.\"이라는 문장을 [\"I\", \"love\",\n",
      "\"programming\", \".\"]으로 분할합니다.\n",
      "연관키워드: 토큰화, 자연어 처리, 구문 분석\n",
      "VectorStore\n",
      "정의: 벡터스토어는 벡터 형식으로 변환된 데이터를 저장하는 시스\n",
      "템입니다. 이는 검색, 분류 및 기타 데이터 분석 작업에 사용됩니\n",
      "다.\n",
      "예시: 단어 임베딩 벡터들을 데이터베이스에 저장하여 빠르게 접근\n"
     ]
    }
   ],
   "source": [
    "# 관련된 문서를 검색하여 가져옵니다.\n",
    "retrieved_docs = retriever.invoke(result_docs[1].page_content)\n",
    "\n",
    "# 검색된 문서를 출력합니다.\n",
    "for doc in retrieved_docs:\n",
    "    print(doc.page_content)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "py-test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
