{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install -qU PyPDF2"
      ],
      "metadata": {
        "id": "evFC3K4NGwA9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xeJJf6IoE6Iq",
        "outputId": "2c14fffe-6971-4fbd-f70b-8e5cb0cc636c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ARTIFICIAL INTELLIGENCE -DRIVEN CLINICAL DECISION\n",
            "SUPPORT SYSTEMS\n",
            "A P REPRINT\n",
            "Muhammet Alkan\n",
            "School of Computing Science\n",
            "University of Glasgow\n",
            "Glasgow, Scotland, UKIdris Zakariyya\n",
            "School of Computing Science\n",
            "University of Glasgow\n",
            "Glasgow, Scotland, UKSamuel Leighton\n",
            "School of Health and Well Being\n",
            "University of Glasgow\n",
            "Glasgow, Scotland, UK\n",
            "Kaushik Bhargav Sivangi\n",
            "School of Computing Science\n",
            "University of Glasgow\n",
            "Glasgow, Scotland, UKChristos Anagnostopoulos\n",
            "School of Computing Science\n",
            "University of Glasgow\n",
            "Glasgow, Scotland, UKFani Deligianni∗\n",
            "School of Computing Science\n",
            "University of Glasgow\n",
            "Glasgow, Scotland, UK\n",
            "Fani.Deligianni@glasgow.ac.uk\n",
            "January 17, 2025\n",
            "“The advance of technology is based on making it fit in so that you don’t really even notice it, so it’s\n",
            "part of everyday life.” — Bill Gates\n",
            "ABSTRACT\n",
            "As artificial intelligence (AI) becomes increasingly embedded in healthcare delivery, this chapter\n",
            "explores the critical aspects of developing reliable and ethical Clinical Decision Support Systems\n",
            "(CDSS). Beginning with the fundamental transition from traditional statistical models to sophisticated\n",
            "machine learning approaches, this work examines rigorous validation strategies and performance\n",
            "assessment methods, including the crucial role of model calibration and decision curve analysis.\n",
            "The chapter emphasizes that creating trustworthy AI systems in healthcare requires more than just\n",
            "technical accuracy; it demands careful consideration of fairness, explainability, and privacy. The\n",
            "challenge of ensuring equitable healthcare delivery through AI is stressed, discussing methods to\n",
            "identify and mitigate bias in clinical predictive models. The chapter then delves into explainability\n",
            "as a cornerstone of human-centered CDSS. This focus reflects the understanding that healthcare\n",
            "professionals must not only trust AI recommendations but also comprehend their underlying reasoning.\n",
            "The discussion advances in an analysis of privacy vulnerabilities in medical AI systems, from data\n",
            "leakage in deep learning models to sophisticated attacks against model explanations. The text\n",
            "explores privacy-preservation strategies such as differential privacy and federated learning, while\n",
            "acknowledging the inherent trade-offs between privacy protection and model performance. This\n",
            "progression, from technical validation to ethical considerations, reflects the multifaceted challenges\n",
            "of developing AI systems that can be seamlessly and reliably integrated into daily clinical practice\n",
            "while maintaining the highest standards of patient care and data protection.\n",
            "Keywords CDSS ·AI·ML·explainability ·fairness ·privacy-preservation ·probability calibration ·decision curve\n",
            "analysis\n",
            "∗Corresponding author, Fani DeligianniarXiv:2501.09628v1  [cs.AI]  16 Jan 2025Artificial Intelligence-Driven Clinical Decision Support Systems A P REPRINT\n",
            "1 Artificial Intelligence-Driven Clinical Decision Support Systems\n",
            "1.1 From machine learning and statistical models to clinical decision support systems: An Overview\n",
            "Clinical research demands a meticulous, multifaceted approach when evaluating predictive models, which extends\n",
            "beyond the traditional data science perspective. As we dive into this complex landscape, we must consider a series\n",
            "of key questions that shape the development and validation of machine learning models, ultimately determining their\n",
            "suitability as decision support systems in healthcare.\n",
            "In prediction modeling, our main focus is on estimating the risk of adverse events based on a combination of factors. We\n",
            "seek to understand not only the predictive power of these factors, but also their individual contributions to the model’s\n",
            "decision-making process. This understanding is crucial, as it allows us to incorporate subject matter knowledge into the\n",
            "modeling pipeline, bridging the gap between data-driven insights and clinical expertise.\n",
            "The foundations of the clinical prediction model validation process have been presented in Steyerberg [Steyerberg\n",
            "and Vergouwe, 2014]. At the heart of this process lies the fundamental research question or hypothesis. For example,\n",
            "the choice of prediction outcome is paramount in clinical research. Outcomes such as mortality rates at 30 days are\n",
            "frequently relevant to various research questions. However, it’s not just the nature of the outcome that matters, but also\n",
            "its frequency within the dataset. This frequency effectively determines the sample size, which in turn influences the\n",
            "statistical power and reliability of the model.\n",
            "The selection of patient data for the development of the model is a critical consideration. Often, these data are collected\n",
            "for purposes other than the study at hand, raising questions about their representativeness. We must carefully examine\n",
            "whether patient records truly reflect the population for which the study is intended. Additionally, the treatment of\n",
            "prognostic factors and their effects presents a unique challenge. Although traditional studies often consider treatment\n",
            "effects negligible compared to prognostic factors, there are instances where these effects warrant specific attention.\n",
            "Adjusting for baseline prognostic factors can offer significant advantages in estimating treatment effects applicable to\n",
            "individual patients.\n",
            "The reliability and completeness of the predictor measurements pose another hurdle in model development. Incomplete\n",
            "datasets are common, with missing values for potential predictors. The approach to handling these missing data can\n",
            "significantly impact the model’s performance and validity. Although complete case analysis – excluding patients with\n",
            "missing values – is a straightforward solution, it often results in the loss of significant information. More sophisticated\n",
            "methods, such as imputation techniques that leverage correlations between variables, offer a more nuanced approach to\n",
            "preserving data integrity. In addition, informative missingness, where the fact that data are missing is related to the\n",
            "outcome of interest, must be carefully considered to avoid biased results.\n",
            "As we navigate these considerations, we recognize that the development of machine learning models for clinical decision\n",
            "support systems is a multifaceted process. It requires a delicate balance between statistical rigor, clinical relevance, and\n",
            "practical applicability. By addressing these key questions and challenges, we pave the way for more robust and reliable\n",
            "predictive models that can enhance clinical decision-making and, ultimately, patient care.\n",
            "1.2 A Quick Overview of Model Development and Validation Strategies of Machine Learning Models\n",
            "Figure 1: Model Development\n",
            "Model evaluation and selection are critical steps in the machine learning development process. In an ideal scenario, we\n",
            "would have access to data that perfectly represents the entire target population. In this case, we could train and test the\n",
            "2Artificial Intelligence-Driven Clinical Decision Support Systems A P REPRINT\n",
            "machine learning model using the same data, and the error rate obtained would closely reflect the true error rate when\n",
            "the number of samples is very large. However, in reality, the error rate obtained when training and testing on the same\n",
            "dataset is positively biased. This is because the model has been exposed to the same data during both the training and\n",
            "testing phases, which can lead to an overly optimistic estimate of its performance. To address this issue, in real-world\n",
            "applications, it is important to split the available data into two separate sets: a training set and a testing set. Typically,\n",
            "around 70% of the data is used for training the model, while the remaining 30% is reserved for testing its performance\n",
            "on unseen examples. By separating the training and testing data, we can evaluate the model’s ability to make accurate\n",
            "predictions on new, unseen data, which is crucial for deploying the model in real-world applications.\n",
            "In most cases, we estimate the empirical risk based on a limited number of samples. This involves measuring the loss\n",
            "function with respect to our trained classifier, as discussed in [Japkowicz and Shah, 2011]. Empirical risk estimation is\n",
            "achieved by computing the average loss over the data points ( mis the number of samples) according to a loss function\n",
            "L, which penalizes the differences between the predicted values f(x)and the actual targets y:\n",
            "RS(f) =1\n",
            "mmX\n",
            "i=1L(yi, f(xi)) (1)\n",
            "Variations in the empirical risk estimation can arise from several factors. These include random variations in the training\n",
            "and testing sets, the learning algorithm itself, and even the noise inherent in the data classes being considered. One\n",
            "key advantage of the hold-out method (where the training and testing sets are independent) is that it provides some\n",
            "guarantees about the model’s performance on data it has not been trained on before. However, we must also consider the\n",
            "confidence intervals around the empirical risk estimation. For example, when evaluating a machine learning algorithm,\n",
            "we should not assume a Gaussian distribution of the loss error, as the errors may be clustered near zero.\n",
            "The error can be modeled using the Bernoulli distribution to calculate the error bound, Equation 2, providing an\n",
            "indication of the potential deviation between the empirical risk estimation and the true risk with a probability of\n",
            "accuracy of ( 1−δ). In Equation 2, m′represents the sample size and δrepresents the confidence parameter, which\n",
            "quantifies the probability that our estimate is accurate.\n",
            "E=r\n",
            "1\n",
            "2m′ln(2\n",
            "δ) (2)\n",
            "Thek-fold cross-validation is one of the most popular error estimation approaches in machine learning model training\n",
            "and evaluation. In this method, the dataset is divided into kdistinct parts or \"folds\" like in Figure 2. During each\n",
            "iteration, one of these folds is reserved for testing, while the remaining ( k−1) folds are used for training the model.\n",
            "This process is repeated ktimes, with a different fold serving as the test set each time. By doing so, we obtain k\n",
            "separate estimates of the classifier’s error rate. These estimates can then be averaged to give the mean performance of\n",
            "the algorithm across the different folds. Examining the variability of the error estimates across the kiterations can also\n",
            "provide valuable insights into the algorithm’s stability and robustness. A key advantage of k-fold cross-validation is\n",
            "that the test samples are independent between the different folds, as there is no overlap. This helps to ensure a more\n",
            "reliable and unbiased assessment of the model’s generalization capabilities.\n",
            "A potential issue that can arise with standard k-fold cross-validation is that the data may not be evenly distributed\n",
            "across classes. This problem becomes worse when dealing with imbalanced class data, which is common in healthcare\n",
            "applications. To address this, we can employ a technique called stratified k- fold cross validation. In this approach,\n",
            "the folds are created in a way that ensures the class distribution within each fold closely matches the original class\n",
            "distribution in the overall dataset.\n",
            "A special case of k-fold cross-validation is leave-one-out cross validation (LOOCV). In this case, the value kis set to\n",
            "the number of samples in the dataset, meaning that each sample is used as the test set once while the remaining ( k−1)\n",
            "samples are used for training. LOOCV has the advantage of utilising most of the available data, which can result in\n",
            "relatively unbiased estimate of the model’s performance. However, this comes at the cost of significant computational\n",
            "expense, especially as the dataset size grows. Although, LOOCV may provide better performance estimates in datasets\n",
            "with extreme values, it is important to note that this is not a guarantee of an unbiased classifier, especially when dealing\n",
            "with small datasets. The underlying assumption of LOOCV is that the training set is representative of the true data\n",
            "distribution, which may not always hold.\n",
            "One key aspect of validation techniques such as k-fold cross-validation and LOOCV is that the estimate is not based\n",
            "on a single, fixed classifier. Instead, the model is retrained each time, producing a new classifier with each iteration.\n",
            "This approach has both advantages and disadvantages. The primary advantage is that it allows us to assess the stability\n",
            "of machine learning models across different data partitions. However, the disadvantage is that when comparing the\n",
            "3\n"
          ]
        }
      ],
      "source": [
        "import PyPDF2\n",
        "\n",
        "texts = \"\".join([page.extract_text() for page in PyPDF2.PdfReader(\"/content/2501.pdf\").pages])\n",
        "print(texts)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cleaned_text = texts.replace('\\n', ' ').strip()\n",
        "cleaned_text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        },
        "id": "iIO0CMyUGtv5",
        "outputId": "95a427bc-c04d-4c39-9ddd-205f4e6e2f56"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'ARTIFICIAL INTELLIGENCE -DRIVEN CLINICAL DECISION SUPPORT SYSTEMS A P REPRINT Muhammet Alkan School of Computing Science University of Glasgow Glasgow, Scotland, UKIdris Zakariyya School of Computing Science University of Glasgow Glasgow, Scotland, UKSamuel Leighton School of Health and Well Being University of Glasgow Glasgow, Scotland, UK Kaushik Bhargav Sivangi School of Computing Science University of Glasgow Glasgow, Scotland, UKChristos Anagnostopoulos School of Computing Science University of Glasgow Glasgow, Scotland, UKFani Deligianni∗ School of Computing Science University of Glasgow Glasgow, Scotland, UK Fani.Deligianni@glasgow.ac.uk January 17, 2025 “The advance of technology is based on making it fit in so that you don’t really even notice it, so it’s part of everyday life.” — Bill Gates ABSTRACT As artificial intelligence (AI) becomes increasingly embedded in healthcare delivery, this chapter explores the critical aspects of developing reliable and ethical Clinical Decision Support Systems (CDSS). Beginning with the fundamental transition from traditional statistical models to sophisticated machine learning approaches, this work examines rigorous validation strategies and performance assessment methods, including the crucial role of model calibration and decision curve analysis. The chapter emphasizes that creating trustworthy AI systems in healthcare requires more than just technical accuracy; it demands careful consideration of fairness, explainability, and privacy. The challenge of ensuring equitable healthcare delivery through AI is stressed, discussing methods to identify and mitigate bias in clinical predictive models. The chapter then delves into explainability as a cornerstone of human-centered CDSS. This focus reflects the understanding that healthcare professionals must not only trust AI recommendations but also comprehend their underlying reasoning. The discussion advances in an analysis of privacy vulnerabilities in medical AI systems, from data leakage in deep learning models to sophisticated attacks against model explanations. The text explores privacy-preservation strategies such as differential privacy and federated learning, while acknowledging the inherent trade-offs between privacy protection and model performance. This progression, from technical validation to ethical considerations, reflects the multifaceted challenges of developing AI systems that can be seamlessly and reliably integrated into daily clinical practice while maintaining the highest standards of patient care and data protection. Keywords CDSS ·AI·ML·explainability ·fairness ·privacy-preservation ·probability calibration ·decision curve analysis ∗Corresponding author, Fani DeligianniarXiv:2501.09628v1  [cs.AI]  16 Jan 2025Artificial Intelligence-Driven Clinical Decision Support Systems A P REPRINT 1 Artificial Intelligence-Driven Clinical Decision Support Systems 1.1 From machine learning and statistical models to clinical decision support systems: An Overview Clinical research demands a meticulous, multifaceted approach when evaluating predictive models, which extends beyond the traditional data science perspective. As we dive into this complex landscape, we must consider a series of key questions that shape the development and validation of machine learning models, ultimately determining their suitability as decision support systems in healthcare. In prediction modeling, our main focus is on estimating the risk of adverse events based on a combination of factors. We seek to understand not only the predictive power of these factors, but also their individual contributions to the model’s decision-making process. This understanding is crucial, as it allows us to incorporate subject matter knowledge into the modeling pipeline, bridging the gap between data-driven insights and clinical expertise. The foundations of the clinical prediction model validation process have been presented in Steyerberg [Steyerberg and Vergouwe, 2014]. At the heart of this process lies the fundamental research question or hypothesis. For example, the choice of prediction outcome is paramount in clinical research. Outcomes such as mortality rates at 30 days are frequently relevant to various research questions. However, it’s not just the nature of the outcome that matters, but also its frequency within the dataset. This frequency effectively determines the sample size, which in turn influences the statistical power and reliability of the model. The selection of patient data for the development of the model is a critical consideration. Often, these data are collected for purposes other than the study at hand, raising questions about their representativeness. We must carefully examine whether patient records truly reflect the population for which the study is intended. Additionally, the treatment of prognostic factors and their effects presents a unique challenge. Although traditional studies often consider treatment effects negligible compared to prognostic factors, there are instances where these effects warrant specific attention. Adjusting for baseline prognostic factors can offer significant advantages in estimating treatment effects applicable to individual patients. The reliability and completeness of the predictor measurements pose another hurdle in model development. Incomplete datasets are common, with missing values for potential predictors. The approach to handling these missing data can significantly impact the model’s performance and validity. Although complete case analysis – excluding patients with missing values – is a straightforward solution, it often results in the loss of significant information. More sophisticated methods, such as imputation techniques that leverage correlations between variables, offer a more nuanced approach to preserving data integrity. In addition, informative missingness, where the fact that data are missing is related to the outcome of interest, must be carefully considered to avoid biased results. As we navigate these considerations, we recognize that the development of machine learning models for clinical decision support systems is a multifaceted process. It requires a delicate balance between statistical rigor, clinical relevance, and practical applicability. By addressing these key questions and challenges, we pave the way for more robust and reliable predictive models that can enhance clinical decision-making and, ultimately, patient care. 1.2 A Quick Overview of Model Development and Validation Strategies of Machine Learning Models Figure 1: Model Development Model evaluation and selection are critical steps in the machine learning development process. In an ideal scenario, we would have access to data that perfectly represents the entire target population. In this case, we could train and test the 2Artificial Intelligence-Driven Clinical Decision Support Systems A P REPRINT machine learning model using the same data, and the error rate obtained would closely reflect the true error rate when the number of samples is very large. However, in reality, the error rate obtained when training and testing on the same dataset is positively biased. This is because the model has been exposed to the same data during both the training and testing phases, which can lead to an overly optimistic estimate of its performance. To address this issue, in real-world applications, it is important to split the available data into two separate sets: a training set and a testing set. Typically, around 70% of the data is used for training the model, while the remaining 30% is reserved for testing its performance on unseen examples. By separating the training and testing data, we can evaluate the model’s ability to make accurate predictions on new, unseen data, which is crucial for deploying the model in real-world applications. In most cases, we estimate the empirical risk based on a limited number of samples. This involves measuring the loss function with respect to our trained classifier, as discussed in [Japkowicz and Shah, 2011]. Empirical risk estimation is achieved by computing the average loss over the data points ( mis the number of samples) according to a loss function L, which penalizes the differences between the predicted values f(x)and the actual targets y: RS(f) =1 mmX i=1L(yi, f(xi)) (1) Variations in the empirical risk estimation can arise from several factors. These include random variations in the training and testing sets, the learning algorithm itself, and even the noise inherent in the data classes being considered. One key advantage of the hold-out method (where the training and testing sets are independent) is that it provides some guarantees about the model’s performance on data it has not been trained on before. However, we must also consider the confidence intervals around the empirical risk estimation. For example, when evaluating a machine learning algorithm, we should not assume a Gaussian distribution of the loss error, as the errors may be clustered near zero. The error can be modeled using the Bernoulli distribution to calculate the error bound, Equation 2, providing an indication of the potential deviation between the empirical risk estimation and the true risk with a probability of accuracy of ( 1−δ). In Equation 2, m′represents the sample size and δrepresents the confidence parameter, which quantifies the probability that our estimate is accurate. E=r 1 2m′ln(2 δ) (2) Thek-fold cross-validation is one of the most popular error estimation approaches in machine learning model training and evaluation. In this method, the dataset is divided into kdistinct parts or \"folds\" like in Figure 2. During each iteration, one of these folds is reserved for testing, while the remaining ( k−1) folds are used for training the model. This process is repeated ktimes, with a different fold serving as the test set each time. By doing so, we obtain k separate estimates of the classifier’s error rate. These estimates can then be averaged to give the mean performance of the algorithm across the different folds. Examining the variability of the error estimates across the kiterations can also provide valuable insights into the algorithm’s stability and robustness. A key advantage of k-fold cross-validation is that the test samples are independent between the different folds, as there is no overlap. This helps to ensure a more reliable and unbiased assessment of the model’s generalization capabilities. A potential issue that can arise with standard k-fold cross-validation is that the data may not be evenly distributed across classes. This problem becomes worse when dealing with imbalanced class data, which is common in healthcare applications. To address this, we can employ a technique called stratified k- fold cross validation. In this approach, the folds are created in a way that ensures the class distribution within each fold closely matches the original class distribution in the overall dataset. A special case of k-fold cross-validation is leave-one-out cross validation (LOOCV). In this case, the value kis set to the number of samples in the dataset, meaning that each sample is used as the test set once while the remaining ( k−1) samples are used for training. LOOCV has the advantage of utilising most of the available data, which can result in relatively unbiased estimate of the model’s performance. However, this comes at the cost of significant computational expense, especially as the dataset size grows. Although, LOOCV may provide better performance estimates in datasets with extreme values, it is important to note that this is not a guarantee of an unbiased classifier, especially when dealing with small datasets. The underlying assumption of LOOCV is that the training set is representative of the true data distribution, which may not always hold. One key aspect of validation techniques such as k-fold cross-validation and LOOCV is that the estimate is not based on a single, fixed classifier. Instead, the model is retrained each time, producing a new classifier with each iteration. This approach has both advantages and disadvantages. The primary advantage is that it allows us to assess the stability of machine learning models across different data partitions. However, the disadvantage is that when comparing the 3'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "HuggingFace Endpoint Embedding"
      ],
      "metadata": {
        "id": "f3ekczsgNzaL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -qU langchain_huggingface"
      ],
      "metadata": {
        "id": "wZOsea4DN1xO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -qU huggingface_hub"
      ],
      "metadata": {
        "id": "4pDAvHp5Tacp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_huggingface.embeddings import HuggingFaceEndpointEmbeddings\n",
        "\n",
        "model_name = \"intfloat/multilingual-e5-large-instruct\"\n",
        "\n",
        "hf_embeddings = HuggingFaceEndpointEmbeddings(\n",
        "    model=model_name,\n",
        "    task=\"feature-extraction\",\n",
        "    huggingfacehub_api_token=\"\",\n",
        ")\n",
        "\n",
        "%time\n",
        "embedded_documents = hf_embeddings.embed_documents(texts)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "4WvCrs08HMu1",
        "outputId": "1acda409-2c2f-49a1-b2da-e8b8694e51b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 3 µs, sys: 0 ns, total: 3 µs\n",
            "Wall time: 6.68 µs\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "HfHubHTTPError",
          "evalue": "504 Server Error: Gateway Time-out for url: https://api-inference.huggingface.co/pipeline/feature-extraction/intfloat/multilingual-e5-large-instruct",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_http.py\u001b[0m in \u001b[0;36mhf_raise_for_status\u001b[0;34m(response, endpoint_name)\u001b[0m\n\u001b[1;32m    405\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 406\u001b[0;31m         \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_for_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    407\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mHTTPError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/requests/models.py\u001b[0m in \u001b[0;36mraise_for_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1023\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhttp_error_msg\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1024\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mHTTPError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhttp_error_msg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mHTTPError\u001b[0m: 504 Server Error: Gateway Time-out for url: https://api-inference.huggingface.co/pipeline/feature-extraction/intfloat/multilingual-e5-large-instruct",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mHfHubHTTPError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-df51bd07918f>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'time'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0membedded_documents\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhf_embeddings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed_documents\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_huggingface/embeddings/huggingface_endpoint.py\u001b[0m in \u001b[0;36membed_documents\u001b[0;34m(self, texts)\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0m_model_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_kwargs\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0;31m#  api doc: https://huggingface.github.io/text-embeddings-inference/#/Text%20Embeddings%20Inference/embed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m         responses = self.client.post(\n\u001b[0m\u001b[1;32m    113\u001b[0m             \u001b[0mjson\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"inputs\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtexts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0m_model_kwargs\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/huggingface_hub/inference/_client.py\u001b[0m in \u001b[0;36mpost\u001b[0;34m(self, json, data, model, task, stream)\u001b[0m\n\u001b[1;32m    304\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 306\u001b[0;31m                 \u001b[0mhf_raise_for_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    307\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mstream\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mHTTPError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_http.py\u001b[0m in \u001b[0;36mhf_raise_for_status\u001b[0;34m(response, endpoint_name)\u001b[0m\n\u001b[1;32m    475\u001b[0m         \u001b[0;31m# Convert `HTTPError` into a `HfHubHTTPError` to display request information\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;31m# as well (request id and/or server error message)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0m_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mHfHubHTTPError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mHfHubHTTPError\u001b[0m: 504 Server Error: Gateway Time-out for url: https://api-inference.huggingface.co/pipeline/feature-extraction/intfloat/multilingual-e5-large-instruct"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "v0CYPl4ON56C"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}