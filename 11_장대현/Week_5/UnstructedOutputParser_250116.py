# -*- coding: utf-8 -*-
"""UnstructedOutputParser_250116.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1xkaWNMqYLFZkeZqeduLmJP1qkCLTcUn2
"""

!pip install -qU langchain_openai

from langchain.output_parsers import ResponseSchema, StructuredOutputParser
from langchain_core.prompts import PromptTemplate
from langchain_openai import ChatOpenAI

# 사용자의 질문에 대한 답변
response_schemas = [
    ResponseSchema(name = "answer", description = "사용자의 질문에 대한 답변"),
    ResponseSchema(name = "source", description = "사용자의 질문에 답하기 위해 사용된 '출처', '웹사이트 주소' 이어야 합니다."),
]

response_schemas

output_parser = StructuredOutputParser.from_response_schemas(response_schemas)

# 출력 형식 지시사항을 파싱
format_instructions = output_parser.get_format_instructions()

prompt = PromptTemplate(

    # 사용자의 질문에 최대한 답변하도록 템플릿을 설정
    template = """answer the users question as best as possible.
    {format_instructions}
    {question}""",

    # 입력 변수로 'question' 사용
    input_variables = ["question"],

    # 부분 변수로 'format_instructions' 사용
    partial_variables = {"format_instructions": format_instructions},
)

prompt

model = ChatOpenAI(temperature = 0, model = 'gpt-4o')

chain = prompt | model | output_parser

response = chain.invoke({"question": "지구가 멸망할 시기는?"})

print(response)