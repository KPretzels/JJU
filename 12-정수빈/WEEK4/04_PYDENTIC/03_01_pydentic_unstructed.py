# -*- coding: utf-8 -*-
"""03-01 pydentic-unstructed.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/15XYgsaPtCXENnYsxMIK09CmM7bwJZCcN
"""

import os

os.environ["OPENAI_API_KEY"] = ""
os.environ["LANGCHAIN_API_KEY"] = ""
os.environ["LANGCHAIN_TRACING_V2"] = "true"
os.environ["LANGCHAIN_ENDPOINT"] = "https://api.smith.langchain.com"
os.environ["LANGCHAIN_PROJECT"] = "01-06"

import os
from pydantic import BaseModel, Field
from langchain_core.prompts import PromptTemplate
from langchain_openai import ChatOpenAI
from langchain.output_parsers import PydanticOutputParser
from langchain_teddynote.messages import stream_response

# 1. 이메일 구조를 표현하는 Pydantic 모델 정의
class EmailStructure(BaseModel):
    sender: str = Field(description="메일을 보낸 사람")
    recipients: list[str] = Field(description="메일을 받은 사람들")
    cc: list[str] = Field(description="참조로 메일을 받은 사람들")
    content: str = Field(description="메일 본문 내용")
    summary: str = Field(description="메일 본문 내용 요약")
    reply: str = Field(description="회신 내용 작성")
    save_path: str = Field(description="저장 경로")

# 2. PydanticOutputParser 생성
parser = PydanticOutputParser(pydantic_object=EmailStructure)

# 3. 이메일 파일 읽기
email_file = "email.txt"
if not os.path.exists(email_file):
    raise FileNotFoundError(f"{email_file} 파일이 존재하지 않습니다.")

with open(email_file, "r", encoding="utf-8") as f:
    email_conversation = f.read()

# 4. PromptTemplate 생성
prompt = PromptTemplate.from_template(
    """
You are a helpful assistant. Extract the following information from the email in KOREAN:
- 보낸 사람
- 받는 사람들
- 참조로 메일을 받은 사람들
- 메일 본문 내용
- 메일 본문 내용 요약
- 회신 내용 작성
- 저장 경로

EMAIL CONVERSATION:
{email_conversation}

FORMAT:
{format}
"""
)

# PromptTemplate에 PydanticOutputParser의 format 추가
prompt = prompt.partial(format=parser.get_format_instructions())

# 5. LLM 및 체인 생성
llm = ChatOpenAI(temperature=0, model_name="gpt-4o")
chain = prompt | llm

# 6. 실시간 스트림 출력 함수
def stream_response(response, return_output=False):
    answer = ""
    for token in response:
        if isinstance(token, str):
            answer += token
            print(token, end="", flush=True)
        elif hasattr(token, "content"):  # AIMessageChunk 처리
            answer += token.content
            print(token.content, end="", flush=True)
    if return_output:
        return answer

# 7. 체인 실행 및 결과 출력
response = chain.stream(
    {
        "email_conversation": email_conversation,
    }
)

# 8. 실시간 출력 및 최종 결과 반환
output = stream_response(response, return_output=True)

# 9. reply.md 파일로 저장
reply_file = "reply.md"
with open(reply_file, "w", encoding="utf-8") as f:
    f.write(f"# 회신 내용\n\n{output}\n")

print(f"\n\n--- 최종 회신 내용이 '{reply_file}'에 저장되었습니다. ---")