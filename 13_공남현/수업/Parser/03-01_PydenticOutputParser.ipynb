{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1epa2TH2AfYQ"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"\"\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_ENDPOINT\"] = \"https://api.smith.langchain.com\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"03-01\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "krmZvR4BA2E8"
   },
   "outputs": [],
   "source": [
    "pip install -qU langchain_openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9Ph9HuJvBNuj"
   },
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import PydanticOutputParser\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "\n",
    "llm = ChatOpenAI(temperature=0, model_name=\"gpt-4o\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XsvD872pBztL"
   },
   "outputs": [],
   "source": [
    "email_conversation = \"\"\"\n",
    "From: John (John@bikecorporation.me)\n",
    "To: Kim (Kim@teddyinternational.me)\n",
    "Subject: “ZENESIS” bike distribution cooperation and meeting schedule proposal\n",
    "Dear Mr. Kim,\n",
    "\n",
    "I am John, Senior Executive Director at Bike Corporation. I recently learned about your new bicycle model, \"ZENESIS,\" through your press release. Bike Corporation is a company that leads innovation and quality in the field of bicycle manufacturing and distribution, with long-time experience and expertise in this field.\n",
    "\n",
    "We would like to request a detailed brochure for the ZENESIS model. In particular, we need information on technical specifications, battery performance, and design aspects. This information will help us further refine our proposed distribution strategy and marketing plan.\n",
    "\n",
    "Additionally, to discuss the possibilities for collaboration in more detail, I propose a meeting next Tuesday, January 15th, at 10:00 AM. Would it be possible to meet at your office to have this discussion?\n",
    "\n",
    "Thank you.\n",
    "\n",
    "Best regards,\n",
    "John\n",
    "Senior Executive Director\n",
    "Bike Corporation\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_Kewa2fICqdR"
   },
   "source": [
    "## OuputParser를 사용하지 않는 경우"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rZuhS2O4Bz4a"
   },
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "prompt = PromptTemplate.from_template(\n",
    "    \"다음의 이메일 내용중 중요한 내용을 추출해 주세요.\\n\\n{email_conversation}\"\n",
    ")\n",
    "\n",
    "llm = ChatOpenAI(temperature=0, model_name=\"gpt-4o\")\n",
    "\n",
    "chain = prompt | llm\n",
    "\n",
    "answer = chain.stream({\"email_conversation\": email_conversation})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2Ybfy-uKGC9c"
   },
   "outputs": [],
   "source": [
    "def stream_response(response, return_output = False):\n",
    "    \"\"\"\n",
    "    Streams the response from the AI model, processing and printing each chunk.\n",
    "\n",
    "    This function iterates over each item in the 'response' iterable. If an item is an instance of AIMessageChunk, it extracts and prints the content.\n",
    "    If the item is a string, it prints the string directly.\n",
    "    Optionally, the function can return the concatenated string of all response chunks.\n",
    "\n",
    "    Args:\n",
    "    - response (iterable): An iterable of response chunks, which can be AIMessageChunk objects or strings.\n",
    "    - return_output (bool, optional): If True, the function returns the concatenated response string. The default is False.\n",
    "\n",
    "    Returns:\n",
    "    - str: If `return_output` is True, the concatenated response string. Otherwise, nothing is returned.\n",
    "    \"\"\"\n",
    "    answer = \"\"\n",
    "    for token in response:\n",
    "      if isinstance(token, AIMessageChunk):\n",
    "        answer += token.content\n",
    "        print(token.content, end = \"\", flush = True)\n",
    "\n",
    "      elif isinstance(token, str):\n",
    "        answer += token\n",
    "        print(token, end = \"\", flush = True)\n",
    "\n",
    "    if return_output:\n",
    "      return answer\n",
    "\n",
    "output = stream_response(answer, return_output=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fFCkbpNnHAY0"
   },
   "outputs": [],
   "source": [
    "print(output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q7G3dkUVHWL7"
   },
   "source": [
    "## Use Output Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rrfaZuoNHJKT"
   },
   "outputs": [],
   "source": [
    "class EmailSummary(BaseModel):\n",
    "    person: str = Field(description=\"The sender of the email\")\n",
    "    email: str = Field(description=\"The sender's email address\")\n",
    "    subject: str = Field(description=\"The subject of the email\")\n",
    "    summary: str = Field(description=\"A summary of the email body\")\n",
    "    is_spam: bool = Field(description=\"Whether the email is spam or not, 만약 '스팸'이 아니면 'not spam'이라고 입력해\")\n",
    "    date: str = Field(description=\"The meeting date and time mentioned in the email body\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UAEobswzHJUr"
   },
   "outputs": [],
   "source": [
    "# PydanticOutputParser 생성\n",
    "parser = PydanticOutputParser(pydantic_object=EmailSummary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YD4nJjUkKXuM"
   },
   "source": [
    "## Prompt 제작"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6zNnsTlQKaEI"
   },
   "outputs": [],
   "source": [
    "prompt = PromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "You are a helpful assistant. Please answer the following questions in KOREAN.\n",
    "\n",
    "QUESTION:\n",
    "{question}\n",
    "\n",
    "EMAIL CONVERSATION:\n",
    "{email_conversation}\n",
    "\n",
    "FORMAT:\n",
    "{format}\n",
    "\"\"\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SLmMUTcGKfWW"
   },
   "outputs": [],
   "source": [
    "\n",
    "# format 에 PydanticOutputParser의 부분 포맷팅(partial) 추가\n",
    "prompt = prompt.partial(format=parser.get_format_instructions())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J7asGgIRSKuH"
   },
   "outputs": [],
   "source": [
    "# chain 을 생성합니다.\n",
    "chain = prompt | llm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X3W75C12Khnu"
   },
   "outputs": [],
   "source": [
    "# chain 을 실행하고 결과를 출력합니다.\n",
    "response = chain.stream(\n",
    "    {\n",
    "        \"email_conversation\": email_conversation,\n",
    "        \"question\": \"이메일 내용중 주요 내용을 추출해 주세요.\",\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DtZaOZdISPcm"
   },
   "outputs": [],
   "source": [
    "output = stream_response(response, return_output=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TTIQaDEgUP4t"
   },
   "outputs": [],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5s9_CKNFUyGL"
   },
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNtBeHbI4SNrmtBslp9MoLr",
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
