{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from datetime import datetime\n",
    "\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_openai.embeddings import OpenAIEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_upstage import UpstageDocumentParseLoader # 위키독스 따라가면 안됨.\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prossed_document(file_path):\n",
    "    loader = UpstageDocumentParseLoader(file_path=file_path, output_format=\"html\", split=\"element\", ocr=\"force\", coordinates=False,)\n",
    "    docs = loader.load()\n",
    "    metadata = {\"source\": file_path, \"date\": datetime.now().isoformat()}\n",
    "    if metadata:\n",
    "        for doc in docs:\n",
    "            if hasattr(doc, \"metadata\"):  # 문서에 metadata 속성이 있는지 확인\n",
    "                doc.metadata.update(metadata)  # 메타데이터 업데이트\n",
    "            else:\n",
    "                doc.metadata = metadata  # 새로운 메타데이터 추가\n",
    "\n",
    "    return docs\n",
    "\n",
    "def create_db(DB_PATH, documents, embedding=OpenAIEmbeddings(model=\"text-embedding-3-small\"), name=\"db\"):\n",
    "    db = Chroma.from_documents(\n",
    "    documents=documents, persist_directory=DB_PATH, embedding=embedding, collection_name=name\n",
    "    )\n",
    "    return db \n",
    "\n",
    "def add_data(db, documents):\n",
    "    db.add_documents(documents)\n",
    "\n",
    "def dorp_data(db, ids):\n",
    "    db.delete(ids=ids)\n",
    "\n",
    "def select_data(db, query=None):\n",
    "    try:\n",
    "        if query or query != []:\n",
    "            return db.get(where=query)\n",
    "        elif query != []:\n",
    "            return db.get()\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DB_PATH = \"./chroma_db\"\n",
    "name = \"my_db\"\n",
    "embedding = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "file_path = \"data/Aligning Instruction Tuning with Pre-training.pdf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "HTTP error: {\"error\":{\"message\":\"API key suspended due to insufficient credit. Register your payment method at https://console.upstage.ai/billing to continue.\",\"type\":\"invalid_request_error\",\"param\":\"\",\"code\":\"api_key_is_not_allowed\"}}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\joyos\\anaconda3\\envs\\bitcomputer\\Lib\\site-packages\\langchain_upstage\\document_parse_parsers.py:181\u001b[0m, in \u001b[0;36mUpstageDocumentParseParser._get_response\u001b[1;34m(self, files)\u001b[0m\n\u001b[0;32m    169\u001b[0m response \u001b[38;5;241m=\u001b[39m requests\u001b[38;5;241m.\u001b[39mpost(\n\u001b[0;32m    170\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbase_url,\n\u001b[0;32m    171\u001b[0m     headers\u001b[38;5;241m=\u001b[39mheaders,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    179\u001b[0m     },\n\u001b[0;32m    180\u001b[0m )\n\u001b[1;32m--> 181\u001b[0m \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    182\u001b[0m result \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mjson()\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124melements\u001b[39m\u001b[38;5;124m\"\u001b[39m, [])\n",
      "File \u001b[1;32mc:\\Users\\joyos\\anaconda3\\envs\\bitcomputer\\Lib\\site-packages\\requests\\models.py:1024\u001b[0m, in \u001b[0;36mResponse.raise_for_status\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1023\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m http_error_msg:\n\u001b[1;32m-> 1024\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(http_error_msg, response\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[1;31mHTTPError\u001b[0m: 401 Client Error: Unauthorized for url: https://api.upstage.ai/v1/document-ai/document-parse",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m documents \u001b[38;5;241m=\u001b[39m \u001b[43mprossed_document\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m documents\n",
      "Cell \u001b[1;32mIn[2], line 3\u001b[0m, in \u001b[0;36mprossed_document\u001b[1;34m(file_path)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprossed_document\u001b[39m(file_path):\n\u001b[0;32m      2\u001b[0m     loader \u001b[38;5;241m=\u001b[39m UpstageDocumentParseLoader(file_path\u001b[38;5;241m=\u001b[39mfile_path, output_format\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhtml\u001b[39m\u001b[38;5;124m\"\u001b[39m, split\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124melement\u001b[39m\u001b[38;5;124m\"\u001b[39m, ocr\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mforce\u001b[39m\u001b[38;5;124m\"\u001b[39m, coordinates\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,)\n\u001b[1;32m----> 3\u001b[0m     docs \u001b[38;5;241m=\u001b[39m \u001b[43mloader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m     metadata \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource\u001b[39m\u001b[38;5;124m\"\u001b[39m: file_path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m\"\u001b[39m: datetime\u001b[38;5;241m.\u001b[39mnow()\u001b[38;5;241m.\u001b[39misoformat()}\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m metadata:\n",
      "File \u001b[1;32mc:\\Users\\joyos\\anaconda3\\envs\\bitcomputer\\Lib\\site-packages\\langchain_upstage\\document_parse.py:165\u001b[0m, in \u001b[0;36mUpstageDocumentParseLoader.load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    163\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    164\u001b[0m     blob \u001b[38;5;241m=\u001b[39m Blob\u001b[38;5;241m.\u001b[39mfrom_path(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfile_path)\n\u001b[1;32m--> 165\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlazy_parse\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblob\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_batch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\joyos\\anaconda3\\envs\\bitcomputer\\Lib\\site-packages\\langchain_upstage\\document_parse_parsers.py:412\u001b[0m, in \u001b[0;36mUpstageDocumentParseParser.lazy_parse\u001b[1;34m(self, blob, is_batch)\u001b[0m\n\u001b[0;32m    409\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m start_page \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m number_of_pages:\n\u001b[0;32m    410\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m--> 412\u001b[0m elements \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_split_and_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfull_docs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_page\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_pages\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    413\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m element \u001b[38;5;129;01min\u001b[39;00m elements:\n\u001b[0;32m    414\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_element_document(element, start_page)\n",
      "File \u001b[1;32mc:\\Users\\joyos\\anaconda3\\envs\\bitcomputer\\Lib\\site-packages\\langchain_upstage\\document_parse_parsers.py:225\u001b[0m, in \u001b[0;36mUpstageDocumentParseParser._split_and_request\u001b[1;34m(self, full_docs, start_page, num_pages)\u001b[0m\n\u001b[0;32m    223\u001b[0m     merger\u001b[38;5;241m.\u001b[39mwrite(buffer)\n\u001b[0;32m    224\u001b[0m     buffer\u001b[38;5;241m.\u001b[39mseek(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m--> 225\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdocument\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    227\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[1;32mc:\\Users\\joyos\\anaconda3\\envs\\bitcomputer\\Lib\\site-packages\\langchain_upstage\\document_parse_parsers.py:185\u001b[0m, in \u001b[0;36mUpstageDocumentParseParser._get_response\u001b[1;34m(self, files)\u001b[0m\n\u001b[0;32m    183\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[0;32m    184\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m requests\u001b[38;5;241m.\u001b[39mHTTPError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m--> 185\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHTTP error: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mtext\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    186\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m requests\u001b[38;5;241m.\u001b[39mRequestException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    187\u001b[0m     \u001b[38;5;66;03m# Handle any request-related exceptions\u001b[39;00m\n\u001b[0;32m    188\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to send request: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: HTTP error: {\"error\":{\"message\":\"API key suspended due to insufficient credit. Register your payment method at https://console.upstage.ai/billing to continue.\",\"type\":\"invalid_request_error\",\"param\":\"\",\"code\":\"api_key_is_not_allowed\"}}"
     ]
    }
   ],
   "source": [
    "documents = prossed_document(file_path)\n",
    "\n",
    "documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "persist_db = create_db(DB_PATH=DB_PATH, documents=documents, embedding=embedding, name=name)\n",
    "db = Chroma(persist_directory=DB_PATH, embedding_function=embedding, collection_name=name,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain_chroma.vectorstores.Chroma"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(db)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 추가로 사용할 수 있는 연산자\n",
    "- `$and`: 모든 조건이 만족되어야 함\n",
    "- `$or`: 하나라도 조건이 만족되면 됨\n",
    "- `$gt`, `$lt`, `$gte`, `$lte`: 숫자 비교\n",
    "- `$eq`, `$ne`: 같음/같지 않음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ddb = select_data(db, {'$and': [{'page': 6}, {'id': 1}]})['ids']\n",
    "\n",
    "ddb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected IDs to be a non-empty list, got 0 IDs in delete.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\joyos\\anaconda3\\envs\\bitcomputer\\Lib\\site-packages\\chromadb\\api\\models\\CollectionCommon.py:90\u001b[0m, in \u001b[0;36mvalidation_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     89\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 90\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     91\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\Users\\joyos\\anaconda3\\envs\\bitcomputer\\Lib\\site-packages\\chromadb\\api\\models\\CollectionCommon.py:439\u001b[0m, in \u001b[0;36mCollectionCommon._validate_and_prepare_delete_request\u001b[1;34m(self, ids, where, where_document)\u001b[0m\n\u001b[0;32m    438\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m request_ids \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 439\u001b[0m     \u001b[43mvalidate_ids\u001b[49m\u001b[43m(\u001b[49m\u001b[43mids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest_ids\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    440\u001b[0m validate_filter_set(filter_set\u001b[38;5;241m=\u001b[39mfilters)\n",
      "File \u001b[1;32mc:\\Users\\joyos\\anaconda3\\envs\\bitcomputer\\Lib\\site-packages\\chromadb\\api\\types.py:504\u001b[0m, in \u001b[0;36mvalidate_ids\u001b[1;34m(ids)\u001b[0m\n\u001b[0;32m    503\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(ids) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 504\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected IDs to be a non-empty list, got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(ids)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m IDs\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    505\u001b[0m seen \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[1;31mValueError\u001b[0m: Expected IDs to be a non-empty list, got 0 IDs",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[44], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m dd \u001b[38;5;241m=\u001b[39m \u001b[43mdorp_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m dd\n",
      "Cell \u001b[1;32mIn[43], line 24\u001b[0m, in \u001b[0;36mdorp_data\u001b[1;34m(db, ids)\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdorp_data\u001b[39m(db, ids):\n\u001b[1;32m---> 24\u001b[0m     \u001b[43mdb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdelete\u001b[49m\u001b[43m(\u001b[49m\u001b[43mids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mids\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\joyos\\anaconda3\\envs\\bitcomputer\\Lib\\site-packages\\langchain_chroma\\vectorstores.py:1257\u001b[0m, in \u001b[0;36mChroma.delete\u001b[1;34m(self, ids, **kwargs)\u001b[0m\n\u001b[0;32m   1250\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdelete\u001b[39m(\u001b[38;5;28mself\u001b[39m, ids: Optional[List[\u001b[38;5;28mstr\u001b[39m]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1251\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Delete by vector IDs.\u001b[39;00m\n\u001b[0;32m   1252\u001b[0m \n\u001b[0;32m   1253\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   1254\u001b[0m \u001b[38;5;124;03m        ids: List of ids to delete.\u001b[39;00m\n\u001b[0;32m   1255\u001b[0m \u001b[38;5;124;03m        kwargs: Additional keyword arguments.\u001b[39;00m\n\u001b[0;32m   1256\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1257\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_collection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdelete\u001b[49m\u001b[43m(\u001b[49m\u001b[43mids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\joyos\\anaconda3\\envs\\bitcomputer\\Lib\\site-packages\\chromadb\\api\\models\\Collection.py:371\u001b[0m, in \u001b[0;36mCollection.delete\u001b[1;34m(self, ids, where, where_document)\u001b[0m\n\u001b[0;32m    352\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdelete\u001b[39m(\n\u001b[0;32m    353\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    354\u001b[0m     ids: Optional[IDs] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    355\u001b[0m     where: Optional[Where] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    356\u001b[0m     where_document: Optional[WhereDocument] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    357\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    358\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Delete the embeddings based on ids and/or a where filter\u001b[39;00m\n\u001b[0;32m    359\u001b[0m \n\u001b[0;32m    360\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    369\u001b[0m \u001b[38;5;124;03m        ValueError: If you don't provide either ids, where, or where_document\u001b[39;00m\n\u001b[0;32m    370\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 371\u001b[0m     delete_request \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_and_prepare_delete_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    372\u001b[0m \u001b[43m        \u001b[49m\u001b[43mids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwhere\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwhere_document\u001b[49m\n\u001b[0;32m    373\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    375\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client\u001b[38;5;241m.\u001b[39m_delete(\n\u001b[0;32m    376\u001b[0m         collection_id\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mid,\n\u001b[0;32m    377\u001b[0m         ids\u001b[38;5;241m=\u001b[39mdelete_request[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mids\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    381\u001b[0m         database\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdatabase,\n\u001b[0;32m    382\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\joyos\\anaconda3\\envs\\bitcomputer\\Lib\\site-packages\\chromadb\\api\\models\\CollectionCommon.py:93\u001b[0m, in \u001b[0;36mvalidation_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     92\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(e)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 93\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(e)(msg)\u001b[38;5;241m.\u001b[39mwith_traceback(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\joyos\\anaconda3\\envs\\bitcomputer\\Lib\\site-packages\\chromadb\\api\\models\\CollectionCommon.py:90\u001b[0m, in \u001b[0;36mvalidation_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m     88\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;28mself\u001b[39m: Any, \u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m T:\n\u001b[0;32m     89\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 90\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     91\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     92\u001b[0m         msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(e)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\joyos\\anaconda3\\envs\\bitcomputer\\Lib\\site-packages\\chromadb\\api\\models\\CollectionCommon.py:439\u001b[0m, in \u001b[0;36mCollectionCommon._validate_and_prepare_delete_request\u001b[1;34m(self, ids, where, where_document)\u001b[0m\n\u001b[0;32m    437\u001b[0m \u001b[38;5;66;03m# Validate\u001b[39;00m\n\u001b[0;32m    438\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m request_ids \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 439\u001b[0m     \u001b[43mvalidate_ids\u001b[49m\u001b[43m(\u001b[49m\u001b[43mids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest_ids\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    440\u001b[0m validate_filter_set(filter_set\u001b[38;5;241m=\u001b[39mfilters)\n\u001b[0;32m    442\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m DeleteRequest(\n\u001b[0;32m    443\u001b[0m     ids\u001b[38;5;241m=\u001b[39mrequest_ids, where\u001b[38;5;241m=\u001b[39mwhere, where_document\u001b[38;5;241m=\u001b[39mwhere_document\n\u001b[0;32m    444\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\joyos\\anaconda3\\envs\\bitcomputer\\Lib\\site-packages\\chromadb\\api\\types.py:504\u001b[0m, in \u001b[0;36mvalidate_ids\u001b[1;34m(ids)\u001b[0m\n\u001b[0;32m    502\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected IDs to be a list, got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(ids)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m as IDs\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    503\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(ids) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 504\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected IDs to be a non-empty list, got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(ids)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m IDs\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    505\u001b[0m seen \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n\u001b[0;32m    506\u001b[0m dups \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[1;31mValueError\u001b[0m: Expected IDs to be a non-empty list, got 0 IDs in delete."
     ]
    }
   ],
   "source": [
    "dd = dorp_data(db, select_data(db, {'$and': [{'page': 6}, {'id': 1}]})['ids'])\n",
    "\n",
    "dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"과제\\20250122과제\\data\\Parallel Multi-objective Metaheuristics for Smart Communications in Vehicular Networks.pdf\"\n",
    "documents = prossed_document(file_path)\n",
    "\n",
    "add_data(persist_db, documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ids': ['e6d51af1-2629-413e-ac90-4c7019dd0afe',\n",
       "  'fdbd0627-b33e-4711-bbc3-a4ec465a5454',\n",
       "  'c09fc517-d4f1-47bf-952b-9529b91a2693',\n",
       "  '4a866414-535b-4d5e-90a1-9b7f9d082325',\n",
       "  'f8e10b64-f1bf-40f7-99c6-51f10c92e064',\n",
       "  '42a81464-68f3-44a4-b44e-671589ae4499',\n",
       "  'ee4c7fa5-0b88-49c9-a0c7-df786dc7b080',\n",
       "  '0f5f417e-6bd2-4872-ab92-0a4b3c8351fe',\n",
       "  'c4b3cde4-31bc-4b1d-8cb3-b8e4af718c1d',\n",
       "  '5435caf8-a48a-437e-95ac-edd23af51786',\n",
       "  'fa336dbe-26d5-4671-8eda-f0b74c86718c',\n",
       "  '2dd9a63f-d6f4-436a-9b4f-6b06774954a5',\n",
       "  'c14a3fca-d2a6-4b2a-aaa7-cb3eebb0dd3a',\n",
       "  '4e54ca26-f0e5-466e-b3c7-98909c333f52',\n",
       "  'd93e6be6-3588-43e9-a8b9-3edd8284eba3',\n",
       "  '11143cd0-e6ed-4696-b7c3-431d7cf49b02',\n",
       "  '71bccbf9-bec7-40c2-9a57-8249ab4cb303',\n",
       "  'bb9dcb6f-474a-4e4f-8571-ac8c17e15856',\n",
       "  '13e9f8da-7144-425e-8ebc-cd759f346ed7',\n",
       "  '9ddb9ac2-d262-424d-953b-29577d5f18e7',\n",
       "  '80a0c1ab-4c70-4e3b-8167-3ae3e954123c',\n",
       "  '51e69502-40eb-463f-8866-f8316ca83967',\n",
       "  '4844b18d-3c51-4ca6-be3a-427ea112ac02',\n",
       "  '11ae45c9-978e-40f7-aa7e-6c1e474d57db',\n",
       "  '97ad06b8-c39e-4035-9241-dcb5c62e8737',\n",
       "  'f8a412f5-77a1-4fed-bba0-68227c42063b',\n",
       "  '07870969-f74d-4e9f-9f27-5f4081f4fcdc',\n",
       "  '291b56dd-134f-4873-bdeb-a4fe547e2ec2',\n",
       "  '85790628-e759-4aa6-b9c8-ff2191b62195',\n",
       "  '4e7bf24b-0e13-430a-9626-43305ab61516',\n",
       "  '1f4825fa-186e-4d2f-a624-50098d99bbb6',\n",
       "  '2eeecf5b-a927-4995-9448-b501f5aafef4',\n",
       "  '79afdc8e-2e79-40ab-a63e-c9e26d9d9e90',\n",
       "  '8b379f37-90e8-4dd3-a514-53f66e68be78',\n",
       "  '439a082b-2a49-49e3-b565-6b748df0c12a',\n",
       "  '7d91bc3d-3017-49ae-a6b3-545d361b16f5',\n",
       "  '11b10c75-f670-4373-aecc-b1a567687e41',\n",
       "  '3d38d09c-08c5-4d47-b3ed-fa775a2ea7be',\n",
       "  'cf8b63e6-af7a-4b1d-bc1a-270c0d6f874e',\n",
       "  'b0fe7213-e12e-4b39-9118-116b6d75dda3',\n",
       "  '4d160135-0ea3-400d-b12f-52fb5c087b00',\n",
       "  '7e03f941-9d7a-4d2d-a7fd-11f9bc91a96b',\n",
       "  '99bbd7b8-516d-470c-b162-c255bb651ecd',\n",
       "  '28341cb5-e8f8-4a3b-8e0d-20d14294c9ac',\n",
       "  '68a8dec0-f6aa-4127-b3a3-01c0e41d88e0',\n",
       "  '110c3f10-e11b-43e5-b71a-6ed5cdcb2b0a',\n",
       "  'd1782163-c1cf-42f1-96f0-b07108f6b2db',\n",
       "  '06fa26ad-5011-415c-8eb4-f1dcf2426bd1',\n",
       "  '1c7590d1-361b-4eab-88b7-bdc196e49233',\n",
       "  '0258d30c-b227-4c79-acd1-8d77e8b1d964',\n",
       "  '5145d3f1-afb7-438d-a283-d4665f91000f',\n",
       "  '5d1ff61f-24b2-4a1b-9726-f05c363963f4',\n",
       "  'e46b9bc6-f45b-4e52-bfd3-fa910c0ffa68',\n",
       "  '36395039-0ca2-441b-81ee-6a0c3f57a525',\n",
       "  '36151a04-0aad-45a3-922c-643c62160997',\n",
       "  'b637a45a-6fb6-42c8-9b79-dda1a26c0d98',\n",
       "  '69a0281e-4728-4fc3-9270-d838a43f8256',\n",
       "  'f793248d-5ea4-4d3d-9f82-4932e5fa4d08',\n",
       "  '55cd433e-309e-4f8b-826a-c1eda24001de',\n",
       "  '4690b672-99b3-4730-8f01-be261088c426',\n",
       "  '55a75edb-062f-42cd-a705-f57bbf636aed',\n",
       "  'c39f4dbb-497e-46ca-80b6-102ee41712b3',\n",
       "  'ea241744-975c-4777-a3c9-8b717cd78368',\n",
       "  'fb703a5b-bb89-4858-b08f-15c5e6ae5039',\n",
       "  'e492a0f7-ff96-430a-959b-b4455afd5721',\n",
       "  '51198750-4155-4075-85a2-150ac1612dc0',\n",
       "  'e9df620f-44bb-4dc9-b55d-eed05bc22c61',\n",
       "  'c4d29c65-e56b-43e4-8612-860e3272d6c1',\n",
       "  '29ba15bb-06e4-48c8-8869-0e43cb93cd44',\n",
       "  '67fa6de7-fe9f-4016-ba64-f5092198cb9b',\n",
       "  '11354c55-ea22-4700-8786-d5cd4bf74aea',\n",
       "  '292795a0-37af-4a44-ac20-bf8ced613fc4',\n",
       "  'ab3bdd83-7d61-46eb-8566-bae32b225c49',\n",
       "  'c6ae0a71-88a8-4ac9-9f46-67f103d264b7',\n",
       "  'ce5ccec3-b08e-4762-9950-7f2760eae634',\n",
       "  'bfa25bce-2940-4ae2-988a-bee574c9466f',\n",
       "  '43e3b2e7-8657-4e13-873e-6b9fcbf105c3',\n",
       "  'f0c16aff-1b07-48c1-8beb-9f01e0d3aee7',\n",
       "  '345fc2d7-089e-4ff1-91e4-a7aebec7caf6',\n",
       "  'e59351cb-25d4-470f-9b18-b8881c6299bf',\n",
       "  '80805d0a-b923-4ea2-b4c4-f11d6ecbd0f4',\n",
       "  '203dbdcf-4f92-408c-86b9-fc67c10be8ca',\n",
       "  '59c792a8-ce05-41f1-b53a-561e615eb0eb',\n",
       "  '1eb57454-3398-479e-865d-c2849738e037',\n",
       "  'f357eb0c-a3fb-407d-923f-3b55b1ab271d',\n",
       "  '329bb90b-56d9-45e0-a9fc-2f111976274e',\n",
       "  'd6ade264-0262-4e04-b1e0-d09ab4f3a195',\n",
       "  'b49d2c00-2220-4c7f-849a-08cbec73dc9f',\n",
       "  '390b9807-f65d-4934-92cd-741a0580d96a',\n",
       "  'e779b4d7-6007-40bb-9552-2b69eb8120e4',\n",
       "  '0801deb1-b0f2-465e-aaef-6035966497e5',\n",
       "  '873ec5fe-d1c2-4e53-a5ce-2503fd2036cb',\n",
       "  '7981e429-c712-4b6b-b47e-27d417894154',\n",
       "  '33efeac8-1249-45a5-87bf-ad76f49734b9',\n",
       "  '7ae80db0-4d5f-4d2c-b38e-802114153668',\n",
       "  'ad2db4a2-0971-492c-91a7-87844d5c2ddb',\n",
       "  '3e9d3b99-0189-48ae-bd10-76c0a27676e2',\n",
       "  '0006d886-ff4a-4189-b6fc-0177f81b3f17',\n",
       "  '0041af02-b29d-41e2-81c6-8859150307ba',\n",
       "  '0cd726a2-2e1e-48dc-abed-3502a048fc10',\n",
       "  '1b7e4a7b-d1a5-4afe-aa24-b936f07a6bb6',\n",
       "  '9e7b530e-fd41-4a8e-accb-dc85b47c56ce',\n",
       "  '6cec896f-a6ce-422c-b2c7-182e019514b1',\n",
       "  '012a22dc-fdd9-433f-9424-e3dcb240ca26',\n",
       "  '1428b9f8-7a99-4881-9295-06d520048220',\n",
       "  '95aa8753-ebb4-4dc1-b700-3073edaae1c5',\n",
       "  'b9d7405a-52e6-438f-8e10-728213aae416',\n",
       "  '8c0d2d96-7173-4642-b376-400815867e12',\n",
       "  'a5c447cc-2d70-4237-a158-7489e02b7eb2',\n",
       "  '75267f9b-86bc-4294-9943-65a3c1286c24',\n",
       "  '664d7fc5-c818-484f-9f14-c134c5056b64',\n",
       "  '8db7b66a-9ded-454f-96c8-d08296c94486',\n",
       "  '1ab5c0f5-49fd-4d89-b56e-d40b4938556d',\n",
       "  '0c92b3a2-e048-48ba-a0d2-dec297171073',\n",
       "  '0461a941-424b-4888-bc8d-e0858a206220',\n",
       "  'f279fb89-1b6c-4910-b88c-f083de68d28f',\n",
       "  '2e6f7167-bcc6-49ad-ad64-f1f3215b5677',\n",
       "  '16f3f9de-c11c-4d0d-a356-b6018f86895a',\n",
       "  '06c1012c-7f05-4794-ba97-41c5c366fb0f',\n",
       "  '0cbb81b7-a61f-4468-9879-e04097d30aad',\n",
       "  '0c1bce1e-1af0-4dc8-b1db-26ec3b348323',\n",
       "  '63547a8a-3329-4ead-8f60-af51e48cbae5',\n",
       "  'c8725861-f1c9-4c49-935c-089667534b29',\n",
       "  '798671e9-894c-49cf-834d-7ea4dac9e8e8',\n",
       "  'ddafaa67-c4ec-4480-b39e-1a8a5b6aaea9',\n",
       "  'e5b95837-ee68-4a12-ae69-0cb3b40c0bc5',\n",
       "  '9e0439a2-cd43-4c6e-a1a3-894b98474ed3',\n",
       "  '29010ff6-fc27-4df4-a0e1-d07622ce742b',\n",
       "  '7c64daee-d40b-4574-9bac-3f770d20ea75',\n",
       "  '075b46b7-83c7-442f-9e45-5357bf57b5ab',\n",
       "  '2cd25faf-fca1-45c5-a509-b7af52b2c0cf',\n",
       "  'a29fe1e6-73a8-4d13-82b4-ca695bfbd15c',\n",
       "  '4feeb3ba-9c3e-4a0c-9664-f2366919eb7e',\n",
       "  '7426bc5e-dbdc-4cbd-8704-573d7be5b6a3',\n",
       "  '57c67b8a-ad3c-449d-94ab-925667933fac',\n",
       "  '4bf0b2bc-8f5d-4d70-9968-15ae23f1d6bb',\n",
       "  '0012efe3-d92a-47fd-8049-7f85448de4b8',\n",
       "  'c400fc7a-fd4f-436d-b5d5-db0abda70483',\n",
       "  '5ba810b2-fac1-425a-aa76-7cd5010dad95',\n",
       "  'a6fffbf0-7780-4caa-821d-6cb2100978b3',\n",
       "  'a7d63f00-26dc-4faa-ac88-4ad2d8df939b',\n",
       "  '7ac6ca4f-6f43-46f2-b46c-27dab41f4621',\n",
       "  'a7c5754d-9045-4b96-867a-56aeea7ac173',\n",
       "  '62a43c56-66e6-44d8-a14b-d94b578dc27c',\n",
       "  '2250d8b8-6dce-404c-8480-deef760ec456',\n",
       "  '767affe2-e097-4a84-bb79-3d639ae12d30',\n",
       "  'e12622ca-3679-4b53-a05a-a93fae908b97',\n",
       "  '5196fe70-b2d3-4fb7-a414-e3d8f96bb89b',\n",
       "  '183646e7-c505-425b-883b-e006023e7df2',\n",
       "  '78382c29-bb45-4cb8-91d8-ef2948d2c1d3',\n",
       "  'bb10730c-fd28-488c-b0ec-b95a0f3fb9c9',\n",
       "  '088b81f3-3e61-41ab-aadb-8c33ce2e2afa',\n",
       "  '0802dc97-2203-4652-aa5d-19b98ee72eeb',\n",
       "  'c2cd263d-e26c-4b1c-9091-c88f9a9b21e7',\n",
       "  'eea03ff2-dc21-463a-a56b-a6bfd0bed513',\n",
       "  '1433491d-3951-4a94-bc3c-3e8f8136326a',\n",
       "  '249ee475-2980-4093-81f1-7b1785bb46a6',\n",
       "  '5fb391e7-4e77-4433-8f31-31668f22ac23',\n",
       "  'cfd8ea67-37b0-45ca-aeb2-798e6add3597',\n",
       "  '921bdd84-722e-4fce-868d-c334c6e76789',\n",
       "  '7dfc3a76-2fca-422e-bf8b-35c8405e319d',\n",
       "  '02672bc6-c67a-411b-8af4-9c3965ce1661',\n",
       "  '5e563c29-adb6-4b91-b4ea-87472bde6d0f',\n",
       "  '1db90e40-a91a-4e04-9250-929e54f88c1f',\n",
       "  '6d427784-19e6-4f96-aa67-b11d95b9cb88',\n",
       "  'a778a83c-7f76-4c81-bf99-2d1b409f8097',\n",
       "  '30e25ae1-ed1d-412f-a433-bd2abb83b153',\n",
       "  '03fb2526-00d5-428b-8d09-4344bcb57eae',\n",
       "  '7d70e500-37f5-45a5-ab50-0f279726da9c',\n",
       "  'd3e1fa88-3e3b-4473-835d-7e86f4a7e01e',\n",
       "  '4db8159e-7e9e-401d-bf66-72f88cdb43f7',\n",
       "  'fc5cb9a4-f37b-4527-ae5a-8f0a9cf88526',\n",
       "  '6960c595-7c46-4447-85c6-00d957211433',\n",
       "  '6b0cff9a-279e-4193-9abd-1948d3824a6a',\n",
       "  'e114ff89-387c-47f2-b02b-3101f3ade44d',\n",
       "  'b1afd422-ffe0-4ea0-8838-aa2e8f527fc8',\n",
       "  'b4a5589f-878b-458a-ab65-2a81cc6e3156',\n",
       "  '281ffcb7-e9cd-457f-88e0-decacc6ea77a',\n",
       "  'b483025f-f482-4e40-b071-5ce12b4c3e57',\n",
       "  '742c40a1-08a0-4bca-ae2b-22b50e1000ab',\n",
       "  'd56aec50-ff49-4acb-a2f5-15f98d6e4445',\n",
       "  '50096e9b-7a0c-4b7b-adfd-ab43ffb7d8cc',\n",
       "  '9946013c-8b58-41f9-96c3-3ea85b8839dc',\n",
       "  '9002e4b0-5fab-43d5-80a4-af2ad9fd8254',\n",
       "  '81d07a40-259c-4c99-8502-6e515a9894b7',\n",
       "  '52295ea2-b8f7-4b45-bd66-379a37b93b0c',\n",
       "  '6c12651d-f2c9-45e0-9846-491285de366b',\n",
       "  'e0a6f164-3f06-4d6d-a5f9-469bde05ec97',\n",
       "  '30d3e502-49ad-446f-b6bb-c6fc91de6dbe',\n",
       "  '0c550ee9-5569-4d50-9a20-665fd9c6aaa2',\n",
       "  '54652b2b-18c1-4cab-81c4-d35f243baca1',\n",
       "  'e475784d-5316-44c3-9159-3e007ab5e7d1',\n",
       "  'd518c520-7134-432c-a746-395f4f644bdd',\n",
       "  '887c6a23-fe27-4b89-b4f5-2aefd361bba1',\n",
       "  'f738d9bb-2a7a-48d2-ad87-3e6c8a9024ed',\n",
       "  '88dec906-0e6b-4317-9e33-839b131e71b6',\n",
       "  '3e6dab86-3d22-4535-8eab-cd2147f0fe4a',\n",
       "  'a9804968-41be-4ede-8e2d-883523a3c814',\n",
       "  'fa37834c-b809-4fbc-b8fc-78ecf9470d6b',\n",
       "  'fa34e3e7-6a01-480c-b56c-a31de0159728',\n",
       "  '350042fc-3314-4fdf-b691-e6bb7abc27d6',\n",
       "  'e02b3ae6-167e-4cf0-977d-9e8b8e6ff71f',\n",
       "  '03dc216a-b15d-4eec-b6a6-35efc61ce9c9',\n",
       "  '5ad0df35-e25f-496c-9afe-fcda664c14a7',\n",
       "  '14885dcd-a3f0-4fda-9d30-b7a1fce3ccc3',\n",
       "  '671b6d55-14bf-4371-a697-4dc5482b2b11',\n",
       "  'a3d78153-1119-431a-8b8a-3a3f9a9d53a6',\n",
       "  'c728cca1-fbbc-4c2a-a416-82c00fa6f2bc',\n",
       "  '22e2811c-9429-486e-81fd-74f78cbb6edb',\n",
       "  'd2788f50-5915-4bf0-93e5-26dc54c96b14',\n",
       "  'b7230b16-5149-4c65-9f28-e860d107fb0a',\n",
       "  'e08de29c-e6da-49ac-9a56-71ace6bd59a1',\n",
       "  'b27ace19-8d6a-41f8-8d8a-a6ab63403fcf',\n",
       "  'a18ea6ed-e292-4897-83c1-e8f97deb2338',\n",
       "  '1762da4e-3458-4adc-bee0-03703c71ede9',\n",
       "  '131dd391-c6f1-43a6-b7d9-22a42f65a80b',\n",
       "  'c8c3df3d-e6f9-45cc-8484-9fc842eaf9ec',\n",
       "  '4dfd5024-f533-4d7e-8d97-eeea1f39fdcd',\n",
       "  '0eeba201-1454-45db-999e-ad0edc7f230e',\n",
       "  'bc7db63a-5380-491f-9fb6-4a9eafcbb23d',\n",
       "  '8c514dab-1bd2-4c74-ad97-98a5bdb968ef',\n",
       "  '88dcaac3-8799-4340-8f1c-ac1d4d7eb677',\n",
       "  '0ca791a7-b854-4e31-a217-febae9cae6a3',\n",
       "  '12780e52-6fda-4490-84e3-aecbcbc4cb5c',\n",
       "  '9617bd38-93a3-446b-b0f5-98c807cb9fbf',\n",
       "  'b9510976-34c4-4014-b961-404162060216',\n",
       "  '711e6946-1397-4f2e-b45b-efaf32a79053',\n",
       "  '3311a571-2a6e-4fce-acc3-15d08f444188',\n",
       "  '407a581c-b5e6-4003-82a5-2d1709cce6f8',\n",
       "  'b27588a2-2fc0-40af-a73f-b3fe3e6550e3',\n",
       "  '0aeba0c1-2509-45ad-b96a-8bf1c9ad6432',\n",
       "  '1ff727a0-6bfc-483f-bd0e-58dba8f3ed12',\n",
       "  '73c0acc3-8e3a-44e5-a33d-e6b35653ecb2',\n",
       "  'dd70603a-27c1-4cc5-bbbb-6e3cc01bbdea',\n",
       "  '7dc07a33-6ab4-436a-9431-172fdd1dd1b6',\n",
       "  'b86bfacf-ac5a-4a82-b39a-4160e0da6f41',\n",
       "  '63662c01-cd05-40a3-8027-133b21ad2ea8',\n",
       "  'd70e20a0-d3cb-4bfb-bca4-8f4e3ed2bd08',\n",
       "  '3c83a110-c4ed-42d6-ad56-be4760579cfc',\n",
       "  '21a22e9b-e073-4f56-92b0-fea212cd4f9f',\n",
       "  '1541c681-1e2b-4621-acea-189cccd9d2f0',\n",
       "  '4d158cfa-6d29-4c25-af24-c0a3c633eb91',\n",
       "  'df302e80-24af-491c-a0e2-f8746053632b',\n",
       "  '06ed52fa-7a04-4624-af0f-5f179d65d5c0',\n",
       "  'e768d799-7860-47d1-9bce-82cfd8e39a3f',\n",
       "  '7e8375fd-6128-49a0-ab44-7329001477da',\n",
       "  'b46a1b2b-93ad-4583-a3af-d2f63096e571',\n",
       "  '14a01f87-b2f6-42a4-a1d4-1fff5af96b7a',\n",
       "  '42c5767f-7220-48ee-b251-b6aa6ab31f28',\n",
       "  '12c38971-bec3-4ef0-9176-a4a43e3e8afd',\n",
       "  '4008800d-8121-46a8-bd9c-873ae7c11620',\n",
       "  '525b624b-622e-4682-836e-75c7b79fb3b7',\n",
       "  'cd8c817e-094a-4b06-ae58-59bfd7e4bea1',\n",
       "  '81397053-34d2-403a-826e-3a12084c7106',\n",
       "  '63f4a9c1-ad79-4c60-9bc2-18751e9c115d',\n",
       "  '3c164492-d91c-4062-add0-d50b51010824',\n",
       "  '4b284d4e-3f36-487a-8807-c6ed840770b5',\n",
       "  '065ce61a-1ec7-44c5-af49-05de2e644510',\n",
       "  '110ddffb-ac0b-4e65-98d4-1024c12aa985',\n",
       "  'dbac108b-5130-4864-8714-de1a6a3702c8',\n",
       "  'b6899ed7-a52d-413a-b28f-83eed31c85db',\n",
       "  'b0af7ab2-0cc9-4c95-81fa-28203ee17dcb',\n",
       "  '42b9bddc-987c-469c-89d2-b4557df26325',\n",
       "  '4f149fdd-a7a2-4a76-8cac-f9d59632f87f',\n",
       "  '66c06523-e21a-4d0a-87c2-ee67242d617b',\n",
       "  '7cb09fa6-fe97-4553-8736-9d9d04b9c6f5',\n",
       "  '48ede460-71f5-4fa6-8820-844707641846',\n",
       "  'd762e31a-ed0b-4f91-9878-8301a2344360',\n",
       "  '9d4b2ea5-ef48-4276-8a63-6a11fb76f5fb',\n",
       "  'a34c19e4-60ab-44c9-ae7e-0a86363fa05e',\n",
       "  '5650c56b-57eb-49c8-a977-44751c320525',\n",
       "  'b2b18421-dc22-4740-96e2-d497ac61a3fd',\n",
       "  'b99211aa-b385-4d67-b261-1e8af246cfaf',\n",
       "  '2ec218cb-e1a7-4688-a8c4-cfe6cbbd72a3',\n",
       "  '14e1f1b3-23fe-4a26-9eaf-aea2fea6294b',\n",
       "  '539679e3-21cb-4ec9-90c6-9945002cf5f4',\n",
       "  '2c3850e7-835d-48a7-9c3f-23ed5f4ea19e',\n",
       "  '64625295-93bd-40bc-a1f1-d0443e6b9021',\n",
       "  '29eba342-4ef2-4205-a29f-4f65eaaa1d6f',\n",
       "  '8c73cc99-d40b-494f-ac3b-74a06e8392bc',\n",
       "  'b8f21286-8691-4a64-bab1-b1a2d7fbfc14',\n",
       "  '18b42822-da46-4990-b5c0-31200272e860',\n",
       "  'c62602e2-5e7d-45ce-afca-b666058359c9',\n",
       "  '5a7627fb-bf0b-4535-aa5d-171c70d5cc66',\n",
       "  '2b340292-6f10-43c0-853b-d93eaf3c7c92',\n",
       "  '7c9eef5d-18d0-4f2f-810c-c47f54855603',\n",
       "  'd26b76df-37d8-4e7e-bfce-22737057bb36',\n",
       "  '1955decc-b5ea-4ebf-a8a5-559fff158dfc',\n",
       "  '3fd390cd-518e-451d-8b14-3984f5b9926c',\n",
       "  '134c0e60-2949-4d58-81a2-717c4aae7698',\n",
       "  'b03e223d-486c-4583-a624-357aca5705bf',\n",
       "  'f4dde224-ada9-465c-8f38-849135ed6ecd',\n",
       "  '556f9670-0f12-4fc4-a534-1dbf0376245e',\n",
       "  '85c45841-3267-44dd-9e9f-835f52d95490',\n",
       "  'e63b2fbc-0154-4a85-b795-6e5c44787877',\n",
       "  '7f9334f1-cd5e-4468-a80f-9a13ef0f773a',\n",
       "  '3cd6a9a3-e026-4d9f-9732-4b09cfc4d34e',\n",
       "  '321c717a-4fae-450a-aba4-b7b1736bcf69',\n",
       "  '05d75801-5732-4a1b-9d34-9b14e48b87ab',\n",
       "  '04250754-18c6-43be-9b13-1b339c09fcc7',\n",
       "  '34cefcac-b1c1-4ac8-815c-283088904e2f',\n",
       "  'a03734ba-9084-4b6f-aa93-b5adaeee56a8',\n",
       "  '37d14cbf-ee50-45a9-a406-4236aee17dae',\n",
       "  '01020d6b-86dc-41f1-a158-9bbbb9e86167',\n",
       "  '6b73a521-34c3-4eb3-b0b0-20d46cbc5323',\n",
       "  'd0e86e7a-1fec-4706-b453-ff9978ef2bd1',\n",
       "  '35a6422c-c295-49a7-9feb-9aa3887353ad',\n",
       "  '98471710-3a2f-4394-a4e4-f506f11c8b0c',\n",
       "  'd8f2426f-ec36-4442-bfd3-d1ec742833ae',\n",
       "  'd1165960-a47f-4771-9a49-830ab386cb66',\n",
       "  '2b9451e3-573a-4d41-8b9a-fa74c3d43058',\n",
       "  '559c241d-2023-4f93-8a20-49baa77c4c29',\n",
       "  'f509f280-5200-41d9-ad3a-34f42f21309f',\n",
       "  '0d4a55f1-8aaf-4565-983e-2692ca422ef3',\n",
       "  '75709af9-3dc4-4764-afad-d0ecbbdeed3d',\n",
       "  '86a1bdbc-6027-4b0f-9c34-3c295cbb69b3',\n",
       "  '8ae04efe-1005-42a2-8119-912029a0a617',\n",
       "  'a103d70b-061a-40da-9a28-4707f2848ebc',\n",
       "  'f242d511-d363-48b2-9d62-7439661412e4',\n",
       "  '34c7bc9e-479d-4385-8c31-d2422b042651',\n",
       "  '7519da53-997b-41e8-a4f4-fdeedb372abf',\n",
       "  'd478f99e-66ea-414b-9764-9e2cdc8d00ee',\n",
       "  '2869262f-87d7-4e20-a05c-0e4685cf948e',\n",
       "  'beee8c2f-3886-4a79-8ab8-f741a6c36345',\n",
       "  '20f2ff93-77ef-4034-a09e-06b67b56e01f',\n",
       "  'fc6444d0-8dca-416e-b383-a67ca96eff52',\n",
       "  'a8843225-6d4b-4efe-b57f-5d15989fe903',\n",
       "  '2b124a95-9458-4177-8195-0fae36aeab8b',\n",
       "  'bfbcb792-3054-4d14-b82d-fa8e979145ed',\n",
       "  'd0fc58d1-fa67-4f05-bc78-957454accf1c',\n",
       "  'e0c8e795-2b4b-44e8-a473-b2c4617df1e7',\n",
       "  'eebb8fe7-fb70-4dff-9fad-95980b4ca71b',\n",
       "  'ae22b2df-81b6-4cff-8279-fdf8ec9a30df',\n",
       "  'e3786902-c9cd-4196-8a4b-4e2b30025f18',\n",
       "  'b2ae9c49-5575-4a21-b476-20814e60e32d',\n",
       "  '046cea6d-dc76-4b23-b726-3db2bbcdffbe',\n",
       "  '7ce7b233-91a6-45e2-9b15-57802986a88b',\n",
       "  '4b82e783-3969-455c-8ee7-3da672f9a3fe',\n",
       "  '83fd2c06-7348-462f-8575-24179eee9aa3',\n",
       "  '54acc012-bf0a-4f6b-8d48-71e5ee7c2350',\n",
       "  'a85e0043-e636-4434-8a3c-9908a03664e6',\n",
       "  '81ddcb1a-04ff-4898-8ecc-2b8fef142524',\n",
       "  '6d8b92e8-8492-43eb-b634-28f03064e328',\n",
       "  '80a422cb-300b-434e-b6ad-82c67e273747',\n",
       "  'ef03b235-82dd-4044-b414-0fd9b8826132',\n",
       "  'c5e36207-5b01-4fb0-b701-4c1a001b07d8',\n",
       "  'e07381dd-f1f3-4063-8b6d-665db9abff62',\n",
       "  '92cda11a-ed80-47d9-a9eb-1aec9dd05891',\n",
       "  '4f764975-7c1a-4dc5-87df-b57e3513d19a',\n",
       "  '77cbd9b1-6193-4b1c-9d32-29e8f2363a11',\n",
       "  '0c27e26e-a12d-412c-bb4d-fe0d810b73a8',\n",
       "  'c92ade8a-724b-41e2-9d32-f510c271321e',\n",
       "  'd47c6d2b-81ef-434e-8b45-0f1567cc24a0',\n",
       "  '2babf25e-ee5d-4a49-8d04-5a70289a5175',\n",
       "  '1a83a858-054e-4937-81de-9b279322dcff',\n",
       "  '9eb10805-51ac-45bd-acea-cd87ca9ae30f',\n",
       "  '846837a8-ec08-4c43-b881-b3ed6ee5b43c',\n",
       "  'f81643ae-4483-4f8a-8ec1-a2e948dce03f',\n",
       "  'dae6e79e-6cfb-4444-952d-56ffe91b4858',\n",
       "  '15de2650-a499-4e13-a787-0cc87508b882',\n",
       "  '3301f61a-3082-40cb-8930-1d1bb6d17289',\n",
       "  'd8601d5c-19a4-41cd-8477-3542dcd8325d',\n",
       "  'c45cb9e7-06e4-450e-bc5c-548c2299c7a8',\n",
       "  'e0910682-3a32-4b1e-955e-f6023984cdb2',\n",
       "  '4ee62e48-0954-4b2a-8707-b30607f85cc1',\n",
       "  '33b6593a-c9e3-4be6-bdc6-9f9b63401629',\n",
       "  '7ecab3d9-5d5b-46a9-a19b-70d0f54d87e4',\n",
       "  'bc0cbfda-51fe-4fdc-a982-48d0c0294c51',\n",
       "  'bfae777e-c84f-43cd-9df0-ed2994a527a6',\n",
       "  'ba4861f3-27d7-47e7-9011-70cbb58b2bcc',\n",
       "  'c5bee742-dc06-4164-9769-aea5a94c193f',\n",
       "  'c58b4b62-7a5b-4644-bfd0-096332ce7955',\n",
       "  '12ada7f2-9b6c-41f0-adef-5b33c2d513b9',\n",
       "  '2309835a-01b6-4599-92b3-6d0d842ebe40',\n",
       "  '9c2dfb04-3eda-4c5d-9616-14018844cf41',\n",
       "  'b349f3e3-7b0e-43f1-a604-a2ddaf1759c7',\n",
       "  'd598619b-8e02-4f71-90c4-8914564701ad',\n",
       "  '3b306583-8e5d-4aea-85ee-6bf342604478',\n",
       "  '4ef2261b-95d9-4345-b935-3d8ed8a94cce',\n",
       "  '7ae6292e-2cbf-426b-aed2-5c8679d395b4',\n",
       "  '733c0131-211b-4338-abf4-5077f8cf8747',\n",
       "  '3d6bf6d0-84c7-4d44-b24e-5743b29217bc',\n",
       "  '303da38e-e275-4901-8c19-d29e0510b22a',\n",
       "  'a915089d-85b3-43c0-b618-7d061d9304f1',\n",
       "  '71a55b77-6d90-479d-818a-e775314cc64d',\n",
       "  '7f2b9cbf-f6b0-4859-861b-df31175dea0c',\n",
       "  'bb9dc8ab-139c-4149-9510-42323821148a',\n",
       "  '35af07e9-0d75-45a5-a384-3e67f1a1020a',\n",
       "  '60ff8091-8c80-46b3-bab6-1119ef332445',\n",
       "  'dd4af6ba-10cb-4cba-8333-51c96c5d98a8',\n",
       "  'b8f09c0f-2f90-4fb0-b693-ff235746e003',\n",
       "  '509d2855-2568-4244-ae07-cbc0bee5abd1',\n",
       "  'e314a1a7-9d3f-4aa7-bf2b-3d09e93df018',\n",
       "  '83d8c456-265b-4a2f-9483-5435413a6519',\n",
       "  'aa4febeb-a1da-4b48-87c9-85fae56d75d7',\n",
       "  '46761a45-2b0b-4653-9208-0f6a1ed37912',\n",
       "  '9822d50d-7b84-4a34-b1fb-83048e45fae2',\n",
       "  '1ddbc242-c481-4b25-b8b1-f0e5132e71c7',\n",
       "  '735e40f9-9032-420f-b0c5-b2bdfc57a658',\n",
       "  'ddedd32e-ab20-4685-acb0-97f2bffeb1c3',\n",
       "  '3d86f5fd-f847-4e8c-af15-9be960d31b71',\n",
       "  '02eb463d-afb3-4267-9f22-56862b3e56d6',\n",
       "  '406bb3f5-b040-4b06-9721-c62e428c2a7f',\n",
       "  'b7daa240-508d-4e60-9293-ee7bc9cb6ab4',\n",
       "  '18baf4c3-e173-4d94-95d1-77f7348650c8',\n",
       "  'c7bf749a-f9b8-4e36-91bc-67475a4e03b3',\n",
       "  '77b781d7-c7f3-4a9b-a1dd-a6e4172a4953',\n",
       "  '93492925-6407-46a5-b218-883cd70ea326',\n",
       "  'e43cd1a5-f472-4a84-b6cd-e9ab9c4b9cd2',\n",
       "  '09659876-d5db-45b7-a234-6feb520b8ff0',\n",
       "  '64354f64-66a3-41ff-a408-884910037b78',\n",
       "  '499f21c5-6c68-41a3-92de-32e1ecfc6780',\n",
       "  'c8adbd74-b4ad-4c7e-a6e9-1454c1d1317b',\n",
       "  '0204144b-457c-4445-80b4-a681a353ce03',\n",
       "  '6e069390-bc4f-4de4-8ff9-95cd82e9235d',\n",
       "  'b50a992a-efc7-40cc-a68e-9014113eab8f',\n",
       "  '2650be80-e201-4d46-83f7-1f34136602d0',\n",
       "  'f9f7a9b0-4848-4ced-8d76-1c487315743a',\n",
       "  'ba35899a-830e-42cc-86f2-95082b0eae07',\n",
       "  '4f671570-caa0-49d1-ab93-17f7ec39e3fc',\n",
       "  '455387ee-7314-4b3e-a320-15ba086da803',\n",
       "  'aaf67c0c-19b8-46b9-8fbf-70db355d6e56',\n",
       "  '47493d29-acc2-402b-86f1-083bea21cb69',\n",
       "  '7f388c7e-d8be-4635-bf84-6337bed6fabe',\n",
       "  'e221a623-908a-4594-ac67-ac4ade4f522b',\n",
       "  'ffdaceda-245f-42ae-87e1-cc0a04e8059c',\n",
       "  '408245eb-c0c3-40c5-8e81-8587b71a8a56',\n",
       "  '5b636902-43d3-4b37-8621-3c9cc84ec0bc',\n",
       "  '15812f0d-8223-4fa1-8ab0-adcdc285307f',\n",
       "  '262f4298-a553-43ca-9c6d-055ca5709575',\n",
       "  '41ae0706-defe-40d2-a4d0-8a96bbba0613',\n",
       "  'b865a825-fde6-4faf-a6ff-741950d8da38',\n",
       "  '646d405b-f89a-45ef-ac4a-17c8551af1db',\n",
       "  '80baeb3a-4dd7-4732-aa47-dbadd340ea3d',\n",
       "  '1e6a5813-1b88-4ff5-951a-ee9da1bd8e41',\n",
       "  'aebaf23d-20e3-4df1-b647-077c2f82f3b7',\n",
       "  '068829c4-6f18-4905-bf40-7b6a9a05efc1',\n",
       "  '0c014183-5179-4f57-b2ed-d5db4f3be665',\n",
       "  '61c7521b-2639-4239-a46e-8705d90f4ffd',\n",
       "  '9fd4097f-aafe-4424-bacd-62157d1fefb1',\n",
       "  '0009e301-f2c4-45dc-9493-c2620b83a6a0',\n",
       "  'c6deefc4-6f6b-4bef-844b-d79a3f83f9da',\n",
       "  'a9e803aa-1f6f-489e-b55d-543e11ca7786',\n",
       "  'ebfa1c3f-d85f-4892-aa8c-1b7aad1042c9',\n",
       "  '1fddcfe2-49f4-48e2-90f3-f4a92fc2b677',\n",
       "  '0b680901-d483-49f5-939c-a021e261c263',\n",
       "  'c4205b9d-3668-4ddb-b240-4605d91ffb35',\n",
       "  '852b85b0-4b9d-4db8-978a-d4d9d5ecb8ec',\n",
       "  'cae3c2b8-3a2f-4b25-8dae-610546b4b6db',\n",
       "  'a3bd9f71-6198-4492-b165-3ee063cbb2f8',\n",
       "  '5b7964a2-818e-458d-a295-a27f1fcc5e25',\n",
       "  '7d009e4a-18f0-49e5-b1a1-60081209a628',\n",
       "  '612c2fbd-259d-4bb7-b862-fdac20418f62',\n",
       "  '10e4c5db-9d61-4be0-9cf0-852828661f0d',\n",
       "  'c153d274-9c74-4cc5-b667-e506f71a03ea',\n",
       "  'd3c75c2e-dcb8-444c-a76c-6e2c891b7c33',\n",
       "  '75046519-20e1-4858-a369-0f24ae1bc436',\n",
       "  '2cad3e90-6d9c-49ee-90c9-0dbbfe8ff315',\n",
       "  '9d8c3578-1c62-4d64-afdd-4affd0677718',\n",
       "  '9c0d1b38-1274-41ae-8aca-27afafe4dd1c',\n",
       "  '2fa0750d-635e-48b5-a8fb-593a79e823d1',\n",
       "  '6c1ed83c-7fce-4020-a6e5-4d97794668f2',\n",
       "  '4389b3d1-6c20-4670-ab50-1ac58b027321',\n",
       "  'ad977a76-fbae-415c-9481-138f48c24c54',\n",
       "  'a97eb2f1-772a-4fa3-b6c2-232186d83e4d',\n",
       "  'b5084555-8cd4-4050-8c77-e22dfda3d9d9',\n",
       "  'd86e0388-8477-43d1-b579-b7056ade3318',\n",
       "  '8dd17791-86e5-4153-add4-ae26fae07e3c',\n",
       "  '99357f08-b81c-4706-a146-cac5e9b5137a',\n",
       "  'c1d3dcf5-470b-4212-8d77-b236fdffef37',\n",
       "  'a0e467fc-dcb7-4340-8ad8-59af1a2789b1',\n",
       "  '67774eae-fe8a-497f-bbe7-0afd9f44e4f2',\n",
       "  'ade38bab-626c-463e-b9ec-89301980d87f',\n",
       "  '9d1a732b-c289-40dd-a210-89cd638d6e6f',\n",
       "  'e4519270-3fb2-4e7c-8388-c5eb9575e07d',\n",
       "  '71025a9b-1249-4ed3-b718-0da8d3f1a85e',\n",
       "  '47d2d2ee-f0b8-4c78-a2d0-33f3df81b736',\n",
       "  'd06b3e96-435f-4607-bb88-a468192678f8',\n",
       "  'a7da8064-1350-4d7a-aead-0c881d59d355',\n",
       "  '03e2aeb4-d6e4-4bbc-bbce-9c9c7a6b8fe8',\n",
       "  '92265828-5bdf-4b50-893d-6f1514aea441',\n",
       "  '15a80bb0-183e-4347-80ec-8a62806de9a9',\n",
       "  '80666770-bd49-4d48-9366-0e3bce786a32',\n",
       "  '15f0fa49-6a26-4e04-a2a3-c7c3ff0ee007',\n",
       "  '36839d97-a511-4a79-a9f4-4058fa81191c',\n",
       "  '172b1e38-c59c-4b4c-b871-e7b58efcf455',\n",
       "  'a61dcf7d-9b63-4ac4-9a48-3779a077b4c4',\n",
       "  '529151ce-947f-4812-9460-0856d0b9372d',\n",
       "  '452231cb-e021-4036-beea-ba3c0a29331f',\n",
       "  'af86ba14-a01b-4100-aa52-65874adb2ebf',\n",
       "  'f80f8901-6ada-48e1-8307-01bb5ba0bcd9',\n",
       "  'f9f0dcd0-11b9-4727-80f8-6faf36b66c16',\n",
       "  '2a005564-95db-4235-91d5-7139b834577e',\n",
       "  '48da1026-22b4-4837-9ccc-11cb3c78c6c0',\n",
       "  'ea201eb0-a1aa-4df4-8034-681996e6bf06',\n",
       "  'dbc603df-792a-43b5-8d0f-35d48156eb23',\n",
       "  '50630599-62cd-4351-b5aa-5e2fc53537f7',\n",
       "  '4ae149f7-d909-40a5-babe-058912815b84',\n",
       "  '518e34ee-6cbc-4a04-990c-160a3c8141c7',\n",
       "  '6dd7d1b0-d573-4650-8d00-3b5d2b6e23a7',\n",
       "  '8a88018d-af10-404d-af9d-7a2d9589f64c',\n",
       "  '007945ac-77d2-44fd-b413-99c6e98a45c6',\n",
       "  'd0976778-c53e-46e2-9c4b-202a5cbacb79',\n",
       "  'feb407d3-fb22-4e75-989c-8628293a7b97',\n",
       "  '9f0ab3df-0f33-4501-8790-10cd87a10bed',\n",
       "  '21139cc0-06c7-4a35-8851-94fc968b1f91',\n",
       "  'b9341e51-591a-4516-8ba1-be30c553b28c',\n",
       "  '95a3bebb-1719-437f-9c13-86c22876ca7f',\n",
       "  'a634f73b-166e-47d4-aaf3-8bf56bd9c555',\n",
       "  'e16457c2-a8af-433c-9832-a6d895ab817d',\n",
       "  'c6d7b846-d8bb-4a3d-a27f-8f92c147c0da',\n",
       "  'bd1cf7aa-f1a2-4289-81f7-b69947548014',\n",
       "  '212e4d77-d2ce-4729-96c9-538630d860d1',\n",
       "  '51b2a3f8-8737-4b55-8c6d-6dae3bf31cd2',\n",
       "  'e73ba61e-92c2-4adc-b33c-d20d84e80851',\n",
       "  '640742ee-00b7-4a0e-bbcf-b0a89d4eba6a',\n",
       "  'a3d63338-4fa1-4042-a583-94098c7e3fe8',\n",
       "  'e6366dde-bc38-4df2-b71e-93f202c52e75',\n",
       "  'd769650c-bcd9-4813-90cb-8acf73d22457',\n",
       "  'ef295f50-e3fa-495d-816a-b12b9eae2771',\n",
       "  '295337a4-9b3f-40b5-a8c8-2a68df0f0ff4',\n",
       "  '543535ad-f29e-4366-bec3-1ec0f0e29963',\n",
       "  '2eca13f9-e803-4bd5-aece-7b98de572dc8',\n",
       "  '9125ad77-2b52-464b-baf0-d8b7741e6caa',\n",
       "  '379ed064-a600-45e1-a57e-c9bae100cd40',\n",
       "  'd2ded019-6458-462d-99f6-e10879f91198',\n",
       "  '3bd221ae-3512-4609-adfe-e0f01cd422f1',\n",
       "  'e8114c0b-fba4-4907-b725-a0a0e340dda0',\n",
       "  '0fc1cb09-47e2-4b87-bdd8-a1c6a3d9b881',\n",
       "  'faa92c86-9fb1-4f63-8948-42aac612bb2e',\n",
       "  '3525a3d7-2fc9-4ee9-85fd-82937200ee8a',\n",
       "  '3bc09ceb-9006-41ac-a073-6fe0e718e3d9',\n",
       "  '5667bdeb-8532-425a-8ced-2c8acc6ba777',\n",
       "  '407652da-5c54-4eba-bac0-adaec64c3591',\n",
       "  '4b381c56-1647-402c-870d-b46f52be4c2b',\n",
       "  'a94b5e22-bd1e-4144-a698-6d20318d3470',\n",
       "  '7bcbeca9-bf18-4595-9187-a499bcb67520',\n",
       "  'f2efec17-b6f9-484e-a75d-b9eaf048a8b9',\n",
       "  'b5b3f0b3-4a7d-44f4-aefa-f7d0d148b36c',\n",
       "  '78b43461-702a-43ef-b622-96d03408164c',\n",
       "  '8a3aa0cd-5ded-469a-b5fa-506ad42e0fb2',\n",
       "  '8f7fa2f9-a04d-4f23-b967-8e0ac4d91332',\n",
       "  'a74ce3f2-aac3-410e-b68e-75b4ec2ace34',\n",
       "  '14f16479-4363-4963-9f93-e6f625f749d0',\n",
       "  '3e4fa11f-5373-4754-90c6-d8305353bdae',\n",
       "  'c469a290-0f52-4b76-a3c9-90b05c7f4153',\n",
       "  'febd3765-f6eb-4062-a998-21c238d6f1e4',\n",
       "  'e736f3ca-8fc0-47ab-bf71-3175a185c6bf',\n",
       "  '63314ce1-be76-42c1-8d94-9441606bb7fb',\n",
       "  'd9fc7e32-b911-4ea9-a6c0-b282b33c2410',\n",
       "  'c88e504e-dcb1-48bc-b3bb-eb37993899e9',\n",
       "  'ecf50a40-c731-4f79-97d4-738a6d84fdc9',\n",
       "  'd98e7550-f27a-4712-8d8c-f634eb0d51c2',\n",
       "  'd39e745b-a672-42e9-bcf1-bd05cff7e7b4',\n",
       "  '93507bb9-1a88-4373-a843-ccab5deb857a',\n",
       "  '12f127ea-3928-41e6-864f-561f3f87fef0',\n",
       "  '960cec99-d489-4564-80bf-6733c75ec991',\n",
       "  '0294bde1-e5c2-4eb7-bc98-52290cfe804b',\n",
       "  '38732384-f729-4c6e-88ad-1a4a35a6c67d',\n",
       "  '1b1fd6d2-6dc4-4c29-9f6a-26236af21a53',\n",
       "  'f89a1a6d-f9cb-497c-a30e-1b3c91ae6d98',\n",
       "  'c6306c4a-1261-4d39-af95-6662b1adbc49',\n",
       "  'e8b40415-fe0f-4696-b03c-549dea92732d',\n",
       "  '34abd231-7d09-4d16-a019-5eb86fa1e9da',\n",
       "  '2b64afe2-0c1a-4ab3-a154-996611eac635',\n",
       "  '8b62bc2c-dc0c-40af-8892-3a5a3c952124',\n",
       "  '5ecd2eb9-17c5-4db9-b0e1-3d4a018c33f0',\n",
       "  '3e6b6e05-9335-4fc7-8c4b-094b46d7aca5',\n",
       "  '65f298e4-67db-48cd-80e4-9443ded23a51',\n",
       "  '213d0edf-d3a9-4be5-aca3-30f04543a6a4',\n",
       "  '26719a9b-c2f4-4dfb-9f87-f3c53712afda',\n",
       "  '99338c25-2f36-421c-81c0-e8b7563909b2',\n",
       "  '6f2fb7f2-e057-4cc7-b644-b350027c52e7',\n",
       "  'e15de4d0-a335-4410-95b5-fd15a74014fe',\n",
       "  'e7d5f85d-9ce0-46d3-9509-6ece189f1b8b',\n",
       "  'a265a218-f82b-43a5-9fb9-dd0eee477f34',\n",
       "  'a95d8e94-bdcc-4fcd-a6c9-978135507a7f',\n",
       "  '78f5d490-9105-43b6-9119-d8e35ee54ade',\n",
       "  'cad4361f-1f72-4d86-a815-f154275527d3',\n",
       "  '95862ee7-5876-41eb-af59-37bd5456c8cd',\n",
       "  '9a8181c7-a597-4af4-9188-5ca725b9b62f',\n",
       "  '36c8b8fd-d4c0-49fa-a0e1-995a0f27cd53',\n",
       "  '14ede7c3-bc83-4f4d-8542-2f1bc538f8bf',\n",
       "  '8c6aa116-b431-48ba-b893-b64b13c64424',\n",
       "  '52632008-7170-4c0f-b808-8f628f8f0da8',\n",
       "  'c24c784f-f6e1-4baf-a8cb-db4647ecff41',\n",
       "  '3d8df225-38a2-4a69-ae0b-fbaec30d825d',\n",
       "  'e42351a5-2581-4e73-8437-7677bba22500',\n",
       "  'a6c2678d-e1fc-49d9-b83a-f5d71fdb3401',\n",
       "  '013413f3-6920-4e66-91b7-dd76818a9f2a',\n",
       "  '8726af28-ae4e-4671-bba5-f6a58c97931c',\n",
       "  '0600a5aa-cce2-461a-8748-eab8557320ff',\n",
       "  '72ca54d9-ae7a-456a-89dc-fc6563d94664',\n",
       "  'f5586474-04e0-4f3d-8d36-b51ea7c85bcb',\n",
       "  '7c6c80bc-8c1f-4d22-bf53-c360138fa84d',\n",
       "  'fba78bc2-265c-4052-b328-ce0b90d4c798',\n",
       "  '5c53c39c-2454-4c51-850a-06564315eb59',\n",
       "  '232ebe74-31ac-47b7-96fd-12d018ee6f9e',\n",
       "  'ee3d150d-3366-4a23-98d5-b526153333d9',\n",
       "  'eef07b0b-7c65-4555-8e2b-fc773b844dd2',\n",
       "  'ee356b4c-e666-4cfa-84e9-8bbf63f756ce',\n",
       "  'a0cd4e77-8708-4293-8654-004d04bebc77',\n",
       "  '5899d602-53a0-40c9-9f7f-e9c0b8813931',\n",
       "  '8104a14a-30a6-46c9-9ab2-3f84626dc88f',\n",
       "  '751ad8c4-1998-4e1a-bf12-a90f88c4c590',\n",
       "  '252546ea-3a30-4049-af49-a75d8a7ef880',\n",
       "  'baaf3a5f-564f-467c-bce2-5b336ec7a44d',\n",
       "  '3765e44e-e8fa-4b81-bf48-2c5326954051',\n",
       "  'ac41e2a9-fecd-48f9-9176-28f90aa07d08',\n",
       "  'c9679850-fa9c-4589-9298-cd3bbfc66541',\n",
       "  'e7b0ea1d-74f7-4287-8412-5e9bd6c611ea',\n",
       "  '991472b4-a37f-44e2-8541-65f107542944',\n",
       "  '4ff35de6-1268-47de-8c14-7840d52fecc0',\n",
       "  '50ec5621-c70f-4040-b49f-9506052f682c',\n",
       "  '94718338-8250-431e-90a1-ec3e1fd2a6ef',\n",
       "  '92efd1b3-e40a-4a7f-af23-c36b1743fd3d',\n",
       "  '23ec91f6-e282-4e44-88fb-37af45300c81',\n",
       "  '898fa022-9b93-4972-9346-05852f5dd0bb',\n",
       "  '4d86d6ba-8ce6-4d59-880f-16a8724ef4c1',\n",
       "  'fc3d5543-afa7-4c02-8d9e-672ac426e8f3',\n",
       "  '40a4dd5a-ddf5-44dc-bec8-58cc6e76b270',\n",
       "  '590cf724-893c-41bf-98c2-106ab1980739',\n",
       "  '11e48479-1805-4a8c-b567-7638aa57e30b',\n",
       "  '1b234734-660c-4598-b95d-16df9c8029cb',\n",
       "  '5e42232b-4f04-4060-b1b0-51883591d648',\n",
       "  '29cacdda-812c-4a60-8589-45e5d7f74f20',\n",
       "  '42176741-cbc1-4dc2-a196-a4276d9fee51',\n",
       "  '4f8247b0-a52e-4548-b69c-f88433e29d86',\n",
       "  'a53bc8e9-5e15-4cdd-af51-bbae5eeb70d1',\n",
       "  '59cebe74-99eb-4b6a-bad7-d0e23519eccc',\n",
       "  '8d9052b0-a351-4abe-985a-622cdf8966c7',\n",
       "  'ba1fe5df-1c41-4896-9023-4f4cf0034bc5',\n",
       "  '5738a18c-0743-4ab8-bd5d-4644eed08db4',\n",
       "  'ff98ecb5-da15-40d2-a90b-1e6576ea83f5',\n",
       "  '004a351e-ba2e-4c78-a7a9-89fef6cf78d9',\n",
       "  '8a2eeb58-f0e5-43ae-81e2-ac5b3e06d259',\n",
       "  'b854914e-3da2-4d1f-af61-1eb206b5172a',\n",
       "  '0499287f-c4ca-4101-9a4a-e74db4147f70',\n",
       "  '2349bf22-5715-47f4-b964-e55eaa05f1b9',\n",
       "  'f0c30ff1-fb37-4390-aae5-2f327ad50cfa',\n",
       "  '771c646b-de8d-4bae-95a8-e3b84e54a4c3',\n",
       "  '8a895d8a-b91c-42d3-ba50-77bde2d35d9b',\n",
       "  'ab04a9be-2bfe-41b9-9800-650976542990',\n",
       "  '9fa00f02-6d73-451f-9203-518edc9440a8',\n",
       "  '052f91ac-73c1-4055-b6f4-3e31da17bfe6',\n",
       "  '628329a6-f0c6-49aa-ad02-0424bc360e62',\n",
       "  'fe0b68fa-0921-4257-ac6f-c63438d8699d',\n",
       "  'bea5fdac-5e09-4c99-b318-3e53791d2378',\n",
       "  'fc31ccfb-a920-4cda-a377-d1741aed6872',\n",
       "  '74ab30f2-3a7a-46b8-b331-3c962028ca06',\n",
       "  'ace6b515-5f76-4be4-a907-16ceaf382ae9',\n",
       "  'c3881acf-f425-4654-985d-ea4e1f15b630',\n",
       "  '7dee50b9-0ff2-479c-9a8a-7230837f3e2b',\n",
       "  '758bdd22-7e5c-4b18-8f91-b0721dc9247f',\n",
       "  'c04905ef-c76f-49ba-997c-e45a926afc9b',\n",
       "  '59405906-e864-4b46-a8c5-c0ece0db7e32',\n",
       "  '104e5aa9-4d6d-42ac-80e3-4176549c1464',\n",
       "  '2e2e9c99-689d-459c-a0ff-5234c1b17eab',\n",
       "  '364cef14-720e-4cd1-a560-373c7d06907a',\n",
       "  '646f929d-21a1-47b4-a8a5-e00c663aa663',\n",
       "  'd737063c-cbd9-4a55-a4d3-e96a92b7bcc2',\n",
       "  '075f4a1c-bcfd-4038-8918-2af4d0546e49',\n",
       "  '01ee2685-c776-4cbc-b500-f6bf5531032d',\n",
       "  '51bf186e-92bf-437d-bad8-f69e404b502a',\n",
       "  '3ab00d93-58fc-44a3-8c87-e8329eb6a317',\n",
       "  '8c4e83fc-e942-4cdf-ae40-f34af78fba8d',\n",
       "  '1e61e5f3-0b34-46db-baef-7df27a91bf21',\n",
       "  '1c003a03-5bb7-4c0a-b46c-210e9a288374',\n",
       "  '1934d863-25bd-491d-a2c6-4eaf4dacc1ad',\n",
       "  'bd3db9ea-2b6e-40bf-b6df-34a3b404e494',\n",
       "  '9c811073-818e-4046-9f91-61a28e5678e3',\n",
       "  '43cb9b1a-0674-498a-bc4f-38fa8c62fbea',\n",
       "  'd57efc51-ccd3-4ffa-98a0-22b14a374704',\n",
       "  'f5ced57d-b7e6-4aed-8180-4e97ca6480d1',\n",
       "  'f589f188-5332-40b6-bc15-e12484093cdc',\n",
       "  '77146b9b-0249-43b3-9c7f-6199ea07d9e7',\n",
       "  'd56e4f52-c9a8-442b-a452-2e9ec53f5580',\n",
       "  '59c16095-4ce0-4f7b-94f4-2e92e9faf3c7',\n",
       "  '450d6538-d457-4600-ac31-154c5bf96eb9',\n",
       "  '91d6a700-e789-4efe-9ed2-a9029dafdc84'],\n",
       " 'embeddings': None,\n",
       " 'documents': [\"<h1 id='0' style='font-size:22px'>Aligning Instruction Tuning with Pre-training</h1>\",\n",
       "  \"<table id='1' style='font-size:18px'><tr><td>Yiming Liang * 123</td><td>* 45 Tianyu Zheng</td><td>*45 Xinrun Du</td><td>*4 Ge Zhang</td></tr><tr><td>Jiaheng Liu 4 Xingwei Qu 4</td><td>Wenqiang Zu 12</td><td>Xingrun Xing 12</td><td>Chujie Zheng 5 Lei Ma 36</td></tr><tr><td>Wenhu Chen 4 Guoyin Wang 5</td><td>Zhaoxiang Zhang 2</td><td>Wenhao Huang 4</td><td>Xiang Yue 4 Jiajun Zhang 12</td></tr></table>\",\n",
       "  \"<p id='2' data-category='paragraph' style='font-size:20px'>Abstract</p>\",\n",
       "  \"<br><p id='3' data-category='paragraph' style='font-size:18px'>Instruction tuning enhances large language mod-<br>els (LLMs) to follow human instructions across<br>diverse tasks, relying on high-quality datasets to<br>guide behavior. However, these datasets, whether<br>manually curated or synthetically generated, are<br>often narrowly focused and misaligned with the<br>broad distributions captured during pre-training,<br>limiting LLM generalization and effective use<br>of pre-trained knowledge. We propose Aligning<br>Instruction Tuning with Pre-training (AITP), a<br>method that bridges this gap by identifying COV-<br>erage shortfalls in instruction-tuning datasets and<br>rewriting underrepresented pre-training data into<br>high-quality instruction-response pairs. This ap-<br>proach enriches dataset diversity while preserving<br>task-specific objectives. Evaluations on three fully<br>open LLMs across eight benchmarks demonstrate<br>consistent performance improvements with AITP.<br>Ablations highlight the benefits of adaptive data<br>selection, controlled rewriting, and balanced inte-<br>gration, emphasizing the importance of aligning<br>instruction tuning with pre-training distributions<br>to unlock the full potential of LLMs.</p>\",\n",
       "  \"<p id='4' data-category='paragraph' style='font-size:20px'>1. Introduction</p>\",\n",
       "  \"<br><header id='5' style='font-size:14px'>2025<br>Jan<br>20<br>[cs.AI]<br>arXiv:2501.09368v3</header>\",\n",
       "  \"<p id='7' data-category='footnote' style='font-size:18px'>* 1School of Artificial Intelligence, Uni-<br>Equal contribution<br>versity of Chinese Academy of Sciences 2Institute of Automa-<br>tion, Chinese Academy of Sciences 3BAAI 4M-A-P 501.ai<br>'Peking University. Correspondence to: Jiaheng Liu <buaalji-<br>aheng @gmail.com>, wenhaohuang <rubio8741@gmail.com>,<br>JiaJun Zhang <jjzhang@nlpr.ia.ac.cn>.</p>\",\n",
       "  \"<p id='8' data-category='paragraph' style='font-size:18px'>Preprint. Work in Progress</p>\",\n",
       "  '<br><figure id=\\'9\\'><img style=\\'font-size:14px\\' alt=\"15\\n15\\n10 10-\\n2\\n5 2\\n5\\nComponent\\n0\\n0\\n-5 Component\\nPCA\\nPCA\\n-5\\n-10\\n-10\\n-15\\n-15\\n-20\\n-20 -10 0 10 20 -20 -15 -10 -5 0 5 10 15\\nPCA Component 1 PCA Component 1\" data-coord=\"top-left:(636,413); bottom-right:(1137,661)\" /></figure>',\n",
       "  \"<p id='10' data-category='paragraph' style='font-size:18px'>Figure 1: Visualization of Projections. The red regions<br>at the bottom represent the pre-training corpus, while the<br>light blue regions above represent the SFT datasets. Darker<br>areas indicate a higher concentration of data points, whereas<br>lighter areas represent sparser distributions. Additional pro-<br>jections are shown in Appendix A.</p>\",\n",
       "  \"<p id='11' data-category='paragraph' style='font-size:18px'>on the other hand, frequently depend on expensive APIs<br>of strong models and are tightly coupled with their gener-<br>ation pipelines, limiting flexibility (Peng et al., 2023; Lian<br>et al., 2023). Additionally, manually combining open-source<br>datasets, as seen in efforts like OpenHermes-2.5 (Teknium,<br>2023) and Tulu- V2 (Ivison et al., 2023), often overlooks the<br>underlying data distributions, leading to inefficiencies.</p>\",\n",
       "  \"<p id='12' data-category='paragraph' style='font-size:18px'>Pre-training corpora, by contrast, reflect broader real-world<br>distributions and align closely with the internal knowledge<br>of LLMs, making them a rich source of high-quality super-<br>visory signals. However, current instruction-tuning methods<br>fail to leverage this alignment, creating a fundamental gap<br>in optimizing dataset coverage and distribution. Addressing<br>this challenge requires aligning instruction-tuning datasets<br>with pre-training distributions to fully exploit the knowledge<br>embedded in LLMs.</p>\",\n",
       "  \"<p id='13' data-category='paragraph' style='font-size:18px'>In this paper, we propose Aligning Instruction Tuning with<br>Pre-training (AITP), a method that systematically bridges<br>this gap. Rather than generating instruction-response pairs<br>from scratch, AITP identifies gaps in existing datasets by<br>comparing their distribution to that of the pre-training cor-<br>pus. Underrepresented data is then rewritten into high-<br>quality instruction-response pairs, enhancing dataset cover-<br>age and alignment. As shown in Figure 2, AITP involves</p>\",\n",
       "  \"<footer id='14' style='font-size:16px'>1</footer>\",\n",
       "  \"<header id='15' style='font-size:16px'>MAP</header>\",\n",
       "  '<figure id=\\'16\\'><img style=\\'font-size:14px\\' alt=\"Raw Text\\nText: # Confidence Interval calculation for\\nPower Density Estimation in MATLAB\\n,\\nAnd\\nFirst of all, I am new to these statistics stuff but\\n♥ background. I try to......\\nvery interested in the\\nPretraining Corpus Original SFT Dataset Difference Set Rewriting\\nInstruction Data\\nQ: Why does MATLAB\\'s pwelch function use 2k\\ndegrees of freedom for confidence intervals in\\npower spectral density estimation, and what is\\nSupervised + the reasoning behind this choice?\\nA: In the calculation of confidence intervals for\\npower spectral density (PSD) estimation using\\nFine-Tuning Welch\\'s method, MATLAB\\'s pwelch function\\nuses 2k degrees of freedom instead of k-1 or 2k-\\nCombined Set Original SFT Dataset Rewritten Set 1. This choice is based on\" data-coord=\"top-left:(110,131); bottom-right:(1134,389)\" /></figure>',\n",
       "  \"<p id='17' data-category='paragraph' style='font-size:16px'>Figure 2: The pipeline of AITP. AITP first generates a difference set, then rewrites the raw text into instruction-response<br>pairs to form a rewritten set, and finally combines the rewritten set with the original SFT dataset for model training.</p>\",\n",
       "  \"<p id='18' data-category='paragraph' style='font-size:16px'>three stages: (1) generating a difference set based on density<br>comparisons, (2) rewriting raw text into instruction-response<br>pairs, and (3) integrating these pairs into the original dataset<br>for fine-tuning.</p>\",\n",
       "  \"<p id='19' data-category='paragraph' style='font-size:16px'>Figure 1 visualizes the significant distributional differences<br>between instruction-tuning datasets and the pre-training cor-<br>pus, underscoring the need for such alignment. Through<br>experiments on three open-source LLMs across eight bench-<br>marks, we demonstrate that AITP consistently improves<br>model performance. Detailed ablation studies highlight<br>the effectiveness of adaptive data selection and integration,<br>showing how AITP guides instruction tuning toward more<br>effective and generalizable fine-tuned models.</p>\",\n",
       "  \"<p id='20' data-category='paragraph' style='font-size:16px'>Our contributions include: 1) Demonstrating the distribu-<br>tional gaps between instruction-tuning datasets and pre-<br>training corpora through visualization. 2) Proposing the<br>AITP method to adaptively optimize instruction-tuning<br>datasets by leveraging pre-training corpora as a reference.<br>3) Validating the effectiveness of AITP with extensive ex-<br>periments and ablation studies.</p>\",\n",
       "  \"<h1 id='21' style='font-size:20px'>2. Methods</h1>\",\n",
       "  \"<br><p id='22' data-category='paragraph' style='font-size:16px'>2.1. Difference Set Generation</p>\",\n",
       "  \"<p id='23' data-category='paragraph' style='font-size:16px'>In this section, we define the process of difference set gener-<br>ation, isolating data points from the pre-training corpora that<br>differ from those in the SFT dataset. The goal is to identify<br>regions in the pre-training data distribution that are absent<br>from or sparsely populated in the supervised fine-tuning<br>(SFT) data. This can be formalized as follows:</p>\",\n",
       "  \"<p id='24' data-category='equation'>$$D_{\\\\mathrm{diff}}=\\\\{d_{i}|d_{i}\\\\in D_{\\\\mathrm{pretrin}},\\\\Delta(d_{i},D_{\\\\mathrm{SFT}})<\\\\tau\\\\}\\\\qquad(1)$$</p>\",\n",
       "  \"<br><p id='25' data-category='paragraph' style='font-size:16px'>DSFT, Ddiff represent the pre-training<br>Where Dpretrain,<br>dataset, the SFT dataset and the resulting difference set,<br>respectively. △(di, DSFT) represents the density estimate of<br>the data point di in the SFT dataset, and T is the threshold<br>that determines whether a data point should be included in<br>the difference set. To achieve this, we outline the procedure</p>\",\n",
       "  \"<br><p id='26' data-category='paragraph' style='font-size:16px'>in three main stages: data representation, density estimation,<br>and identification of the difference set.</p>\",\n",
       "  \"<p id='27' data-category='paragraph' style='font-size:16px'>2.1.1. DATA REPRESENTATION</p>\",\n",
       "  \"<p id='28' data-category='paragraph' style='font-size:16px'>Each data point is represented as a vector derived from the<br>final-layer embedding of the model. We then apply dimen-<br>sionality reduction (DR) to project these high-dimensional<br>embeddings into two-dimensional coordinates, facilitating<br>visualization and density comparison across datasets. This<br>process can be formalized as follows:</p>\",\n",
       "  \"<p id='29' data-category='equation'>$$(x_{i},y_{i})=\\\\mathrm{DR}(\\\\mathrm{Model}(d_{i}))$$</p>\",\n",
       "  \"<p id='30' data-category='paragraph' style='font-size:14px'>Applying the same dimension reduction to both pre-training<br>and SFT embeddings results in two sets of two-dimensional<br>vectors:</p>\",\n",
       "  \"<br><caption id='31' style='font-size:22px'>(2)</caption>\",\n",
       "  \"<p id='32' data-category='equation'>$$\\\\begin{array}{l}{{Z_{\\\\mathrm{pretrain}}=\\\\{(x_{i},y_{i})\\\\mid d_{i}\\\\in D_{\\\\mathrm{pretrain}}\\\\}}}\\\\\\\\ {{Z_{\\\\mathrm{SFT}}=\\\\{(x_{i},y_{i})\\\\mid d_{i}\\\\in D_{\\\\mathrm{SFT}}\\\\}}}\\\\end{array}$$</p>\",\n",
       "  \"<p id='33' data-category='paragraph' style='font-size:16px'>2.1.2. DENSITY ESTIMATION</p>\",\n",
       "  \"<br><caption id='34' style='font-size:20px'>(3)</caption>\",\n",
       "  \"<p id='35' data-category='paragraph' style='font-size:16px'>To compare data distributions between the pre-training and<br>SFT datasets, we use Kernel Density Estimation (KDE) to<br>visualize the density of points for each dataset. The KDE<br>function f(x, y) estimates the density at any location (x,y)<br>based on neighboring points:</p>\",\n",
       "  \"<br><caption id='36' style='font-size:20px'>(4)</caption>\",\n",
       "  \"<p id='37' data-category='equation'>$$\\\\hat{f}(x,y)=\\\\frac{1}{n h_{x}h_{y}}\\\\sum_{i=1}^{n}K\\\\left(\\\\frac{x-x_{i}}{h_{x}},\\\\frac{y-y_{i}}{h_{y}}\\\\right)$$</p>\",\n",
       "  \"<br><p id='38' data-category='paragraph' style='font-size:18px'>K(·,·) is the kernel function, typically Gaussian:</p>\",\n",
       "  \"<br><caption id='39' style='font-size:20px'>(5)</caption>\",\n",
       "  \"<p id='40' data-category='equation'>$$K((x,y),(x^{\\\\prime},y^{\\\\prime}))=\\\\exp\\\\left(-\\\\frac{(x-x^{\\\\prime})^{2}+(y-y^{\\\\prime})^{2}}{2\\\\sigma^{2}}\\\\right)~(6)$$</p>\",\n",
       "  \"<p id='41' data-category='paragraph' style='font-size:16px'>Where (x, y) and (x1, y!) are two two-dimensional data<br>points, hx, hy and o are bandwidth parameters that con-<br>trol the smoothness in the x direction, y direction and kernel<br>respectively. The KDE visualization highlights distribution<br>differences, identifying regions of divergence between the<br>pretraining and SFT datasets.</p>\",\n",
       "  \"<footer id='42' style='font-size:16px'>2</footer>\",\n",
       "  \"<header id='43' style='font-size:16px'>MAP</header>\",\n",
       "  \"<p id='44' data-category='paragraph' style='font-size:16px'>2.1.3. FINDING DIFFERENCE SET</p>\",\n",
       "  \"<p id='45' data-category='paragraph' style='font-size:16px'>The difference set is identified based on the density estimates<br>from the SFT dataset. Specifically, if a point di in the<br>pre-training dataset has a low-density estimate within the<br>SFT dataset, we classify this point as absent or sparsely<br>populated in the SFT data. Such points contribute to the<br>observed distributional differences between the two datasets,<br>and we define them formally as:</p>\",\n",
       "  \"<p id='46' data-category='equation'>$$D_{\\\\mathrm{diff}}=\\\\{d_{i}|d_{i}\\\\in{\\\\cal D}_{\\\\mathrm{pretrain}},\\\\hat{f}_{\\\\mathrm{SFT}}(x_{i},y_{i})<\\\\tau\\\\}\\\\qquad(7)$$</p>\",\n",
       "  \"<br><p id='47' data-category='paragraph' style='font-size:16px'>fSFT (xi, yi) represents the density estimate of the data point<br>di from the pretrain corpus within the SFT dataset.</p>\",\n",
       "  \"<p id='48' data-category='equation'>$$\\\\hat{f}_{\\\\mathrm{SFT}}(x_{i},y_{i})=\\\\frac{1}{n h_{x}h_{y}}\\\\sum_{j=1}^{n}K\\\\left(\\\\frac{x_{i}-x_{j}}{h_{x}},\\\\frac{y_{i}-y_{j}}{h_{y}}\\\\right)$$</p>\",\n",
       "  \"<p id='49' data-category='paragraph' style='font-size:16px'>Where (xi, yi) E Zpretrain, (xj,yj) E ZSFT. n is the total<br>number of points in the SFT dataset.</p>\",\n",
       "  \"<h1 id='50' style='font-size:16px'>2.2. Data Transformation of Difference Set</h1>\",\n",
       "  \"<p id='51' data-category='paragraph' style='font-size:16px'>The data transformation phase is designed to convert raw<br>text from the pre-training data within the difference set<br>into instruction-pair data formatted for SFT. This process<br>consists of three key steps. First, we develop a query gen-<br>eration prompt to guide the model in generating relevant<br>questions from the raw text. Next, we implement a query<br>scoring prompt to assess the quality of each generated<br>query. Low-quality queries are filtered out based on these<br>scores, enabling us to eliminate unsuitable questions before<br>answer generation, thus conserving computational resources.<br>Finally, an answer generation prompt is applied to in-<br>struct the model in generating responses to the remaining<br>high-quality queries. These three processes can be formally<br>modeled as follows:</p>\",\n",
       "  \"<p id='52' data-category='equation'>$${\\\\dot{y}}_{t}^{l}={\\\\underset{\\\\mathrm{arg\\\\,max}}{\\\\operatorname{arg\\\\,max}P}}{\\\\bigl(}y_{t}\\\\mid p_{\\\\mathrm{generate}},t,y_{<t};\\\\theta{\\\\bigr)}$$</p>\",\n",
       "  \"<p id='53' data-category='equation'>$$\\\\dot{y}_{t}^{s}\\\\,=\\\\,\\\\arg\\\\operatorname*{max}_{s\\\\,t}P(y_{t}\\\\,\\\\mid p_{\\\\mathrm{score}},\\\\,i,y_{<t};\\\\theta)$$</p>\",\n",
       "  \"<br><p id='54' data-category='paragraph' style='font-size:14px'>Yt</p>\",\n",
       "  \"<br><p id='55' data-category='equation'>$$\\\\hat{y}_{t}^{a}\\\\,=\\\\,{\\\\bf a r g.}\\\\ln_{u_{t}}{\\\\bf u}.{\\\\bf0}\\\\hat{x}\\\\,P(y_{t}\\\\,\\\\mid p_{\\\\mathrm{answer}},\\\\dot{t},y_{<t};\\\\theta)$$</p>\",\n",
       "  \"<p id='56' data-category='paragraph' style='font-size:16px'>where Pgenerate, Pscore, and Panswer represent the prompts used<br>for query generation, query scoring, and answer generation,<br>respectively. Here, t denotes the raw text, 2 represents the<br>instruction, and 0 denotes the model parameters. The yi, Yt,<br>and yt represent the most probable tokens generated at time<br>step t for the instruction, score, and answer, respectively.<br>The detailed prompts utilized in this process can be found<br>in Appendix C.</p>\",\n",
       "  \"<h1 id='57' style='font-size:20px'>2.3. Training</h1>\",\n",
       "  \"<p id='58' data-category='paragraph' style='font-size:14px'>In this phase, the model is trained on a combined dataset that<br>includes both the rewritten data derived from the difference</p>\",\n",
       "  \"<br><p id='59' data-category='paragraph' style='font-size:16px'>set and the original SFT dataset. Notably, the model trained<br>on the combined dataset is the same as the one trained on the<br>pre-training corpus. This serves two main purposes: first, it<br>ensures consistency between the supplemented knowledge<br>distribution and the model's internal knowledge. Second,<br>high-quality instruction-pair data helps correct semantic<br>inaccuracies that may arise from formatting errors in the<br>pre-training corpus. The loss function for training is defined<br>as follows:</p>\",\n",
       "  \"<caption id='60' style='font-size:20px'>(12)</caption>\",\n",
       "  \"<br><p id='61' data-category='equation'>$${\\\\mathcal{L}}_{\\\\mathrm{avg}}=-{\\\\frac{1}{N}}\\\\sum_{t=1}^{N}\\\\log P(a_{t}\\\\mid i,a_{<t};\\\\theta)$$</p>\",\n",
       "  \"<p id='62' data-category='paragraph' style='font-size:20px'>(8)</p>\",\n",
       "  \"<br><p id='63' data-category='paragraph' style='font-size:16px'>where N denotes the sequence length, i and a denote the<br>instruction and response sequence, respectively.</p>\",\n",
       "  \"<p id='64' data-category='paragraph' style='font-size:22px'>3. Experiment Settings</p>\",\n",
       "  \"<br><p id='65' data-category='paragraph' style='font-size:16px'>3.1. Evaluation</p>\",\n",
       "  \"<caption id='66' style='font-size:20px'>(9)</caption>\",\n",
       "  \"<caption id='67' style='font-size:18px'>(10)</caption>\",\n",
       "  \"<br><caption id='68' style='font-size:20px'>(11)</caption>\",\n",
       "  \"<br><p id='69' data-category='paragraph' style='font-size:16px'>We evaluate the model's instruction-following ability using<br>the IFEval benchmark (Zhou et al., 2023b), which is unbi-<br>ased because it does not rely on LLM-generated evaluation<br>scores. It provides four types of accuracy scores: Prompt-<br>level Strict-accuracy (P-S), Instruction-level Strict-accuracy<br>(I-S), Prompt-level Loose-accuracy (P-L), and Instruction-<br>level Loose-accuracy (I-L). We use the OpenCompass, a<br>comprehensive, one-stop platform for LLM evaluation (Con-<br>tributors, 2023). We evaluate the effectiveness of AITP<br>across seven standard benchmarks. These benchmarks pro-<br>vide a comprehensive evaluation of the diverse capabili-<br>ties of language models across various tasks and domains.<br>MMLU (Hendrycks et al., 2021) offers a broad assessment<br>of multitask reasoning and knowledge retrieval, while ARC-<br>c (Clark et al., 2018) and GPQA-diamond (Rein et al.,<br>2023) focus on complex scientific reasoning and physics-<br>specific understanding, respectively. For code generation<br>and problem-solving, HumanEval (Chen et al., 2021) and<br>MBPP (Austin et al., 2021) measure a models ability to<br>write correct and multi-step logical solutions. Addition-<br>ally, HellaSwag (Zellers et al., 2019) tests commonsense<br>reasoning by predicting contextually appropriate continua-<br>tions, and GSM8K (Cobbe et al., 2021) challenges models<br>with elementary-level math problems, combining natural<br>language understanding with mathematical reasoning.</p>\",\n",
       "  \"<p id='70' data-category='paragraph' style='font-size:18px'>3.2. Main Setting</p>\",\n",
       "  \"<p id='71' data-category='paragraph' style='font-size:16px'>Our experiments utilize three fully open-source models:<br>OLMo (Groeneveld et al., 2024), MAP-Neo (Zhang et al.,<br>2024a) and Pythia (Biderman et al., 2023). These models<br>not only release model weights but also training datasets and<br>intermediate checkpoints, aiming to facilitate reproduction<br>and advance scientific research in LLMs. In this paper,<br>the OLMo-7B-base, MAP-Neo-7B-base, and Pythia-12B</p>\",\n",
       "  \"<footer id='72' style='font-size:16px'>3</footer>\",\n",
       "  \"<header id='73' style='font-size:14px'>MAP</header>\",\n",
       "  \"<p id='74' data-category='paragraph' style='font-size:14px'>models, along with their corresponding pre-training corpora,<br>are chosen as the foundational setup for AITP. The OLMo-<br>7B-SFT and MAP-Neo-7B-SFT-v0.1 models are used as<br>baselines to validate the effectiveness of AITP. Since the<br>SFT dataset for Pythia has not been released, we use Tulu-v2<br>for fine-tuning as the baseline for Pythia.</p>\",\n",
       "  \"<p id='75' data-category='paragraph' style='font-size:16px'>Due to the substantial storage and computational resources<br>required for the data embedding and shift phase, we don't<br>use the full pre-training corpus given resource constraints.<br>Instead, we apply reservoir sampling (Vitter, 1985), an algo-<br>rithm that enables uniform sampling from streaming data,<br>ensuring that the sampled subset maintains a distribution<br>consistent with the full pre-training corpus. The reservoir<br>sampling algorithm is described in the Appendix B.</p>\",\n",
       "  \"<br><p id='76' data-category='paragraph' style='font-size:16px'>We conduct experiments on the NVIDIA A800-SXM4-<br>80GB, with the difference set generation phase taking ap-<br>proximately 56 GPU hours. The Data Transformation Set-<br>ting phase utilizes the vLLM (Kwon et al., 2023) frame-<br>work to accelerate inference, requiring approximately 640<br>GPU hours, while the Training Setting phase, involving<br>full-parameter fine-tuning, takes approximately 256 GPU<br>hours.</p>\",\n",
       "  \"<h1 id='77' style='font-size:18px'>3.3. Difference Set Generation Setting</h1>\",\n",
       "  \"<p id='78' data-category='paragraph' style='font-size:16px'>We obtain the text embeddings using two encoding mod-<br>els: BAAI/bge-m3 (Chen et al., 2024) and sentence-<br>transformers/all-MiniLM-L6-v2 (Reimers & Gurevych,<br>2019). We choose the all-MiniLM-L6-v2 model for its<br>simplicity and ease of use, while bge-m3 can handle multi-<br>lingual input and varying input lengths, from short sentences<br>to long documents up to 8192 tokens. For the pre-training<br>corpus, we directly use the text field as input for encoding.<br>For the SFT dataset, we concatenate the instruction and<br>response fields to form a complete input text for encoding.<br>After obtaining the text embeddings, we apply principal<br>component analysis (PCA) to reduce the high-dimensional<br>data to two dimensions, thus simplifying the visualization<br>and analysis. For visualization, we employ kernel density<br>estimation (KDE), which effectively represents data density<br>by smoothing distributions and avoids the issue of point<br>overlap in dense regions that can occur in scatter plots.</p>\",\n",
       "  \"<p id='79' data-category='paragraph' style='font-size:16px'>To identify the difference set, we use two settings: density<br>estimation and density comparison. The density estimation<br>setting is presented in Equation 7 and Equation 8. In this<br>paper, the density comparison setting compares the den-<br>sity estimation of each data point in the pre-training and<br>SFT datasets, selecting difference points based on their den-<br>sity ratio. The density comparison setting is formalized as<br>follows:</p>\",\n",
       "  \"<p id='80' data-category='equation'>$$\\\\hat{f}_{\\\\mathrm{Pre}}(x_{i},y_{i})=\\\\frac{1}{m h_{x}h_{y}}\\\\sum_{k=1,k\\\\neq i}^{m}K\\\\left(\\\\frac{x_{i}-x_{k}}{h_{x}},\\\\frac{y_{i}-y_{k}}{h_{y}}\\\\right)\\\\quad(13$$</p>\",\n",
       "  \"<br><p id='81' data-category='equation'>$$D_{\\\\mathrm{dif}}=\\\\{d_{i}|d_{i}\\\\in D_{\\\\mathrm{pretrain}},\\\\frac{\\\\hat{f}_{\\\\mathrm{pre}}(x_{i},y_{i})}{\\\\hat{f}_{\\\\mathrm{SFT}}(x_{i},y_{i})}>\\\\tau\\\\}$$</p>\",\n",
       "  \"<br><caption id='82' style='font-size:22px'>(14)</caption>\",\n",
       "  \"<p id='83' data-category='paragraph' style='font-size:14px'>Where (xi, Yi), (Xk, Yk) E Zpretrain. m is the total number<br>of points in the pre-training dataset. In this paper, we set T<br>to 0.7 and 1.0 for equations (7) and (14), respectively.</p>\",\n",
       "  \"<p id='84' data-category='paragraph' style='font-size:16px'>3.4. Data Transformation Setting</p>\",\n",
       "  \"<p id='85' data-category='paragraph' style='font-size:14px'>We employ the Qwen2.5-72B-Instruct (Team, 2024) model<br>for data transformation. In the instruction generation phase,<br>we ensure that generated instructions are contextually rel-<br>evant and self-contained, meaning they should not require<br>the raw text as background for understanding. During the<br>instruction scoring phase, each instruction is assessed based<br>on three criteria: quality, difficulty, and the additional infor-<br>mation required. We rate the quality of each instruction on a<br>scale from 1 to 10 based on its clarity, assess its difficulty de-<br>pending on whether specialized knowledge is required, and<br>mark the additional information required field true or false,<br>based on whether extra information is needed to fully an-<br>swer the query. In the answer generation phase, the model is<br>prompted to produce comprehensive and accurate responses<br>informed by both the instruction and text content, ensuring<br>that the responses are detailed and well-aligned with the<br>question context.</p>\",\n",
       "  \"<p id='86' data-category='paragraph' style='font-size:18px'>3.5. Ablation Setting</p>\",\n",
       "  \"<p id='87' data-category='paragraph' style='font-size:14px'>We conduct two ablation studies to evaluate the impact of<br>dataset size and distillation during the data transformation<br>process on AITP. To determine whether the improvement<br>arises from the increased size of the SFT dataset after adding<br>the rewritten difference set, we sample a subset from the<br>combined dataset (original SFT and rewritten difference<br>set) that is equal in size to the original SFT dataset and<br>use it for training. To test whether the improvement is due<br>to distillation in the data transformation phase, we replace<br>the original SFT dataset with a subset sampled from the<br>pre-training corpus that shares a similar distribution and<br>train the model on the combined dataset (the rewritten same<br>set and the rewritten difference set). This setup aligns with<br>the approach used in LongForm (Kksal et al., 2023), which<br>trains models on fully rewritten pre-training datasets but<br>overlooks leveraging existing high-quality datasets.</p>\",\n",
       "  \"<p id='88' data-category='paragraph' style='font-size:20px'>3.6. Training Setting</p>\",\n",
       "  \"<p id='89' data-category='paragraph' style='font-size:14px'>We use combined datasets in AITP to train three open-source<br>models: OLMo, MAP-Neo, and Pythia. The rewritten differ-<br>ence set in the combined datasets is obtained by subtracting<br>the corresponding SFT datasets (TuluV2, Neo-SFT, Tulu V2)<br>from the respective pre-training corpora (Dolma, Matrix,<br>and Pile). Since the SFT dataset for Pythia has not been<br>released, we use TuluV2 as a substitute. Full-parameter</p>\",\n",
       "  \"<footer id='90' style='font-size:14px'>4</footer>\",\n",
       "  \"<header id='91' style='font-size:20px'>MAP</header>\",\n",
       "  '<figure id=\\'92\\'><img style=\\'font-size:16px\\' alt=\"15 15 15 15\\nDense region\\nDense region in pre-training\\nin difference set\\ncorpus: example ①② ③\\n10 10\\n10 10\\n 17\\n2\\n2 5\\n5 2\\n5 2\\n5\\nComponent\\n0\\n0 0 0\\n-5 Component\\n-5 Component\\n-5 Component\\n-5\\nPCA\\nPCA\\nPCA\\n-10 PCA\\n-10 -10 -10\\n-15\\n-15 Dense region in SFT dataset: Empty region -15 -15 Dense region Expanded region\\nexample ④ in difference set Dense region in rewritten set: in combined set\\nin combined set\\n-20 -20 example ⑤⑥⑦\\n-20\\n-20\\n-20 -10 0 10 20 -20 -10 0 10 20 -20 -10 0 10 20 -20 -10 0 10 20\\nPCA Component 1 PCA Component 1 PCA Component 1 PCA Component 1\" data-coord=\"top-left:(119,127); bottom-right:(1113,388)\" /></figure>',\n",
       "  \"<br><p id='93' data-category='paragraph' style='font-size:20px'>(a) Original dataset TuluV2</p>\",\n",
       "  \"<br><p id='94' data-category='paragraph' style='font-size:18px'>(b) The difference set</p>\",\n",
       "  '<figure id=\\'95\\' data-category=\\'chart\\'><img style=\\'font-size:14px\\' alt=\"15 \\nSFT dataset > Pretraining \\ncorpus in density \\n10 \\n2 \\n5 2 \\nComponent \\n0 \\n-5 Component \\nPCA \\nPCA \\n-10 \\n-15 > SFT \\nPretraining corpus \\ndataset in density \\n-20 \\n-20 -10 0 10 20 \\nPCA Component 1 \\n\" data-coord=\"top-left:(126,432); bottom-right:(391,675)\" /></figure>',\n",
       "  \"<br><p id='96' data-category='paragraph' style='font-size:18px'>(c) The rewritten set</p>\",\n",
       "  '<figure id=\\'97\\' data-category=\\'chart\\'><img style=\\'font-size:14px\\' alt=\"15 \\n10 \\n5 2 \\n0 \\n-5 Component \\nPCA \\n-10 \\n-15 Denser region \\nin difference set \\n-20 \\n-20 -10 0 10 20 \\nPCA Component 1 \\n\" data-coord=\"top-left:(383,430); bottom-right:(634,677)\" /></figure>',\n",
       "  '<br><figure id=\\'98\\'><img style=\\'font-size:14px\\' alt=\"15\\n10\\n5 2\\n0\\n-5 Component\\nPCA\\n-10\\n-15 Dense region\\nin rewritten set\\n-20\\n-20 -10 0 10 20\\nPCA Component 1\" data-coord=\"top-left:(627,431); bottom-right:(888,675)\" /></figure>',\n",
       "  \"<br><p id='99' data-category='paragraph' style='font-size:18px'>(d) The combined set</p>\",\n",
       "  \"<p id='100' data-category='paragraph' style='font-size:20px'>(e) Original dataset TuluV2</p>\",\n",
       "  \"<br><p id='101' data-category='paragraph' style='font-size:18px'>(f) The difference set (g) The rewritten set (h) The combined set</p>\",\n",
       "  '<br><figure id=\\'102\\' data-category=\\'chart\\'><img style=\\'font-size:16px\\' alt=\"15 \\n10 \\n5 \\n0 \\n-5 \\n-10 \\n-15 Dense region Expanded region \\nin combined set in combined set \\n-20 \\n-20 -10 0 10 20 \\nPCA Component 1 \\n\" data-coord=\"top-left:(875,430); bottom-right:(1121,676)\" /></figure>',\n",
       "  \"<caption id='103' style='font-size:20px'>Figure 3: Data Distribution Changes in AITP. Subfigures (a)-(d) and (e)-(h) illustrate the distribution changes of the<br>datasets under density estimation and the density comparison settings. The red region at the bottom represents the pre-<br>training corpus, Dolma, while the blue regions in the subfigures represent the projections of Tulu V2, the difference set, the<br>rewritten set, and the combined set, respectively. Darker areas indicate a higher concentration of data points, whereas lighter<br>areas signify sparser distributions. The examples in the subfigures can be found in Appendix F.</caption>\",\n",
       "  \"<p id='104' data-category='paragraph' style='font-size:20px'>fine-tuning is applied, with the detailed training parameters<br>provided in Appendix D.</p>\",\n",
       "  \"<p id='105' data-category='paragraph' style='font-size:22px'>4. Results</p>\",\n",
       "  \"<h1 id='106' style='font-size:22px'>4.1. Distribution Change Analysis</h1>\",\n",
       "  \"<p id='107' data-category='paragraph' style='font-size:20px'>In the density estimation setting, AITP focuses on the dense<br>regions of the SFT dataset and the pre-training corpus to<br>identify points in the pre-training corpus that are underrep-<br>resented in the SFT dataset. Figure 3a highlights the dense<br>regions of Tulu and Dolma (examples are provided in Ap-<br>pendix F). Dense regions 1 and 2 correspond to code and<br>scientific literature data, respectively. Figure 3b demon-<br>strates that the difference set avoids the dense regions in<br>the SFT dataset and aligns with dense regions of Dolma.<br>Figure 3c shows the narrowing of the distribution during<br>rewriting (examples are provided in Appendix F), while<br>Figure 3d indicates that the combined dataset expands the<br>original SFT distribution and highly overlaps with the dense<br>regions of the pre-training corpus. In the density compari-<br>son setting (Figure 3e-3h), AITP focuses on points where<br>the pre-training corpus has a higher density than the SFT<br>dataset. Similarly, AITP with the density comparison set-</p>\",\n",
       "  \"<br><p id='108' data-category='paragraph' style='font-size:20px'>ting can also expand the coverage of the existing dataset and<br>optimize the data distribution.</p>\",\n",
       "  \"<p id='109' data-category='paragraph' style='font-size:20px'>4.2. Main Results</p>\",\n",
       "  \"<p id='110' data-category='paragraph' style='font-size:20px'>As shown in Table 1, compared to the SFT model of OLMo,<br>MAP-Neo, and Pythia baselines, the counterparts trained<br>with AITP achieve average performance improvements<br>of 3.8, 1.1 and 0.9 across eight benchmarks. This illustrates<br>the effectiveness of AITP. We suppose that this improve-<br>ment results from AITP supplementing the original SFT<br>dataset with lacking data, expanding its coverage, and<br>optimizing its distribution.</p>\",\n",
       "  \"<p id='111' data-category='paragraph' style='font-size:20px'>Based on the analysis in subsection 4.1, we can summarize<br>two points supporting the above supposition: (1) A com-<br>parison of Figure 3a and 3b reveals that the difference set<br>includes data from the pre-training corpus that is lacking<br>in SFT datasets, such as code and scientific literature data.<br>(2) Although the distribution narrows during the rewriting<br>process (as shown in Figure 3b and 3c), the final combined<br>dataset expands the coverage of the original SFT dataset,<br>and the dense regions of the combined data align closely<br>those of the pre-training corpus (as shown in Figure 3d).</p>\",\n",
       "  \"<footer id='112' style='font-size:20px'>5</footer>\",\n",
       "  \"<header id='113' style='font-size:18px'>MAP</header>\",\n",
       "  \"<p id='114' data-category='paragraph' style='font-size:20px'>Table 1: Main Results: Experiment performance of different models across various benchmarks. △ represents the<br>change in performance when using AITP compared to the corresponding baseline. P-S, I-S, P-L, and I-L denote prompt-level<br>strict accuracy, instance-level strict accuracy, prompt-level loose accuracy, and instance-level loose accuracy, respectively.</p>\",\n",
       "  '<table id=\\'115\\' style=\\'font-size:16px\\'><tr><td rowspan=\"3\">Experiment Setting</td><td colspan=\"4\">Chat Benchmark</td><td colspan=\"7\">Standard Benchmark</td><td rowspan=\"3\">Average</td></tr><tr><td colspan=\"4\">IFEval</td><td colspan=\"3\">Exam</td><td colspan=\"2\">Coding</td><td colspan=\"2\">Reasoning</td></tr><tr><td>P-S</td><td>I-S</td><td>P-L</td><td>I-L</td><td>MMLU</td><td>ARC</td><td>GPQA</td><td>Human Eval</td><td>MBPP</td><td>Hella Swag</td><td>GSM 8K</td></tr><tr><td>OLMo-SFT</td><td>35.3</td><td>46.5</td><td>38.6</td><td>50.2</td><td>52.9</td><td>63.7</td><td>17.7</td><td>26.8</td><td>43.9</td><td>60.4</td><td>26.8</td><td>42.1</td></tr><tr><td>△ over OLMo</td><td>+3.3</td><td>+2.4</td><td>+1.7</td><td>+1.2</td><td>+2.8</td><td>+12.9</td><td>+7.1</td><td>+1.3</td><td>+0.3</td><td>+4.6</td><td>+4.1</td><td>+3.8</td></tr><tr><td>Neo-SFT</td><td>37.9</td><td>49.2</td><td>41.2</td><td>52.3</td><td>57.6</td><td>77.6</td><td>12.1</td><td>44.5</td><td>45.0</td><td>72.1</td><td>70.1</td><td>50.9</td></tr><tr><td>△ over Neo</td><td>+0.6</td><td>+0.8</td><td>+0.4</td><td>+1.1</td><td>+0.8</td><td>+3.4</td><td>+7.1</td><td>-6.1</td><td>+6.3</td><td>-3.9</td><td>+1.9</td><td>+1.1</td></tr><tr><td>Pythia-SFT</td><td>20.2</td><td>32.3</td><td>22.2</td><td>34.7</td><td>24.2</td><td>27.8</td><td>20.2</td><td>13.4</td><td>19.6</td><td>26.0</td><td>7.7</td><td>22.5</td></tr><tr><td>△ over Pythia</td><td>+1.8</td><td>+1.6</td><td>+2.4</td><td>+1.6</td><td>+1.0</td><td>-4.7</td><td>+4.6</td><td>+1.8</td><td>+0.2</td><td>+0.1</td><td>-0.1</td><td>+0.9</td></tr></table>',\n",
       "  \"<p id='116' data-category='paragraph' style='font-size:20px'>Table 2: The Results of Various Difference Set Generation setting. bge and MiniLM represent the embedding model, and<br>estimation and comparison represent the setting of choosing difference sets. P-S, I-S, P-L, and I-L denote prompt-level strict<br>accuracy, instance-level strict accuracy, prompt-level loose accuracy, and instance-level loose accuracy, respectively.</p>\",\n",
       "  '<table id=\\'117\\' style=\\'font-size:14px\\'><tr><td rowspan=\"3\">Experiment Setting</td><td colspan=\"4\">Chat Benchmark</td><td colspan=\"7\">Standard Benchmark</td><td rowspan=\"3\">Average</td></tr><tr><td colspan=\"4\">IFEval</td><td colspan=\"3\">Exam</td><td colspan=\"2\">Coding</td><td colspan=\"2\">Reasoning</td></tr><tr><td>P-S</td><td>I-S</td><td>P-L</td><td>I-L</td><td>MMLU</td><td>ARC</td><td>GPQA</td><td>Human Eval</td><td>MBPP</td><td>Hella Swag</td><td>GSM 8K</td></tr><tr><td>OLMo-SFT</td><td>35.3</td><td>46.5</td><td>38.6</td><td>50.2</td><td>52.9</td><td>63.7</td><td>17.7</td><td>26.8</td><td>43.9</td><td>60.4</td><td>26.8</td><td>42.1</td></tr><tr><td>bge-estimation (△)</td><td>+3.3</td><td>+2.4</td><td>+1.7</td><td>+1.2</td><td>+2.8</td><td>+12.9</td><td>+7.1</td><td>+1.3</td><td>+0.3</td><td>+4.6</td><td>+4.1</td><td>+3.8</td></tr><tr><td>bge-comparison (△)</td><td>+2.6</td><td>+2.5</td><td>+1.1</td><td>+1.1</td><td>+2.8</td><td>+10.5</td><td>+10.6</td><td>+4.9</td><td>+3.7</td><td>+2.9</td><td>+4.7</td><td>+4.3</td></tr><tr><td>MiniLM-estimation (△)</td><td>-0.7</td><td>+0.5</td><td>-2.0</td><td>-0.9</td><td>+2.6</td><td>+10.5</td><td>+9.1</td><td>+3.1</td><td>+2.7</td><td>+4.1</td><td>+3.5</td><td>+3.0</td></tr><tr><td>MiniLM-comparison (△)</td><td>+0.9</td><td>+1.0</td><td>-0.1</td><td>+0.2</td><td>+2.6</td><td>+10.9</td><td>+8.6</td><td>+1.9</td><td>+0.5</td><td>+3.1</td><td>+4.8</td><td>+3.1</td></tr></table>',\n",
       "  \"<p id='118' data-category='paragraph' style='font-size:18px'>Table 3: The Ablation Results on Data Size and Distillation. P-S, I-S, P-L, and I-L denote prompt-level strict accuracy,<br>instance-level strict accuracy, prompt-level loose accuracy, and instance-level loose accuracy, respectively.</p>\",\n",
       "  '<table id=\\'119\\' style=\\'font-size:16px\\'><tr><td rowspan=\"3\">Experiment Setting</td><td colspan=\"4\">Chat Benchmark</td><td colspan=\"7\">Standard Benchmark</td><td rowspan=\"3\">Average</td></tr><tr><td colspan=\"4\">IFEval</td><td colspan=\"3\">Exam</td><td colspan=\"2\">Coding</td><td colspan=\"2\">Reasoning</td></tr><tr><td>P-S</td><td>I-S</td><td>P-L</td><td>I-L</td><td>MMLU</td><td>ARC</td><td>GPQA</td><td>Human Eval</td><td>MBPP</td><td>Hella Swag</td><td>GSM 8K</td></tr><tr><td>OLMo-SFT</td><td>35.3</td><td>46.5</td><td>38.6</td><td>50.2</td><td>52.9</td><td>63.7</td><td>17.7</td><td>26.8</td><td>43.9</td><td>60.4</td><td>26.8</td><td>42.1</td></tr><tr><td>Distillation (△)</td><td>-4.1</td><td>-3.8</td><td>-4.6</td><td>-4.5</td><td>+0.9</td><td>+4.1</td><td>+4.0</td><td>-3.6</td><td>-2.6</td><td>-6.9</td><td>+14.1</td><td>-0.6</td></tr><tr><td>Same Size (△)</td><td>+0.4</td><td>+0.1</td><td>-0.5</td><td>-1.0</td><td>+2.6</td><td>+10.5</td><td>+12.6</td><td>-2.4</td><td>-0.3</td><td>-0.9</td><td>+1.9</td><td>+2.1</td></tr><tr><td>OLMo (△)</td><td>+3.3</td><td>+2.4</td><td>+1.7</td><td>+1.2</td><td>+2.8</td><td>+12.9</td><td>+7.1</td><td>+1.3</td><td>+0.3</td><td>+4.6</td><td>+4.1</td><td>+3.8</td></tr></table>',\n",
       "  \"<h1 id='120' style='font-size:22px'>4.3. Difference Set Generation Setting Results</h1>\",\n",
       "  \"<p id='121' data-category='paragraph' style='font-size:18px'>Table 2 presents the experimental results for various em-<br>bedding models and different set generation settings. As<br>shown in Table 2, the four AITP variants show improve-<br>ments over the baseline model OLMo-SFT across various<br>settings: using the bge model with density estimation to<br>identify the difference set achieves an average absolute im-<br>provement of 3.8; using bge with density comparison yields<br>an improvement of 4.3; using MiniLM with density compar-<br>ison results in an improvement of 3.0; and using bge with<br>density comparison achieves an improvement of 3.1. These</p>\",\n",
       "  \"<br><p id='122' data-category='paragraph' style='font-size:18px'>results suggest that AITP is robust across various choices of<br>embedding model and difference set generation method.</p>\",\n",
       "  \"<p id='123' data-category='paragraph' style='font-size:20px'>4.4. Ablation Results</p>\",\n",
       "  \"<p id='124' data-category='paragraph' style='font-size:18px'>To verify whether the gains of AITP result from the in-<br>creased size of the SFT dataset after adding the rewritten dif-<br>ference set, we sample a subset from the combined dataset<br>(original SFT and rewritten difference set) that is equal in<br>size to the original SFT dataset and use it for training. Com-<br>paring the first and third rows in Table 3, the AITP method<br>achieves an average absolute improvement of 2.1, even with</p>\",\n",
       "  \"<footer id='125' style='font-size:18px'>6</footer>\",\n",
       "  \"<header id='126' style='font-size:18px'>MAP</header>\",\n",
       "  '<figure id=\\'127\\' data-category=\\'chart\\'><img style=\\'font-size:16px\\' alt=\"Hellaswag GSM8k GPQA Avg \\nP-S I-S P-L - I-L Avg HumanEval MBPP Avg \\n52.5 \\n60 \\n50.0 45 \\n47.5 \\nAccuracy 50 \\nAccuracy \\n45.0 40 \\n42.5 40 \\n35 \\n40.0 Accuracy \\n30 \\n37.5 \\n30 \\n35.0 20 \\n000 0.05 0.07 0.1 10 る 70 0~5 0.6 0.7 000 0.05 0.07 0.1 20 10 0.4 50 00 0.7 000 0.05 0.07 10 10 : 0.4 15 00 0.7 \\n33 \\n33 \\n33 \\nRatio Ratio Ratio \\n(a) IFEval across different ratios (b) Coding across different ratios (c) Reasoning across different ratios \\n\" data-coord=\"top-left:(112,121); bottom-right:(1125,393)\" /></figure>',\n",
       "  \"<caption id='128' style='font-size:18px'>Figure 4: Line graph across different ratios. The x-label represents the ratio of the rewritten set to the original SFT dataset,<br>while the y-label shows accuracy across different benchmarks. More results can be found in Appendix E.</caption>\",\n",
       "  '<figure id=\\'129\\' data-category=\\'chart\\'><img style=\\'font-size:14px\\' alt=\"sft_ data \\nrewrite_ data \\n100 \\n50 \\n2 \\nComponent \\n0 \\nt-SNE \\n-50 \\n-100 \\n-150 \\n- 150 -100 -50 0 50 100 150 \\nt-SNE Component 1 \\n\" data-coord=\"top-left:(128,510); bottom-right:(568,842)\" /></figure>',\n",
       "  \"<caption id='130' style='font-size:18px'>Figure 5: The t-SNE Visualization of SFT and Rewritten<br>Data. The red points and blue points represent the original<br>SFT data and the rewritten data, respectively.</caption>\",\n",
       "  \"<p id='131' data-category='paragraph' style='font-size:18px'>the same dataset size. Comparing the third and fourth rows,<br>the improvement for the same dataset size setting is smaller<br>than the final AITP improvement.</p>\",\n",
       "  \"<p id='132' data-category='paragraph' style='font-size:18px'>Additionally, to test whether the improvement arises from<br>distillation by a stronger model during the rewriting phase,<br>we replace the original SFT dataset with the rewritten dataset<br>from the same distribution and train the model on a com-<br>bined dataset (rewritten same distribution set and rewritten<br>difference set). Comparing the first and second rows in Ta-<br>ble 3, the distillation setting does not outperform the OLMo-<br>SFT baseline, likely because the quality of the rewritten data<br>is lower than that of the original SFT dataset. This indicates<br>that the improvement does not result from distillation by an<br>aligned model.</p>\",\n",
       "  \"<h1 id='133' style='font-size:20px'>4.5. Ratio Results</h1>\",\n",
       "  \"<p id='134' data-category='paragraph' style='font-size:18px'>We further investigate the effect of incorporating various<br>ratios of rewritten difference data on AITP. As shown in<br>Figure 4, the AITP achieves excellent performance with a<br>rewritten data set comprising less than 10 % of the original</p>\",\n",
       "  \"<br><p id='135' data-category='paragraph' style='font-size:18px'>SFT dataset. However, performance declines as the size<br>of the rewritten set increases. We hypothesize that incor-<br>porating a small amount of rewritten data improves model<br>performance significantly by filling gaps in the original SFT<br>data. On the other hand, the quality of the rewritten data<br>might be low, which could degrade the overall data quality<br>when the rewritten ratio is increased. This is consistent with<br>the ablation study on data size in Section 4.4, which shows<br>that the quality of the rewritten data is lower than that of the<br>original SFT dataset and that the improvement in AITP is<br>not due to the increased data size.</p>\",\n",
       "  \"<h1 id='136' style='font-size:18px'>4.6. Visualization</h1>\",\n",
       "  \"<p id='137' data-category='paragraph' style='font-size:20px'>Figure 5 illustrates that the manually combined original<br>SFT dataset (Tulu) forms multiple distinct clusters, indi-<br>cating a high level of diversity within the original dataset.<br>The rewritten data is densely distributed in areas underrep-<br>resented by the original SFT dataset, while intentionally<br>avoiding regions where the original SFT dataset is densely<br>populated. This result clearly demonstrates the effectiveness<br>of the difference set generated by AITP in optimizing data<br>coverage.</p>\",\n",
       "  \"<p id='138' data-category='paragraph' style='font-size:22px'>5. Related Work</p>\",\n",
       "  \"<p id='139' data-category='paragraph' style='font-size:22px'>5.1. Open-Source Large Language Model</p>\",\n",
       "  \"<p id='140' data-category='paragraph' style='font-size:18px'>Current models like GPT-4 (OpenAI et al., 2023), Gemini<br>(Team et al., 2023), and Claude (Anthropic, 2024) have<br>demonstrated impressive performance across various fields.<br>However, their closed-source nature and API-only access<br>limit deployment flexibility. To address this, several open-<br>source models, such as LLaMA (Touvron et al., 2023) ,<br>Qwen (Yang et al., 2024a), DeepSeek(DeepSeek-AI et al.,<br>2024), ChatGLM (GLM et al., 2024), Mixtral (Jiang et al.,<br>2024a), and Yi (AI et al., 2024) have emerged, offering<br>freely accessible model weights. Furthermore, some open-<br>source communities have introduced fully transparent mod-<br>els, such as OLMo (Groeneveld et al., 2024), Map-Neo</p>\",\n",
       "  \"<footer id='141' style='font-size:18px'>7</footer>\",\n",
       "  \"<header id='142' style='font-size:14px'>MAP</header>\",\n",
       "  \"<p id='143' data-category='paragraph' style='font-size:16px'>(Zhang et al., 2024a), LLM360 (Liu et al., 2023), and Pythia<br>(Biderman et al., 2023), which go beyond sharing model<br>weights by providing accessible pre-training corpora, SFT<br>datasets, data-cleaning processes, intermediate checkpoints,<br>and reproducible code, fostering a more open and repro-<br>ducible research ecosystem. In this paper, we primarily<br>conduct experiments on fully transparent open-source mod-<br>els due to their accessible pre-training and SFT datasets.<br>Notably, our method can also be applied to enhance the<br>performance of closed-source models or those that provide<br>open-access weights.</p>\",\n",
       "  \"<h1 id='144' style='font-size:18px'>5.2. Instruction Tuning</h1>\",\n",
       "  \"<p id='145' data-category='paragraph' style='font-size:16px'>Instruction tuning evolves from relying on human-annotated<br>data to incorporating synthetic data, aiming to enhance the<br>adaptability and generalization of pre-trained language mod-<br>els. Initially, instruction tuning involves training models on<br>diverse instruction-response pairs from manually curated<br>datasets, such as FLAN (Wei et al., 2021) and T0 (Sanh<br>et al., 2021), which significantly improve zero-shot and few-<br>shot learning performance. To further enhance cross-task<br>generalization, multi-task learning approaches, like Uni-<br>fiedQA (Khashabi et al., 2020) and FLAN-T5 (Chung et al.,<br>2024), present multiple tasks as instructions, reducing the<br>need for task-specific data and manual prompt engineer-<br>ing. As instruction tuning progresses, the importance of<br>large-scale, diverse datasets becomes evident. Datasets like<br>Super-Natural Instructions (Wang et al., 2022b) provide<br>extensive coverage across tasks, domains, and instruction<br>styles, improving model robustness and mitigating biases.<br>Additionally, the exploration of synthetic data generation<br>techniques augments training sets, enabling models to better<br>handle rare or complex instructions (Xie et al., 2024; Asai<br>et al., 2023). These approaches, which leverage language<br>models to generate additional training samples, demonstrate<br>significant improvements in both performance and general-<br>ization.</p>\",\n",
       "  \"<h1 id='146' style='font-size:18px'>5.3. Improving LLM Using Synthetic Data</h1>\",\n",
       "  \"<p id='147' data-category='paragraph' style='font-size:16px'>Some methods enhance model capabilities by synthesiz-<br>ing data using external signals, such as seed data (Wang<br>et al., 2022a; Sun et al., 2023; Kang et al., 2024; Liang<br>et al., 2024; Taori et al., 2023), pre-training data (Li et al.,<br>2023; Zheng et al., 2024), query data (Huang et al., 2023;<br>Madaan et al., 2023; Yu et al., 2023), feedback data (Lu<br>et al., 2023; Scheurer et al., 2022), and retrieval-augmented<br>generation (RAG) (Asai et al., 2023). These methods can<br>be classified into two types: those that generate synthetic<br>data using the model itself (Liang et al., 2024; Wang et al.,<br>2022a; Sun et al., 2023) and those that use a teacher model<br>for data synthesis (Lee et al., 2024; Li et al., 2024; Taori<br>et al., 2023). While synthetic data approaches effectively<br>mitigate the limitations of supervised dataset sizes, they also</p>\",\n",
       "  \"<br><p id='148' data-category='paragraph' style='font-size:16px'>introduce challenges such as increased hallucinations, lack<br>of diversity, low quality, and distribution misalignment (Liu<br>et al., 2024). Training models iteratively with this synthetic<br>data can lead to issues like model collapse, increased hal-<br>lucinations, and reduced generalizability (Shumailov et al.,<br>2023; Alemohammad et al., 2023; Guo et al., 2024).</p>\",\n",
       "  \"<p id='149' data-category='paragraph' style='font-size:16px'>Recent studies address these limitations through various<br>methods. Some methods aim to improve the quality of gen-<br>erated instruction pairs using self-consistency(Huang et al.,<br>2023), reflection(Renze & Guven, 2024; Li et al., 2024),<br>filtering (Liang et al., 2024; Yuan et al., 2024), and Monte<br>Carlo tree search (MCTS) (Xie et al., 2024; Gao et al., 2024).<br>Others focus on enhancing diversity of generated instruction<br>pairs (Ge et al., 2024; O'Neill et al., 2023), reducing hal-<br>lucinations (Chung et al., 2023; Zhang et al., 2024b; Jones<br>et al., 2023), or optimizing synthetic data distribution (Lu-<br>pidi et al., 2024; Jiang et al., 2024b; Yang et al., 2024b). Our<br>method mainly focuses on further enhancing the diversity of<br>synthetic data after combining existing datasets manually.</p>\",\n",
       "  \"<p id='150' data-category='paragraph' style='font-size:20px'>6. Conclusion</p>\",\n",
       "  \"<p id='151' data-category='paragraph' style='font-size:16px'>The existing SFT datasets exhibit significant differences<br>from the pre-training corpus in terms of coverage and distri-<br>bution. In this paper, we present the AITP method, which<br>adaptively fills the gaps in current manually-assembled SFT<br>datasets by identifying the difference set between the pre-<br>training corpus and the SFT dataset. This approach utilizes<br>existing high-quality SFT data and offers guidance for syn-<br>thesizing lacking data of existing SFT datasets. Our experi-<br>ments demonstrate the effectiveness of AITP, showing that<br>bridging the gap between SFT and pre-training datasets can<br>be achieved by adding a small amount of difference data<br>(less than 10 %). This feature makes AITP a cost-effective<br>and practical solution for real-world applications.</p>\",\n",
       "  \"<p id='152' data-category='paragraph' style='font-size:22px'>References</p>\",\n",
       "  \"<p id='153' data-category='paragraph' style='font-size:18px'>AI, · , : , Young, A., Chen, B., Li, C., Huang, C., Zhang, G.,<br>Zhang, G., Li, H., Zhu, J., Chen, J., Chang, J., Yu, K.,<br>Liu, P., Liu, Q., Yue, S., Yang, S., Yang, S., Yu, T., Xie,<br>W., Huang, W., Hu, X., Ren, X., Niu, X., Nie, P., Xu, Y.,<br>Liu, Y., Wang, Y., Cai, Y., Gu, Z., Liu, Z., and Dai, Z. Yi:<br>Open foundation models by 01.ai. arXiv preprint arXiv:<br>2403.04652, 2024.</p>\",\n",
       "  \"<p id='154' data-category='paragraph' style='font-size:16px'>Alemohammad, S., Casco-Rodriguez, J., Luzi, L., Hu-<br>mayun, A. I., Babaei, H., LeJeune, D., Siahkoohi, A.,<br>and Baraniuk, R. G. Self-consuming generative models<br>go mad. arXiv preprint arXiv: 2307.01850, 2023.</p>\",\n",
       "  \"<p id='155' data-category='paragraph' style='font-size:14px'>Anthropic. Claude 3 haiku: Our fastest model yet,<br>2024. Available at: https : / / www · anthropic.<br>com/ news / claude-3-haiku.</p>\",\n",
       "  \"<footer id='156' style='font-size:14px'>8</footer>\",\n",
       "  \"<header id='157' style='font-size:14px'>MAP</header>\",\n",
       "  \"<p id='158' data-category='paragraph' style='font-size:16px'>Asai, A., Wu, Z., Wang, Y., Sil, A., and Hajishirzi, H. Self-<br>rag: Learning to retrieve, generate, and critique through<br>self-reflection. arXiv preprint arXiv: 2310.11511, 2023.</p>\",\n",
       "  \"<p id='159' data-category='paragraph' style='font-size:18px'>Austin, J., Odena, A., Nye, M., Bosma, M., Michalewski,<br>H., Dohan, D., Jiang, E., Cai, C., Terry, M., Le, Q., and<br>Sutton, C. Program synthesis with large language models.<br>arXiv preprint arXiv: 2108.07732, 2021.</p>\",\n",
       "  \"<p id='160' data-category='paragraph' style='font-size:16px'>Biderman, S., Schoelkopf, H., Anthony, Q., Bradley, H.,<br>O'Brien, K., Hallahan, E., Khan, M. A., Purohit, S.,<br>Prashanth, U. S., Raff, E., Skowron, A., Sutawika, L., and<br>van der Wal, 0. Pythia: A suite for analyzing large lan-<br>guage models across training and scaling. arXiv preprint<br>arXiv: 2304.01373, 2023.</p>\",\n",
       "  \"<p id='161' data-category='paragraph' style='font-size:20px'>Chen, J., Xiao, S., Zhang, P., Luo, K., Lian, D., and<br>Liu, Z. Bge m3-embedding: Multi-lingual, multi-<br>functionality, multi-granularity text embeddings through<br>self-knowledge distillation, 2024.</p>\",\n",
       "  \"<p id='162' data-category='list' style='font-size:18px'>Chen, M., Tworek, J., Jun, H., Yuan, Q., de Oliveira Pinto,<br>H. P., Kaplan, J., Edwards, H., Burda, Y., Joseph, N.,<br>Brockman, G., Ray, A., Puri, R., Krueger, G., Petrov,<br>M., Khlaaf, H., Sastry, G., Mishkin, P., Chan, B., Gray,<br>S., Ryder, N., Pavlov, M., Power, A., Kaiser, L., Bavar-<br>ian, M., Winter, C., Tillet, P., Such, F. P., Cummings, D.,<br>Plappert, M., Chantzis, F., Barnes, E., Herbert- Voss, A.,<br>Guss, W. H., Nichol, A., Paino, A., Tezak, N., Tang,<br>J., Babuschkin, I., Balaji, S., Jain, S., Saunders, W.,<br>Hesse, C., Carr, A. N., Leike, J., Achiam, J., Misra,<br>V., Morikawa, E., Radford, A., Knight, M., Brundage,<br>M., Murati, M., Mayer, K., Welinder, P., McGrew, B.,<br>Amodei, D., McCandlish, S., Sutskever, I., and Zaremba,<br>W. Evaluating large language models trained on code.<br>arXiv preprint arXiv: 2107.03374, 2021.</p>\",\n",
       "  \"<p id='163' data-category='paragraph' style='font-size:18px'>Chung, H. W., Hou, L., Longpre, S., Zoph, B., Tay, Y., Fe-<br>dus, W., Li, Y., Wang, X., Dehghani, M., Brahma, S., et al.<br>Scaling instruction-finetuned language models. Journal<br>of Machine Learning Research, 25(70):1-53, 2024.</p>\",\n",
       "  \"<p id='164' data-category='paragraph' style='font-size:16px'>Chung, J. J. Y., Kamar, E., and Amershi, S. Increasing<br>diversity while maintaining accuracy: Text data genera-<br>tion with large language models and human interventions.<br>arXiv preprint arXiv: 2306.04140, 2023.</p>\",\n",
       "  \"<p id='165' data-category='paragraph' style='font-size:16px'>Clark, P., Cowhey, I., Etzioni, 0., Khot, T., Sabharwal, A.,<br>Schoenick, C., and Tafjord, 0. Think you have solved<br>question answering? try arc, the ai2 reasoning challenge.<br>arXiv preprint arXiv: 1803.05457, 2018.</p>\",\n",
       "  \"<p id='166' data-category='paragraph' style='font-size:18px'>Cobbe, K., Kosaraju, V., Bavarian, M., Chen, M., Jun, H.,<br>Kaiser, L., Plappert, M., Tworek, J., Hilton, J., Nakano,<br>R., Hesse, C., and Schulman, J. Training verifiers to solve<br>math word problems. arXiv preprint arXiv: 2110.14168,<br>2021.</p>\",\n",
       "  \"<br><p id='167' data-category='paragraph' style='font-size:16px'>Contributors, 0. Opencompass: A universal evaluation<br>platform for foundation models. https : / / github.<br>com/ open-compass / opencompass, 2023.</p>\",\n",
       "  \"<p id='168' data-category='paragraph' style='font-size:18px'>DeepSeek-AI, : , Bi, X., Chen, D., Chen, G., Chen, S., Dai,<br>D., Deng, C., Ding, H., Dong, K., Du, Q., Fu, Z., Gao,<br>H., Gao, K., Gao, W., Ge, R., Guan, K., Guo, D. , Guo, J.,<br>Hao, G., Hao, Z., He, Y., Hu, W., Huang, P., Li, E., Li,<br>G., Li, J., Li, Y., Li, Y. K., Liang, W., Lin, F., Liu, A. X.,<br>Liu, B., Liu, W., Liu, X., Liu, X., Liu, Y., Lu, H., Lu, S.,<br>Luo, F., Ma, S., Nie, X., Pei, T., Piao, Y., Qiu, J., Qu,<br>H., Ren, T., Ren, Z., Ruan, C., Sha, Z., Shao, Z., Song,<br>J., Su, X., Sun, J., Sun, Y., Tang, M., Wang, B., Wang,<br>P., Wang, S., Wang, Y., Wang, Y., Wu, T., Wu, Y., Xie,<br>X., Xie, Z., Xie, Z., Xiong, Y., Xu, H., Xu, R. X., Xu,<br>Y., Yang, D., You, Y., Yu, S., Yu, X., Zhang, B., Zhang,<br>H., Zhang, L., Zhang, L., Zhang, M., Zhang, M., Zhang,<br>W., Zhang, Y., Zhao, C., Zhao, Y., Zhou, S., Zhou, S.,<br>Zhu, Q., and Zou, Y. Deepseek llm: Scaling open-source<br>language models with longtermism. arXiv preprint arXiv:<br>2401.02954, 2024.</p>\",\n",
       "  \"<p id='169' data-category='paragraph' style='font-size:16px'>Gao, Z., Niu, B., He, X., Xu, H., Liu, H., Liu, A., Hu,<br>X., and Wen, L. Interpretable contrastive monte carlo<br>tree search reasoning. arXiv preprint arXiv: 2410.01707,<br>2024.</p>\",\n",
       "  \"<p id='170' data-category='paragraph' style='font-size:16px'>Ge, T., Chan, X., Wang, X., Yu, D., Mi, H., and Yu, D. Scal-<br>ing synthetic data creation with 1,000,000,000 personas.<br>arXiv preprint arXiv: 2406.20094, 2024.</p>\",\n",
       "  \"<p id='171' data-category='paragraph' style='font-size:18px'>GLM, T., : , Zeng, A., Xu, B., Wang, B., Zhang, C., Yin, D.,<br>Zhang, D., Rojas, D., Feng, G., Zhao, H., Lai, H., Yu, H.,<br>Wang, H., Sun, J., Zhang, J., Cheng, J., Gui, J., Tang, J.,<br>Zhang, J., Sun, J., Li, J., Zhao, L., Wu, L., Zhong, L., Liu,<br>M., Huang, M., Zhang, P., Zheng, Q., Lu, R., Duan, S.,<br>Zhang, S., Cao, S., Yang, S., Tam, W. L., Zhao, W., Liu,<br>X., Xia, X., Zhang, X., Gu, X., Lv, X., Liu, X., Liu, X.,<br>Yang, X., Song, X., Zhang, X., An, Y., Xu, Y., Niu, Y.,<br>Yang, Y., Li, Y., Bai, Y., Dong, Y., Qi, Z., Wang, Z., Yang,<br>Z., Du, Z., Hou, Z., and Wang, Z. Chatglm: A family of<br>large language models from glm-130b to glm-4 all tools.<br>arXiv preprint arXiv: 2406.12793, 2024.</p>\",\n",
       "  \"<p id='172' data-category='paragraph' style='font-size:18px'>Groeneveld, D., Beltagy, I., Walsh, P., Bhagia, A., Kin-<br>ney, R., Tafjord, O., Jha, A., Ivison, H., Magnusson, I.,<br>Wang, Y., Arora, S., Atkinson, D., Authur, R., Chandu,<br>K. R., Cohan, A., Dumas, J., Elazar, Y., Gu, Y., Hessel, J.,<br>Khot, T., Merrill, W., Morrison, J. D., Muennighoff, N.,<br>Naik, A., Nam, C., Peters, M. E., Pyatkin, V., Ravichan-<br>der, A., Schwenk, D., Shah, S. , Smith, W., Strubell, E.,<br>Subramani, N., Wortsman, M., Dasigi, P., Lambert, N.,<br>Richardson, K., Zettlemoyer, L. S., Dodge, J., Lo, K.,<br>Soldaini, L., Smith, N. A., and Hajishirzi, H. Olmo:<br>Accelerating the science of language models. Annual</p>\",\n",
       "  \"<footer id='173' style='font-size:14px'>9</footer>\",\n",
       "  \"<header id='174' style='font-size:14px'>MAP</header>\",\n",
       "  \"<p id='175' data-category='paragraph' style='font-size:20px'>Meeting of the Associationfor Computational Linguistics,<br>2024. doi: 10.48550/arXiv.2402.00838.</p>\",\n",
       "  \"<p id='176' data-category='paragraph' style='font-size:16px'>Guo, Y., Shang, G., Vazirgiannis, M., and Clavel, C. The<br>curious decline of linguistic diversity: Training language<br>models on synthetic text. In Duh, K., Gomez, H., and<br>Bethard, S. (eds.), Findings of the Associationfor Compu-<br>tational Linguistics: NAACL 2024, pp. 3589-3604, Mex-<br>ico City, Mexico, June 2024. Association for Computa-<br>tional Linguistics. doi: 10.18653/v 1/2024.findings-naacl.<br>228. URL https : / / aclanthology · org/2024.<br>findings-naacl · 228.</p>\",\n",
       "  \"<p id='177' data-category='paragraph' style='font-size:18px'>Hendrycks, D., Burns, C., Basart, S., Zou, A., Mazeika, M.,<br>Song, D., and Steinhardt, J. Measuring massive multitask<br>language understanding. Proceedings of the International<br>Conference on Learning Representations (ICLR), 2021.</p>\",\n",
       "  \"<p id='178' data-category='paragraph' style='font-size:16px'>Huang, J., Gu, S., Hou, L., Wu, Y., Wang, X., Yu, H., and<br>Han, J. Large language models can self-improve. In<br>Bouamor, H., Pino, J., and Bali, K. (eds.), Proceedings<br>of the 2023 Conference on Empirical Methods in Natural<br>Language Processing, pp· 1051-1068, Singapore, De-<br>cember 2023. Association for Computational Linguistics.<br>doi: 10.18653/v1/2023.emnip-main.67. URL https :<br>/ / aclanthology · org/2023 · emnlp-main · 67.</p>\",\n",
       "  \"<p id='179' data-category='paragraph' style='font-size:18px'>Ivison, H., Wang, Y., Pyatkin, V., Lambert, N., Peters, M.,<br>Dasigi, P., Jang, J., Wadden, D., Smith, N. A., Beltagy,<br>I., and Hajishirzi, H. Camels in a changing climate:<br>Enhancing lm adaptation with tulu 2. arXiv preprint<br>arXiv: 2311.10702, 2023.</p>\",\n",
       "  \"<p id='180' data-category='paragraph' style='font-size:18px'>Jiang, A. Q., Sablayrolles, A., Roux, A., Mensch, A.,<br>Savary, B., Bamford, C., Chaplot, D. S., de las Casas,<br>D., Hanna, E. B., Bressand, F., Lengyel, G., Bour, G.,<br>Lample, G., Lavaud, L. R., Saulnier, L., Lachaux, M.-A.,<br>Stock, P., Subramanian, S., Yang, S., Antoniak, S., Scao,<br>T. L., Gervet, T., Lavril, T., Wang, T., Lacroix, T., and<br>Sayed, W. E. Mixtral of experts. arXiv preprint arXiv:<br>2401.04088, 2024a.</p>\",\n",
       "  \"<p id='181' data-category='paragraph' style='font-size:18px'>Jiang, C., min Chan, C., Xue, W., Liu, Q., and Guo, Y.<br>Importance weighting can help large language models<br>self-improve. arXiv preprint arXiv: 2408.09849, 2024b.</p>\",\n",
       "  \"<p id='182' data-category='paragraph' style='font-size:16px'>Jones, E., Palangi, H., Simes, C., Chandrasekaran, V.,<br>Mukherjee, S., Mitra, A., Awadallah, A., and Kamar,<br>E. Teaching language models to hallucinate less with<br>synthetic tasks. arXiv preprint arXiv: 2310.06827, 2023.</p>\",\n",
       "  \"<p id='183' data-category='paragraph' style='font-size:18px'>Kang, J., Luo, H., Zhu, Y., Hansen, J., Glass, J., Cox,<br>D., Ritter, A., Feris, R., and Karlinsky, L. Self-<br>specialization: Uncovering latent expertise within large<br>language models. In Ku, L.-W., Martins, A., and<br>Srikumar, V. (eds.), Findings of the Association for<br>Computational Linguistics: ACL 2024, pp. 2681-2706,</p>\",\n",
       "  \"<br><p id='184' data-category='paragraph' style='font-size:14px'>Bangkok, Thailand, aug 2024. Association for Computa-<br>tional Linguistics. doi: 10.18653/v1/2024.findings-acl.<br>157. URL https : / / aclanthology · org/2024 .<br>findings-acl · 157.</p>\",\n",
       "  \"<p id='185' data-category='paragraph' style='font-size:18px'>Khashabi, D., Min, S., Khot, T., Sabharwal, A., Tafjord, O.,<br>Clark, P., and Hajishirzi, H. Unifiedqa: Crossing format<br>boundaries with a single qa system. arXiv preprint arXiv:<br>2005.00700, 2020.</p>\",\n",
       "  \"<p id='186' data-category='paragraph' style='font-size:18px'>Kwon, W., Li, Z., Zhuang, S., Sheng, Y., Zheng, L., Yu,<br>C. H., Gonzalez, J. E., Zhang, H., and Stoica, I. Efficient<br>memory management for large language model serving<br>with pagedattention. In Proceedings of the ACM SIGOPS<br>29th Symposium on Operating Systems Principles, 2023.</p>\",\n",
       "  \"<p id='187' data-category='paragraph' style='font-size:16px'>Kksal, A., Schick, T., Korhonen, A., and Schtze, H. Long-<br>form: Effective instruction tuning with reverse instruc-<br>tions. Conference on Empirical Methods in Natural<br>Language Processing, 2023. doi: 10.18653/v1/2024.<br>findings-emnlp.414.</p>\",\n",
       "  \"<p id='188' data-category='paragraph' style='font-size:16px'>Lee, N., Wattanawong, T., Kim, S., Mangalam, K., Shen, S.,<br>Anumanchipalli, G., Mahoney, M. W., Keutzer, K., and<br>Gholami, A. Llm21lm: Boosting llms with novel iterative<br>data enhancement. arXiv preprint arXiv: 2403.15042,<br>2024.</p>\",\n",
       "  \"<p id='189' data-category='paragraph' style='font-size:16px'>Li, M., Chen, L., Chen, J., He, S., Gu, J., and Zhou, T.<br>Selective reflection-tuning: Student-selected data recy-<br>cling for LLM instruction-tuning. In Ku, L., Martins,<br>A., and Srikumar, V. (eds.), Findings of the Associa-<br>tion for Computational Linguistics, ACL 2024, Bangkok,<br>Thailand and virtual meeting, August 11-16, 2024, pp.<br>16189-16211. Association for Computational Linguis-<br>tics, 2024. doi: 10.18653/V1/2024.FINDINGS-ACL.<br>958. URL https : / / doi · org/10 · 18653/v1/<br>2024 · findings-acl · 958.</p>\",\n",
       "  \"<p id='190' data-category='paragraph' style='font-size:18px'>Li, X., Yu, P., Zhou, C., Schick, T., Levy, 0., Zettlemoyer,<br>L., Weston, J., and Lewis, M. Self-alignment with instruc-<br>tion backtranslation. arXiv preprint arXiv: 2308.06259,<br>2023.</p>\",\n",
       "  '<p id=\\'191\\' data-category=\\'paragraph\\' style=\\'font-size:16px\\'>Lian, W., Goodson, B., Pentland, E., Cook, A., Vong, C.,<br>and \"Teknium\". Openorca: An open dataset of gpt<br>augmented flan reasoning traces. https : / /https:<br>/ /huggingface · co/ Open-Orca/ OpenOrca,<br>2023.</p>',\n",
       "  \"<p id='192' data-category='paragraph' style='font-size:18px'>Liang, Y., Zhang, G., Qu, X., Zheng, T., Guo, J., Du, X.,<br>Yang, Z., Liu, J., Lin, C., Ma, L., Huang, W., and Zhang,<br>J. I-sheep: Self-alignment of llm from scratch through<br>an iterative self-enhancement paradigm. arXiv preprint<br>arXiv: 2408.08072, 2024.</p>\",\n",
       "  \"<footer id='193' style='font-size:16px'>10</footer>\",\n",
       "  \"<header id='0' style='font-size:14px'>MAP</header>\",\n",
       "  \"<caption id='1' style='font-size:16px'>Liu, R., Wei, J., Liu, F., Si, C., Zhang, Y., Rao, J., Zheng,<br>S., Peng, D., Yang, D., Zhou, D., and Dai, A. M. Best<br>practices and lessons learned on synthetic data. arXiv<br>preprint arXiv: 2404.07503, 2024.</caption>\",\n",
       "  \"<p id='2' data-category='paragraph' style='font-size:20px'>Liu, Z., Qiao, A., Neiswanger, W., Wang, H., Tan, B., Tao,<br>T., Li, J., Wang, Y., Sun, S., Pangarkar, O., Fan, R., Gu,<br>Y., Miller, V., Zhuang, Y., He, G., Li, H., Koto, F., Tang,<br>L., Ranjan, N., Shen, Z., Ren, X., Iriondo, R., Mu, C.,<br>Hu, Z., Schulze, M., Nakov, P., Baldwin, T., and Xing,<br>E. P. Llm360: Towards fully transparent open-source<br>llms. arXiv preprint arXiv: 2312.06550, 2023.</p>\",\n",
       "  \"<p id='3' data-category='paragraph' style='font-size:20px'>Lu, J., Zhong, W., Huang, W., Wang, Y., Zhu, Q., Mi, F.,<br>Wang, B., Wang, W., Zeng, X., Shang, L., Jiang, X., and<br>Liu, Q. Self: Self-evolution with language feedback.<br>arXiv preprint arXiv: 2310.00533, 2023.</p>\",\n",
       "  \"<p id='4' data-category='paragraph' style='font-size:16px'>Lupidi, A., Gemmell, C., Cancedda, N., Dwivedi-Yu, J.,<br>Weston, J., Foerster, J., Raileanu, R., and Lomeli, M.<br>Source2synth: Synthetic data generation and curation<br>grounded in real data sources. arXiv preprint arXiv:<br>2409.08239, 2024.</p>\",\n",
       "  \"<p id='5' data-category='paragraph' style='font-size:20px'>Madaan, A., Tandon, N., Gupta, P., Hallinan, S., Gao, L.,<br>Wiegreffe, S., Alon, U., Dziri, N., Prabhumoye, S., Yang,<br>Y., Gupta, S., Majumder, B. P., Hermann, K., Welleck,<br>S., Yazdanbakhsh, A., and Clark, P. Self-refine: Itera-<br>tive refinement with self-feedback. arXiv preprint arXiv:<br>2303.17651, 2023.</p>\",\n",
       "  \"<p id='6' data-category='paragraph' style='font-size:20px'>O'Neill, C., Ting, Y.-S., Ciuca, I., Miller, J., and Bui, T.<br>Steering language generation: Harnessing contrastive<br>expert guidance and negative prompting for coherent and<br>diverse synthetic data generation. arXiv preprint arXiv:<br>2308.07645, 2023.</p>\",\n",
       "  \"<p id='7' data-category='paragraph' style='font-size:20px'>OpenAI, Achiam, J., Adler, S., Agarwal, S., Ahmad, L.,<br>Akkaya, I., Aleman, F. L., Almeida, D., Altenschmidt, J.,<br>Altman, S., Anadkat, S., Avila, R., Babuschkin, I., Bal-<br>aji, S., Balcom, V., Baltescu, P., Bao, H., Bavarian, M.,<br>Belgum, J., Bello, I., Berdine, J., Bernadett-Shapiro, G.,<br>Berner, C., Bogdonoff, L., Boiko, 0., Boyd, M., Brakman,<br>A.-L., Brockman, G., Brooks, T., Brundage, M., Button,<br>K., Cai, T., Campbell, R., Cann, A., Carey, B., Carlson,<br>C., Carmichael, R., Chan, B., Chang, C., Chantzis, F.,<br>Chen, D., Chen, S., Chen, R., Chen, J., Chen, M., Chess,<br>B., Cho, C., Chu, C., Chung, H. W., Cummings, D., Cur-<br>rier, J., Dai, Y., Decareaux, C., Degry, T., Deutsch, N.,<br>Deville, D., Dhar, A., Dohan, D., Dowling, S., Dunning,<br>S., Ecoffet, A., Eleti, A., Eloundou, T., Farhi, D., Fedus,<br>L., Felix, N., Fishman, S. P., Forte, J., Fulford, I., Gao, L.,<br>Georges, E., Gibson, C., Goel, V., Gogineni, T., Goh, G.,<br>Gontijo-Lopes, R., Gordon, J., Grafstein, M., Gray, S.,<br>Greene, R., Gross, J., Gu, S. S., Guo, Y., Hallacy, C., Han,<br>J., Harris, J., He, Y., Heaton, M., Heidecke, J., Hesse,</p>\",\n",
       "  \"<br><p id='8' data-category='paragraph' style='font-size:20px'>C., Hickey, A., Hickey, W., Hoeschele, P., Houghton, B.,<br>Hsu, K., Hu, S., Hu, X., Huizinga, J., Jain, S., Jain, S.,<br>Jang, J., Jiang, A., Jiang, R., Jin, H., Jin, D., Jomoto, S.,<br>Jonn, B., Jun, H., Kaftan, T., ukasz Kaiser, Kamali, A.,<br>Kanitscheider, I., Keskar, N. S., Khan, T., Kilpatrick, L.,<br>Kim, J. W., Kim, C., Kim, Y., Kirchner, J. H., Kiros, J.,<br>Knight, M., Kokotajlo, D., ukasz Kondraciuk, Kondrich,<br>A., Konstantinidis, A., Kosic, K., Krueger, G., Kuo, V.,<br>Lampe, M., Lan, I., Lee, T., Leike, J., Leung, J., Levy, D.,<br>Li, C. M., Lim, R., Lin, M., Lin, S., Litwin, M., Lopez, T.,<br>Lowe, R., Lue, P., Makanju, A., Malfacini, K., Manning,<br>S., Markov, T., Markovski, Y., Martin, B., Mayer, K.,<br>Mayne, A., McGrew, B., McKinney, S. M., McLeavey, C.,<br>McMillan, P., McNeil, J., Medina, D., Mehta, A., Menick,<br>J., Metz, L., Mishchenko, A., Mishkin, P., Monaco, V.,<br>Morikawa, E., Mossing, D., Mu, T., Murati, M., Murk, 0.,<br>Mly, D., Nair, A., Nakano, R., Nayak, R., Neelakantan,<br>A., Ngo, R., Noh, H., Ouyang, L., O'Keefe, C., Pachocki,<br>J., Paino, A., Palermo, J., Pantuliano, A., Parascandolo,<br>G., Parish, J., Parparita, E., Passos, A., Pavlov, M., Peng,<br>A., Perelman, A., de Avila Belbute Peres, F., Petrov, M.,<br>de Oliveira Pinto, H. P., Michael, Pokorny, Pokrass, M.,<br>Pong, V. H., Powell, T. Power, A., Power, B., Proehl, E.,<br>Puri, R., Radford, A., Rae, J., Ramesh, A., Raymond, C.,<br>Real, F., Rimbach, K., Ross, C., Rotsted, B., Roussez,<br>H., Ryder, N., Saltarelli, M., Sanders, T., Santurkar, S.,<br>Sastry, G., Schmidt, H., Schnurr, D., Schulman, J., Sel-<br>sam, D. , Sheppard, K., Sherbakov, T., Shieh, J. , Shoker,<br>S., Shyam, P., Sidor, S., Sigler, E., Simens, M., Sitkin,<br>J., Slama, K., Sohl, I., Sokolowsky, B., Song, Y., Stau-<br>dacher, N., Such, F. P., Summers, N., Sutskever, I., Tang,<br>J., Tezak, N., Thompson, M. B., Tillet, P., Tootoonchian,<br>A., Tseng, E., Tuggle, P., Turley, N., Tworek, J., Uribe, J.<br>F. C., Vallone, A., Vijayvergiya, A., Voss, C., Wainwright,<br>C., Wang, J. J., Wang, A., Wang, B., Ward, J., Wei, J.,<br>Weinmann, C., Welihinda, A., Welinder, P., Weng, J.,<br>Weng, L., Wiethoff, M., Willner, D., Winter, C., Wolrich,<br>S., Wong, H., Workman, L., Wu, S., Wu, J., Wu, M.,<br>Xiao, K., Xu, T., Yoo, S., Yu, K., Yuan, Q., Zaremba,<br>W., Zellers, R., Zhang, C., Zhang, M., Zhao, S., Zheng,<br>T., Zhuang, J., Zhuk, W., and Zoph, B. Gpt-4 technical<br>report. arXiv preprint arXiv: 2303.08774, 2023.</p>\",\n",
       "  \"<p id='9' data-category='paragraph' style='font-size:16px'>Peng, B., Li, C., He, P., Galley, M., and Gao, J. Instruction<br>tuning with gpt-4. arXiv preprint arXiv: 2304.03277,<br>2023.</p>\",\n",
       "  \"<p id='10' data-category='paragraph' style='font-size:14px'>Reimers, N. and Gurevych, I. Sentence-bert: Sentence em-<br>beddings using siamese bert-networks. In Proceedings<br>of the 2019 Conference on Empirical Methods in Natu-<br>ral Language Processing. Association for Computational<br>Linguistics, 11 2019. URL https : / /arxiv.org/<br>abs/ 1908 · 10084.</p>\",\n",
       "  \"<p id='11' data-category='paragraph' style='font-size:20px'>Rein, D., Hou, B. L., Stickland, A. C., Petty, J., Pang,</p>\",\n",
       "  \"<footer id='12' style='font-size:14px'>11</footer>\",\n",
       "  \"<header id='13' style='font-size:14px'>MAP</header>\",\n",
       "  \"<p id='14' data-category='paragraph' style='font-size:16px'>R. Y., Dirani, J., Michael, J., and Bowman, S. R. Gpqa:<br>A graduate-level google-proof q&a benchmark. arXiv<br>preprint arXiv: 2311.12022, 2023.</p>\",\n",
       "  \"<p id='15' data-category='paragraph' style='font-size:16px'>Renze, M. and Guven, E. Self-reflection in Ilm agents:<br>Effects on problem-solving performance. arXiv preprint<br>arXiv: 2405.06682, 2024.</p>\",\n",
       "  \"<p id='16' data-category='paragraph' style='font-size:20px'>Sanh, V., Webson, A., Raffel, C., Bach, S. H., Sutawika, L.,<br>Alyafeai, Z., Chaffin, A., Stiegler, A., Scao, T. L., Raja,<br>A., Dey, M., Bari, M. S., Xu, C., Thakker, U., Sharma,<br>S. S., Szczechla, E., Kim, T., Chhablani, G., Nayak, N.,<br>Datta, D., Chang, J., Jiang, M. T.-J., Wang, H., Manica,<br>M., Shen, S., Yong, Z. X., Pandey, H., Bawden, R., Wang,<br>T., Neeraj, T., Rozen, J., Sharma, A., Santilli, A., Fevry,<br>T., Fries, J. A., Teehan, R., Bers, T., Biderman, S., Gao, L.,<br>Wolf, T., and Rush, A. M. Multitask prompted training<br>enables zero-shot task generalization. arXiv preprint<br>arXiv: 2110.08207, 2021.</p>\",\n",
       "  \"<p id='17' data-category='paragraph' style='font-size:20px'>Scheurer, J., Campos, J. A., Chan, J. S., Chen, A., Cho, K.,<br>and Perez, E. Training language models with language<br>feedback. arXiv preprint arXiv: 2204.14146, 2022.</p>\",\n",
       "  \"<p id='18' data-category='paragraph' style='font-size:16px'>Shumailov, I., Shumaylov, Z., Zhao, Y., Gal, Y., Papernot,<br>N., and Anderson, R. The curse of recursion: Training<br>on generated data makes models forget. arXiv preprint<br>arXiv: 2305.17493, 2023.</p>\",\n",
       "  \"<p id='19' data-category='paragraph' style='font-size:20px'>Sun, Z., Shen, Y., Zhou, Q., Zhang, H., Chen, Z., Cox, D.,<br>Yang, Y., and Gan, C. Principle-driven self-alignment<br>of language models from scratch with minimal human<br>supervision. arXiv preprint arXiv: 2305.03047, 2023.</p>\",\n",
       "  \"<p id='20' data-category='paragraph' style='font-size:16px'>Taori, R., Gulrajani, I., Zhang, T., Dubois, Y., Li,<br>X., Guestrin, C., Liang, P., and Hashimoto, T. B.<br>Stanford alpaca: An instruction-following llama<br>model. https : / /github · com/tatsu-lab/<br>stanford_alpaca, 2023.</p>\",\n",
       "  \"<p id='21' data-category='paragraph' style='font-size:20px'>Team, G., Anil, R., Borgeaud, S., Alayrac, J.-B., Yu, J.,<br>Soricut, R., Schalkwyk, J., Dai, A. M., Hauth, A., Milli-<br>can, K., Silver, D., Johnson, M., Antonoglou, I., Schrit-<br>twieser, J., Glaese, A., Chen, J., Pitler, E., Lillicrap, T.,<br>Lazaridou, A., Firat, O., Molloy, J., Isard, M., Barham,<br>P. R., Hennigan, T., Lee, B., Viola, F., Reynolds, M.,<br>Xu, Y., Doherty, R., Collins, E., Meyer, C., Rutherford,<br>E., Moreira, E., Ayoub, K., Goel, M., Krawczyk, J.,<br>Du, C., Chi, E., Cheng, H.-T., Ni, E., Shah, P., Kane,<br>P., Chan, B., Faruqui, M., Severyn, A., Lin, H., Li, Y.,<br>Cheng, Y., Ittycheriah, A., Mahdieh, M., Chen, M., Sun,<br>P., Tran, D., Bagri, S., Lakshminarayanan, B., Liu, J.,<br>Orban, A., Gra, F., Zhou, H., Song, X., Boffy, A., Gana-<br>pathy, H., Zheng, S., Choe, H., goston Weisz, Zhu, T.,<br>Lu, Y., Gopal, S., Kahn, J., Kula, M., Pitman, J., Shah,<br>R., Taropa, E., Merey, M. A., Baeuml, M., Chen, Z.,</p>\",\n",
       "  \"<br><p id='22' data-category='paragraph' style='font-size:20px'>Shafey, L. E., Zhang, Y., Sercinoglu, O., Tucker, G., Pi-<br>queras, E., Krikun, M., Barr, I., Savinov, N., Danihelka,<br>I., Roelofs, B., White, A., Andreassen, A., von Glehn,<br>T., Yagati, L., Kazemi, M., Gonzalez, L., Khalman, M.,<br>Sygnowski, J., Frechette, A., Smith, C., Culp, L., Proleev,<br>L., Luan, Y., Chen, X., Lottes, J., Schucher, N., Lebron,<br>F., Rrustemi, A., Clay, N., Crone, P., Kocisky, T., Zhao,<br>J., Perz, B., Yu, D., Howard, H., Bloniarz, A., Rae, J. W.,<br>Lu, H., Sifre, L., Maggioni, M., Alcober, F., Garrette,<br>D., Barnes, M., Thakoor, S., Austin, J., Barth-Maron, G.,<br>Wong, W., Joshi, R., Chaabouni, R., Fatiha, D., Ahuja,<br>A., Tomar, G. S., Senter, E., Chadwick, M., Kornakov,<br>I., Attaluri, N., Iturrate, I., Liu, R., Li, Y., Cogan, S.,<br>Chen, J., Jia, C., Gu, C., Zhang, Q., Grimstad, J., Hart-<br>man, A. J., Garcia, X., Pillai, T. S., Devlin, J., Laskin, M.,<br>de Las Casas, D., Valter, D., Tao, C., Blanco, L., Badia,<br>A. P., Reitter, D., Chen, M., Brennan, J., Rivera, C., Brin,<br>S., Iqbal, S., Surita, G., Labanowski, J., Rao, A., Winkler,<br>S., Parisotto, E., Gu, Y., Olszewska, K., Addanki, R.,<br>Miech, A., Louis, A., Teplyashin, D., Brown, G., Catt, E.,<br>Balaguer, J., Xiang, J., Wang, P., Ashwood, Z., Briukhov,<br>A., Webson, A., Ganapathy, S., Sanghavi, S., Kannan,<br>A., Chang, M.-W., Stjerngren, A., Djolonga, J., Sun, Y.,<br>Bapna, A., Aitchison, M., Pejman, P., Michalewski, H.,<br>Yu, T., Wang, C., Love, J., Ahn, J., Bloxwich, D., Han,<br>K., Humphreys, P., Sellam, T., Bradbury, J., Godbole, V.,<br>Samangooei, S., Damoc, B., Kaskasoli, A., Arnold, S.<br>M. R., Vasudevan, V., Agrawal, S., Riesa, J., Lepikhin,<br>D., Tanburn, R., Srinivasan, S., Lim, H., Hodkinson, S.,<br>Shyam, P., Ferret, J., Hand, S., Garg, A., Paine, T. L.,<br>Li, J., Li, Y., Giang, M., Neitz, A., Abbas, Z., York, S.,<br>Reid, M., Cole, E., Chowdhery, A., Das, D., Rogoziska,<br>D., Nikolaev, V., Sprechmann, P., Nado, Z., Zilka, L.,<br>Prost, F., He, L., Monteiro, M., Mishra, G., Welty, C.,<br>Newlan, J., Jia, D., Allamanis, M., Hu, C. H., de Liedek-<br>erke, R., Gilmer, J., Saroufim, C., Rijhwani, S., Hou, S.,<br>Shrivastava, D., Baddepudi, A., Goldin, A., Ozturel, A.,<br>Cassirer, A., Xu, Y., Sohn, D., Sachan, D., Amplayo,<br>R. K., Swanson, C., Petrova, D., Narayan, S., Guez, A.,<br>Brahma, S., Landon, J., Patel, M., Zhao, R., Villela, K.,<br>Wang, L., Jia, W., Rahtz, M., Gimnez, M., Yeung, L.,<br>Keeling, J., Georgiev, P., Mincu, D., Wu, B., Haykal, S.,<br>Saputro, R., Vodrahalli, K., Qin, J., Cankara, Z., Sharma,<br>A., Fernando, N., Hawkins, W., Neyshabur, B., Kim, S.,<br>Hutter, A., Agrawal, P., Castro-Ros, A., van den Driess-<br>che, G., Wang, T., Yang, F., yiin Chang, S., Komarek, P.,<br>McIlroy, R., Lui, M., Zhang, G., Farhan, W., Sharman,<br>M., Natsev, P., Michel, P., Bansal, Y., Qiao, S., Cao, K.,<br>Shakeri, S., Butterfield, C., Chung, J., Rubenstein, P. K.,<br>Agrawal, S., Mensch, A., Soparkar, K., Lenc, K., Chung,<br>T., Pope, A., Maggiore, L., Kay, J., Jhakra, P., Wang, S.,<br>Maynez, J., Phuong, M., Tobin, T., Tacchetti, A., Trebacz,<br>M., Robinson, K., Katariya, Y., Riedel, S., Bailey, P.,<br>Xiao, K., Ghelani, N., Aroyo, L., Slone, A., Houlsby, N.,</p>\",\n",
       "  \"<footer id='23' style='font-size:16px'>12</footer>\",\n",
       "  \"<header id='24' style='font-size:14px'>MAP</header>\",\n",
       "  \"<p id='25' data-category='paragraph' style='font-size:18px'>Xiong, X., Yang, Z., Gribovskaya, E., Adler, J., Wirth,<br>M., Lee, L., Li, M., Kagohara, T., Pavagadhi, J., Bridgers,<br>S., Bortsova, A., Ghemawat, S., Ahmed, Z., Liu, T., Pow-<br>ell, R., Bolina, V., Iinuma, M., Zablotskaia, P., Besley, J.,<br>Chung, D.-W., Dozat, T., Comanescu, R., Si, X., Greer,<br>J., Su, G., Polacek, M., Kaufman, R. L., Tokumine, S.,<br>Hu, H., Buchatskaya, E., Miao, Y., Elhawaty, M., Sid-<br>dhant, A., Tomasev, N., Xing, J., Greer, C., Miller, H.,<br>Ashraf, S., Roy, A., Zhang, Z., Ma, A., Filos, A., Besta,<br>M., Blevins, R., Klimenko, T., Yeh, C.-K., Changpinyo,<br>S., Mu, J., Chang, 0., Pajarskas, M., Muir, C., Cohen, V.,<br>Lan, C. L., Haridasan, K., Marathe, A., Hansen, S., Dou-<br>glas, S., Samuel, R., Wang, M., Austin, S., Lan, C., Jiang,<br>J., Chiu, J., Lorenzo, J. A., Sjsund, L. L., Cevey, S., Gle-<br>icher, Z., Avrahami, T., Boral, A., Srinivasan, H., Selo, V.,<br>May, R., Aisopos, K., Hussenot, L., Soares, L. B., Baumli,<br>K., Chang, M. B., Recasens, A., Caine, B., Pritzel, A.,<br>Pavetic, F. Pardo, F., Gergely, A., Frye, J., Ramasesh,<br>V., Horgan, D., Badola, K., Kassner, N., Roy, S., Dyer,<br>E., Campos, V. C., Tomala, A., Tang, Y., Badawy, D. E.,<br>White, E., Mustafa, B., Lang, O., Jindal, A., Vikram, S.,<br>Gong, Z., Caelles, S., Hemsley, R., Thornton, G., Feng,<br>F. Stokowiec, W., Zheng, C., Thacker, P., alar nl, Zhang,<br>Z., Saleh, M., Svensson, J., Bileschi, M., Patil, P., Anand,<br>A., Ring, R., Tsihlas, K., Vezer, A., Selvi, M., Shevlane,<br>T., Rodriguez, M., Kwiatkowski, T., Daruki, S., Rong,<br>K., Dafoe, A., FitzGerald, N., Gu-Lemberg, K., Khan,<br>M., Hendricks, L. A., Pellat, M., Feinberg, V., Cobon-<br>Kerr, J., Sainath, T., Rauh, M., Hashemi, S. H., Ives,<br>R., Hasson, Y., Noland, E., Cao, Y., Byrd, N., Hou, L.,<br>Wang, Q., Sottiaux, T., Paganini, M., Lespiau, J.-B., Mou-<br>farek, A., Hassan, S., Shivakumar, K., van Amersfoort, J.,<br>Mandhane, A., Joshi, P., Goyal, A., Tung, M., Brock, A.,<br>Sheahan, H., Misra, V., Li, C., Rakievi, N., Dehghani, M.,<br>Liu, F., Mittal, S., Oh, J., Noury, S., Sezener, E., Huot, F.,<br>Lamm, M., Cao, N. D., Chen, C., Mudgal, S., Stella, R.,<br>Brooks, K., Vasudevan, G., Liu, C., Chain, M., Melink-<br>eri, N., Cohen, A., Wang, V., Seymore, K., Zubkov, S.,<br>Goel, R., Yue, S., Krishnakumaran, S., Albert, B., Hurley,<br>N., Sano, M., Mohananey, A., Joughin, J., Filonov, E.,<br>Kpa, T., Eldawy, Y., Lim, J., Rishi, R., Badiezadegan, S.,<br>Bos, T., Chang, J., Jain, S., Padmanabhan, S. G. S., Putta-<br>gunta, S., Krishna, K., Baker, L., Kalb, N., Bedapudi, V.,<br>Kurzrok, A., Lei, S., Yu, A., Litvin, O., Zhou, X., Wu, Z.,<br>Sobell, S., Siciliano, A., Papir, A., Neale, R., Bragagnolo,<br>J., Toor, T., Chen, T., Anklin, V., Wang, F., Feng, R.,<br>Gholami, M., Ling, K., Liu, L., Walter, J., Moghaddam,<br>H., Kishore, A., Adamek, J., Mercado, T., Mallinson, J.,<br>Wandekar, S., Cagle, S., Ofek, E., Garrido, G., Lombriser,<br>C., Mukha, M., Sun, B., Mohammad, H. R., Matak, J.,<br>Qian, Y., Peswani, V., Janus, P., Yuan, Q., Schelin, L.,<br>David, 0., Garg, A., He, Y., Duzhyi, 0., lgmyr, A., Lottaz,<br>T., Li, Q., Yadav, V., Xu, L., Chinien, A., Shivanna, R.,<br>Chuklin, A., Li, J., Spadine, C., Wolfe, T., Mohamed, K.,</p>\",\n",
       "  \"<br><p id='26' data-category='paragraph' style='font-size:18px'>Das, S., Dai, Z., He, K., von Dincklage, D., Upadhyay, S.,<br>Maurya, A., Chi, L., Krause, S., Salama, K., Rabinovitch,<br>P. G., M, P. K. R., Selvan, A., Dektiarev, M., Ghiasi, G.,<br>Guven, E., Gupta, H., Liu, B., Sharma, D., Shtacher, I. H.,<br>Paul, S., Akerlund, O., Aubet, F.-X., Huang, T., Zhu, C.,<br>Zhu, E., Teixeira, E., Fritze, M., Bertolini, F., Marinescu,<br>L.-E., Blle, M., Paulus, D., Gupta, K., Latkar, T., Chang,<br>M., Sanders, J., Wilson, R., Wu, X., Tan, Y.-X., Thiet,<br>L. N., Doshi, T., Lall, S., Mishra, S., Chen, W., Luong, T.,<br>Benjamin, S., Lee, J., Andrejczuk, E., Rabiej, D., Ranjan,<br>V., Styrc, K., Yin, P., Simon, J., Harriott, M. R., Bansal,<br>M., Robsky, A., Bacon, G., Greene, D., Mirylenka, D.,<br>Zhou, C., Sarvana, O., Goyal, A., Andermatt, S., Siegler,<br>P., Horn, B., Israel, A., Pongetti, F., Chen, C.-W. L., Sel-<br>vatici, M., Silva, P., Wang, K., Tolins, J., Guu, K., Yogev,<br>R., Cai, X., Agostini, A., Shah, M., Nguyen, H., Don-<br>naile, N. , Pereira, S., Friso, L., Stambler, A., Kurzrok,<br>A., Kuang, C., Romanikhin, Y., Geller, M., Yan, Z., Jang,<br>K., Lee, C.-C., Fica, W., Malmi, E., Tan, Q., Banica,<br>D., Balle, D., Pham, R., Huang, Y., Avram, D., Shi, H.,<br>Singh, J., Hidey, C., Ahuja, N., Saxena, P., Dooley, D.,<br>Potharaju, S. P., O'Neill, E., Gokulchandran, A., Foley,<br>R., Zhao, K., Dusenberry, M., Liu, Y., Mehta, P., Kotikala-<br>pudi, R., Safranek-Shrader, C., Goodman, A., Kessinger,<br>J., Globen, E., Kolhar, P., Gorgolewski, C., Ibrahim, A.,<br>Song, Y., Eichenbaum, A., Brovelli, T., Potluri, S., La-<br>hoti, P., Baetu, C., Ghorbani, A., Chen, C., Crawford, A.,<br>Pal, S., Sridhar, M., Gurita, P., Mujika, A., Petrovski, I.,<br>Cedoz, P.-L., Li, C., Chen, S., Santo, N. D., Goyal, S.,<br>Punjabi, J., Kappaganthu, K., Kwak, C., LV,P., Velury, S.,<br>Choudhury, H., Hall, J., Shah, P., Figueira, R., Thomas,<br>M., Lu, M., Zhou, T., Kumar, C., Jurdi, T., Chikkerur, S.,<br>Ma, Y., Yu, A., Kwak, S., hdel, V., Rajayogam, S., Choma,<br>T., Liu, F., Barua, A., Ji, C., Park, J. H., Hellendoorn, V.,<br>Bailey, A., Bilal, T., Zhou, H., Khatir, M., Sutton, C.,<br>Rzadkowski, W., Macintosh, F., Shagin, K., Medina, P.,<br>Liang, C., Zhou, J., Shah, P., Bi, Y., Dankovics, A., Banga,<br>S., Lehmann, S., Bredesen, M., Lin, Z., Hoffmann, J. E.,<br>Lai, J., Chung, R., Yang, K., Balani, N., Brainskas, A.,<br>Sozanschi, A., Hayes, M., Alcalde, H. F., Makarov, P.,<br>Chen, W., Stella, A., Snijders, L., Mandl, M., Krrman,<br>A., Nowak, P., Wu, X., Dyck, A., Vaidyanathan, K., R,<br>R., Mallet, J., Rudominer, M., Johnston, E., Mittal, S.,<br>Udathu, A., Christensen, J., Verma, V., Irving, Z., San-<br>tucci, A., Elsayed, G., Davoodi, E., Georgiev, M., Tenney,<br>I., Hua, N., Cideron, G., Leurent, E., Alnahlawi, M.,<br>Georgescu, I., Wei, N., Zheng, I., Scandinaro, D., Jiang,<br>H., Snoek, J., Sundararajan, M., Wang, X., Ontiveros, Z.,<br>Karo, I., Cole, J., Rajashekhar, V., Tumeh, L., Ben-David,<br>E., Jain, R., Uesato, J., Datta, R., Bunyan, O., Wu, S.,<br>Zhang, J., Stanczyk, P., Zhang, Y., Steiner, D., Naskar,<br>S., Azzam, M., Johnson, M., Paszke, A., Chiu, C.-C.,<br>Elias, J. S., Mohiuddin, A., Muhammad, F., Miao, J.,<br>Lee, A., Vieillard, N., Park, J., Zhang, J., Stanway, J.,</p>\",\n",
       "  \"<footer id='27' style='font-size:14px'>13</footer>\",\n",
       "  \"<header id='28' style='font-size:14px'>MAP</header>\",\n",
       "  \"<p id='29' data-category='paragraph' style='font-size:18px'>Garmon, D., Karmarkar, A., Dong, Z., Lee, J., Kumar,<br>A., Zhou, L., Evens, J., Isaac, W., Irving, G., Loper, E.,<br>Fink, M., Arkatkar, I., Chen, N., Shafran, I., Petrychenko,<br>I., Chen, Z., Jia, J., Levskaya, A., Zhu, Z., Grabowski,<br>P., Mao, Y., Magni, A., Yao, K., Snaider, J., Casagrande,<br>N., Palmer, E., Suganthan, P., Castao, A., Giannoumis, I.,<br>Kim, W., Rybiski, M., Sreevatsa, A., Prendki, J., Soergel,<br>D., Goedeckemeyer, A., Gierke, W., Jafari, M., Gaba,<br>M., Wiesner, J., Wright, D. G., Wei, Y., Vashisht, H.,<br>Kulizhskaya, Y., Hoover, J., Le, M., Li, L., Iwuanyanwu,<br>C., Liu, L., Ramirez, K., Khorlin, A., Cui, A., LIN, T.,<br>Wu, M., Aguilar, R., Pallo, K., Chakladar, A., Perng, G.,<br>Abellan, E. A., Zhang, M., Dasgupta, I., Kushman, N.,<br>Penchev, I., Repina, A., Wu, X., van der Weide, T., Pon-<br>napalli, P., Kaplan, C., Simsa, J., Li, S., Dousse, 0., Yang,<br>F., Piper, J., Ie, N., Pasumarthi, R., Lintz, N., Vijayaku-<br>mar, A., Andor, D., Valenzuela, P., Lui, M., Paduraru,<br>C., Peng, D., Lee, K., Zhang, S., Greene, S., Nguyen,<br>D. D., Kurylowicz, P., Hardin, C., Dixon, L., Janzer, L.,<br>Choo, K., Feng, Z., Zhang, B., Singhal, A., Du, D., McK-<br>innon, D., Antropova, N., Bolukbasi, T., Keller, O., Reid,<br>D., Finchelstein, D., Raad, M. A., Crocker, R., Hawkins,<br>P., Dadashi, R., Gaffney, C., Franko, K., Bulanova, A.,<br>Leblond, R., Chung, S., Askham, H., Cobo, L. C., Xu,<br>K., Fischer, F., Xu, J., Sorokin, C., Alberti, C., Lin, C.-<br>C., Evans, C., Dimitriev, A., Forbes, H., Banarse, D.,<br>Tung, Z., Omernick, M., Bishop, C., Sterneck, R., Jain,<br>R., Xia, J., Amid, E., Piccinno, F., Wang, X., Banzal, P.,<br>Mankowitz, D. J., Polozov, A., Krakovna, V., Brown, S.,<br>Bateni, M., Duan, D., Firoiu, V., Thotakuri, M., Natan,<br>T., Geist, M., tan Girgin, S., Li, H., Ye, J., Roval, 0.,<br>Tojo, R., Kwong, M., Lee-Thorp, J., Yew, C., Sinopal-<br>nikov, D., Ramos, S., Mellor, J., Sharma, A., Wu, K.,<br>Miller, D., Sonnerat, N., Vnukov, D., Greig, R., Beattie,<br>J., Caveness, E., Bai, L., Eisenschlos, J., Korchemniy,<br>A., Tsai, T., Jasarevic, M., Kong, W., Dao, P., Zheng, Z.,<br>Liu, F., Yang, F., Zhu, R., Teh, T. H., Sanmiya, J., Glad-<br>chenko, E., Trdin, N., Toyama, D., Rosen, E., Tavakkol,<br>S., Xue, L., Elkind, C., Woodman, 0., Carpenter, J., Papa-<br>makarios, G., Kemp, R., Kafle, S., Grunina, T., Sinha, R.,<br>Talbert, A., Wu, D., Owusu-Afriyie, D., Du, C., Thorn-<br>ton, C., Pont-Tuset, J., Narayana, P., Li, J., Fatehi, S.,<br>Wieting, J., Ajmeri, O., Uria, B., Ko, Y., Knight, L.,<br>Hliou, A., Niu, N., Gu, S., Pang, C., Li, Y., Levine, N.,<br>Stolovich, A., Santamaria-Fernandez, R., Goenka, S.,<br>Yustalim, W., Strudel, R., Elqursh, A., Deck, C., Lee,<br>H., Li, Z., Levin, K., Hoffmann, R., Holtmann-Rice, D.,<br>Bachem, 0., Arora, S., Koh, C., Yeganeh, S. H., Pder, S.,<br>Tariq, M., Sun, Y., Ionita, L., Seyedhosseini, M., Tafti, P.,<br>Liu, Z., Gulati, A., Liu, J., Ye, X., Chrzaszcz, B., Wang,<br>L., Sethi, N., Li, T. Brown, B., Singh, S., Fan, W., Parisi,<br>A., Stanton, J., Koverkathu, V., Choquette-Choo, C. A.,<br>Li, Y., Lu, T., Ittycheriah, A., Shroff, P., Varadarajan, M.,<br>Bahargam, S., Willoughby, R., Gaddy, D., Desjardins,</p>\",\n",
       "  \"<br><p id='30' data-category='paragraph' style='font-size:18px'>G., Cornero, M., Robenek, B., Mittal, B., Albrecht, B.,<br>Shenoy, A., Moiseev, F., Jacobsson, H., Ghaffarkhah,<br>A., Rivire, M., Walton, A., Crepy, C., Parrish, A., Zhou,<br>Z., Farabet, C., Radebaugh, C., Srinivasan, P., van der<br>Salm, C., Fidjeland, A., Scellato, S., Latorre-Chimoto,<br>E., Klimczak-Pluciska, H., Bridson, D., de Cesare, D.,<br>Hudson, T., Mendolicchio, P., Walker, L., Morris, A.,<br>Mauger, M., Guseynov, A., Reid, A., Odoom, S., Loher,<br>L., Cotruta, V., Yenugula, M., Grewe, D., Petrushkina, A.,<br>Duerig, T., Sanchez, A., Yadlowsky, S., Shen, A., Glober-<br>son, A., Webb, L., Dua, S., Li, D., Bhupatiraju, S., Hurt,<br>D., Qureshi, H., Agarwal, A., Shani, T., Eyal, M., Khare,<br>A., Belle, S. R., Wang, L., Tekur, C., Kale, M. S., Wei, J.,<br>Sang, R., Saeta, B., Liechty, T., Sun, Y., Zhao, Y., Lee, S.,<br>Nayak, P., Fritz, D., Vuyyuru, M. R., Aslanides, J., Vyas,<br>N., Wicke, M., Ma, X., Eltyshev, E., Martin, N., Cate, H.,<br>Manyika, J., Amiri, K., Kim, Y., Xiong, X., Kang, K.,<br>Luisier, F., Tripuraneni, N., Madras, D., Guo, M., Waters,<br>A., Wang, 0., Ainslie, J., Baldridge, J., Zhang, H., Pruthi,<br>G., Bauer, J., Yang, F., Mansour, R., Gelman, J., Xu, Y.,<br>Polovets, G., Liu, J., Cai, H., Chen, W., Sheng, X., Xue,<br>E., Ozair, S., Angermueller, C., Li, X., Sinha, A., Wang,<br>W., Wiesinger, J., Koukoumidis, E., Tian, Y., Iyer, A.,<br>Gurumurthy, M., Goldenson, M., Shah, P., Blake, M., Yu,<br>H., Urbanowicz, A., Palomaki, J., Fernando, C., Durden,<br>K., Mehta, H., Momchev, N., Rahimtoroghi, E., Geor-<br>gaki, M., Raul, A., Ruder, S., Redshaw, M., Lee, J., Zhou,<br>D., Jalan, K., Li, D., Hechtman, B., Schuh, P., Nasr, M.,<br>Milan, K., Mikulik, V., Franco, J., Green, T., Nguyen,<br>N., Kelley, J., Mahendru, A., Hu, A., Howland, J., Var-<br>gas, B., Hui, J., Bansal, K., Rao, V., Ghiya, R., Wang,<br>E., Ye, K., Sarr, J. M., Preston, M. M., Elish, M., Li, S.,<br>Kaku, A., Gupta, J., Pasupat, I., Juan, D.-C., Someswar,<br>M., M., T., Chen, X., Amini, A., Fabrikant, A., Chu, E.,<br>Dong, X., Muthal, A., Buthpitiya, S., Jauhari, S., Hua, N.,<br>Khandelwal, U., Hitron, A., Ren, J., Rinaldi, L., Drath,<br>S., Dabush, A., Jiang, N.-J., Godhia, H., Sachs, U., Chen,<br>A., Fan, Y., Taitelbaum, H., Noga, H., Dai, Z., Wang, J.,<br>Liang, C., Hamer, J., Ferng, C.-S., Elkind, C., Atias, A.,<br>Lee, P., Listk, V., Carlen, M., van de Kerkhof, J., Pikus,<br>M., Zaher, K., Mller, P., Zykova, S., Stefanec, R., Gatsko,<br>V., Hirnschall, C., Sethi, A., Xu, X. F. Ahuja, C., Tsai,<br>B., Stefanoiu, A., Feng, B., Dhandhania, K., Katyal, M.,<br>Gupta, A., Parulekar, A., Pitta, D., Zhao, J., Bhatia, V.,<br>Bhavnani, Y., Alhadlaq, O., Li, X., Danenberg, P., Tu,<br>D., Pine, A., Filippova, V., Ghosh, A., Limonchik, B.,<br>Urala, B., Lanka, C. K., Clive, D., Sun, Y., Li, E., Wu,<br>H., Hongtongsak, K., Li, I., Thakkar, K., Omarov, K.,<br>Majmundar, K., Alverson, M., Kucharski, M., Patel, M.,<br>Jain, M., Zabelin, M., Pelagatti, P., Kohli, R., Kumar,<br>S., Kim, J., Sankar, S., Shah, V., Ramachandruni, L.,<br>Zeng, X., Bariach, B., Weidinger, L., Vu, T., Andreev,<br>A., He, A., Hui, K., Kashem, S., Subramanya, A., Hsiao,<br>S., Hassabis, D., Kavukcuoglu, K., Sadovsky, A., Le, Q.,</p>\",\n",
       "  \"<footer id='31' style='font-size:14px'>14</footer>\",\n",
       "  \"<header id='32' style='font-size:16px'>MAP</header>\",\n",
       "  \"<p id='33' data-category='paragraph' style='font-size:18px'>Strohman, T. Wu, Y., Petrov, S., Dean, J., and Vinyals, 0.<br>Gemini: A family of highly capable multimodal models.<br>arXiv preprint arXiv: 2312.11805, 2023.</p>\",\n",
       "  \"<p id='34' data-category='paragraph' style='font-size:16px'>Team, Q. Qwen2.5: A party of foundation models, Septem-<br>ber 2024. URL https : / / qwenlm · github io/<br>blog/ qwen2 · 5/.</p>\",\n",
       "  \"<p id='35' data-category='paragraph' style='font-size:16px'>Teknium. Openhermes 2.5: An open dataset of<br>synthetic data for generalist llm assistants, 2023.<br>URL https : / /huggingface · co/ datasets/<br>teknium/ OpenHermes-2 . 5.</p>\",\n",
       "  \"<p id='36' data-category='paragraph' style='font-size:20px'>Touvron, H., Lavril, T., Izacard, G., Martinet, X., Lachaux,<br>M.-A., Lacroix, T., Rozire, B., Goyal, N., Hambro, E.,<br>Azhar, F., Rodriguez, A., Joulin, A., Grave, E., and Lam-<br>ple, G. Llama: Open and efficient foundation language<br>models. arXiv preprint arXiv: 2302.13971, 2023.</p>\",\n",
       "  \"<p id='37' data-category='paragraph' style='font-size:14px'>Vitter, J. S. Random sampling with a reservoir. ACM Trans.<br>Math. Softw., 11(1):3757, March 1985. ISSN 0098-3500.<br>doi: 10.1145/3147.3165. URL https : / / doi · org/<br>10 · 1145/3147 · 3165.</p>\",\n",
       "  \"<p id='38' data-category='paragraph' style='font-size:20px'>Wang, Y., Kordi, Y., Mishra, S., Liu, A., Smith, N. A.,<br>Khashabi, D., and Hajishirzi, H. Self-instruct: Aligning<br>language models with self-generated instructions. arXiv<br>preprint arXiv: 2212.10560, 2022a.</p>\",\n",
       "  \"<p id='39' data-category='paragraph' style='font-size:18px'>Wang, Y., Mishra, S., Alipoormolabashi, P., Ko-<br>rdi, Y., Mirzaei, A., Arunkumar, A., Ashok, A.,<br>Dhanasekaran, A. S., Naik, A., Stap, D., et al. Super-<br>naturalinstructions:generalization via declarative instruc-<br>tions on 1600+ tasks. In EMNLP, 2022b.</p>\",\n",
       "  \"<p id='40' data-category='paragraph' style='font-size:18px'>Wei, J., Bosma, M., Zhao, V., Guu, K., Yu, A. W., Lester,<br>B., Du, N., Dai, A. M., and Le, Q. V. Finetuned language<br>models are zero-shot learners. International Conference<br>on Learning Representations, 2021.</p>\",\n",
       "  \"<p id='41' data-category='paragraph' style='font-size:20px'>Xie, Y., Goyal, A., Zheng, W., Kan, M.-Y., Lillicrap, T. P.,<br>Kawaguchi, K., and Shieh, M. Monte carlo tree search<br>boosts reasoning via iterative preference learning. arXiv<br>preprint arXiv: 2405.00451, 2024.</p>\",\n",
       "  \"<p id='42' data-category='paragraph' style='font-size:20px'>Yang, A., Yang, B., Hui, B., Zheng, B., Yu, B., Zhou, C., Li,<br>C., Li, C., Liu, D. , Huang, F., Dong, G., Wei, H., Lin, H.,<br>Tang, J., Wang, J., Yang, J., Tu, J., Zhang, J. , Ma, J., Yang,<br>J., Xu, J., Zhou, J., Bai, J., He, J., Lin, J., Dang, K., Lu,<br>K., Chen, K., Yang, K., Li, M., Xue, M., Ni, N., Zhang,<br>P., Wang, P., Peng, R., Men, R., Gao, R., Lin, R., Wang,<br>S., Bai, S. Tan, S. , Zhu, T., Li, T., Liu, T., Ge, W., Deng,<br>,<br>X., Zhou, X., Ren, X., Zhang, X., Wei, X., Ren, X., Liu,<br>X., Fan, Y., Yao, Y., Zhang, Y., Wan, Y., Chu, Y., Liu, Y.,<br>Cui, Z., Zhang, Z., Guo, Z., and Fan, Z. Qwen2 technical<br>report. arXiv preprint arXiv: 2407.10671, 2024a.</p>\",\n",
       "  \"<br><p id='43' data-category='paragraph' style='font-size:20px'>Yang, Z., Pang, T., Feng, H., Wang, H., Chen, W., Zhu,<br>M., and Liu, Q. Self-distillation bridges distribution gap<br>in language model fine-tuning. arXiv preprint arXiv:<br>2402.13669, 2024b.</p>\",\n",
       "  \"<p id='44' data-category='paragraph' style='font-size:18px'>Yu, L., Jiang, W., Shi, H., Yu,J., Liu, Z., Zhang, Y., Kwok,<br>J. T., Li, Z., Weller, A., and Liu, W. Metamath: Boot-<br>strap your own mathematical questions for large language<br>models. International Conference on Learning Represen-<br>tations, 2023. doi: 10.48550/arXiv.2309.12284.</p>\",\n",
       "  \"<p id='45' data-category='paragraph' style='font-size:20px'>Yuan, W., Pang, R. Y., Cho, K., Li, X., Sukhbaatar, S., Xu,<br>J., and Weston, J. Self-rewarding language models. arXiv<br>preprint arXiv: 2401.10020, 2024.</p>\",\n",
       "  \"<p id='46' data-category='paragraph' style='font-size:18px'>Zellers, R., Holtzman, A., Bisk, Y., Farhadi, A., and Choi,<br>Y. Hellaswag: Can a machine really finish your sentence?<br>Annual Meeting of the Association for Computational<br>Linguistics, 2019. doi: 10.18653/v1/P19-1472.</p>\",\n",
       "  \"<p id='47' data-category='paragraph' style='font-size:20px'>Zhang, G., Qu, S., Liu, J., Zhang, C., Lin, C., Yu, C. L.,<br>Pan, D., Cheng, E., Liu, J., Lin, Q., Yuan, R., Zheng, T.,<br>Pang, W., Du, X., Liang, Y., Ma, Y., Li, Y., Ma, Z., Lin,<br>B., Benetos, E., Yang, H., Zhou, J., Ma, K., Liu, M., Niu,<br>M., Wang, N., Que, Q., Liu, R., Liu, S., Guo, S., Gao, S.,<br>Zhou, W., Zhang, X., Zhou, Y., Wang, Y., Bai, Y., Zhang,<br>Y., Zhang, Y., Wang, Z., Yang, Z., Zhao, Z., Zhang, J.,<br>Ouyang, W., Huang, W., and Chen, W. Map-neo: Highly<br>capable and transparent bilingual large language model<br>series. arXiv preprint arXiv: 2405.19327, 2024a.</p>\",\n",
       "  \"<p id='48' data-category='paragraph' style='font-size:20px'>Zhang, J., Juan, D.-C., Rashtchian, C., Ferng, C.-S., Jiang,<br>H., and Chen, Y. Sled: Self logits evolution decoding<br>for improving factuality in large language models. arXiv<br>preprint arXiv: 2411.02433, 2024b.</p>\",\n",
       "  \"<p id='49' data-category='paragraph' style='font-size:18px'>Zheng, T., Guo, S., Qu, X., Guo, J., Du, X., Jia, Q., Lin,<br>C., Huang, W., Fu, J., and Zhang, G. Kun: Answer pol-<br>ishment for chinese self-alignment with instruction back-<br>translation. arXiv preprint arXiv: 2401.06477, 2024.</p>\",\n",
       "  \"<p id='50' data-category='paragraph' style='font-size:20px'>Zhou, C., Liu, P., Xu, P., Iyer, S., Sun, J., Mao, Y., Ma, X.,<br>Efrat, A., Yu, P., Yu, L., Zhang, S., Ghosh, G., Lewis, M.,<br>Zettlemoyer, L., and Levy, 0. Lima: Less is more for<br>alignment. arXiv preprint arXiv: 2305.11206, 2023a.</p>\",\n",
       "  \"<p id='51' data-category='paragraph' style='font-size:20px'>Zhou, J., Lu, T., Mishra, S., Brahma, S., Basu, S., Luan,<br>Y., Zhou, D., and Hou, L. Instruction-following evalu-<br>ation for large language models. arXiv preprint arXiv:<br>2311.07911, 2023b.</p>\",\n",
       "  \"<footer id='52' style='font-size:16px'>15</footer>\",\n",
       "  \"<header id='53' style='font-size:16px'>MAP</header>\",\n",
       "  \"<p id='54' data-category='paragraph' style='font-size:20px'>A. Visualization of SFT Dataset Projections onto the Pre-training Corpus</p>\",\n",
       "  '<figure id=\\'55\\'><img style=\\'font-size:14px\\' alt=\"15 15 15\\n10 10 10\\n2\\n5\\n5 2\\n5 2\\nComponent\\nComponent\\n0 0 0\\n-5 Component\\n-5 -5\\nPCA\\nPCA\\nPCA\\n10 - 10 -10\\n-15 -15 -15\\n-20 -20 -20\\n20 10 0 10 20 - 20 - 10 0 10 20 - 20 -10 0 10 20\\nPCA Component 1 PCA Component 1 PCA Component 1\\n(a) Dolly VS Dolma (b) EvolInstruct VS Dolma (c) Neo-SFT VS Dolma\\n15 15 15\\n10 10 10\\n2\\n5 2\\n5\\n5 2\\nComponent\\nComponent\\n0 0 0\\n-5 Component\\n-5 -5\\nPCA\\nPCA\\n-10 PCA\\n-10 -10\\n-15 -15 -15\\n-20 -20 -20\\n- 20 - 10 0 10 20 20 - 10 0 10 20 20 - 10 0 10 20\\nPCA Component 1 PCA Component 1 PCA Component 1\\n(d) OpenHermes VS Dolma (e) Tulu VS Dolma (f) WildChat VS Dolma\\n15 15 15\\n10 10 10\\n2\\n2\\n2\\nComponent\\nComponent\\nComponent\\n5 5 5\\n0 0 0\\nPCA\\nPCA\\nPCA\\n-5 -5 -5\\n-10 -10 -10\\n- 15 -15 -15\\n20 -15 -10 -5 0 5 10 15 - 20 - 15 -10 -5 0 5 10 15 -20 -15 -10 -5 0 5 10 15\\nPCA Component 1 PCA Component 1 PCA Component 1\\n(g) Dolly VS Cosmopedia (h) Neo-SFT VS Cosmopedia (i) OpenHermes VS Cosmopedia\" data-coord=\"top-left:(111,204); bottom-right:(1142,1332)\" /></figure>',\n",
       "  \"<br><caption id='56' style='font-size:18px'>Figure 6: Visualization of data distribution changes in AITP. The red regions at the bottom denote the pre-training<br>corpus, while the light blue regions above represent the SFT datasets. Darker areas indicate a higher concentration of data<br>points, whereas lighter areas signify sparser distributions.</caption>\",\n",
       "  \"<footer id='57' style='font-size:16px'>16</footer>\",\n",
       "  \"<header id='58' style='font-size:20px'>MAP</header>\",\n",
       "  \"<h1 id='59' style='font-size:22px'>B. Reservoir sampling algorithm</h1>\",\n",
       "  \"<p id='60' data-category='paragraph' style='font-size:20px'>Reservoir Sampling is an efficient streaming data sampling method that enables uniform sampling of k items from a data<br>stream without knowing the total size of the stream. It is particularly suited for scenarios with memory constraints or<br>uncertain stream sizes, allowing for equal-probability sampling in a single pass over the data.</p>\",\n",
       "  \"<table id='61' style='font-size:18px'><tr><td>Algorithm 1 Reservoir Sampling</td></tr><tr><td>Input: stream of data x1, x2, · · · , sample size k</td></tr><tr><td>Output: a random sample of size k</td></tr><tr><td>Initialize an empty reservoir array R of size k</td></tr><tr><td>for i = 1 to k do</td></tr><tr><td>R[i] ← Xi</td></tr><tr><td>end for</td></tr><tr><td>for i = k + 1 to n do</td></tr><tr><td>j ← random integer from 1 to i</td></tr><tr><td>if j ≤ k then</td></tr><tr><td>R[j] ← xi</td></tr><tr><td>end if</td></tr><tr><td>end for</td></tr><tr><td>return R</td></tr></table>\",\n",
       "  \"<h1 id='62' style='font-size:22px'>C. Prompts for data transformation phase</h1>\",\n",
       "  \"<p id='63' data-category='paragraph' style='font-size:20px'>This section introduces the prompts defined in our data transformation phase, including the question generation prompt, the<br>question evaluation prompt, and the answer generation prompt.</p>\",\n",
       "  \"<p id='64' data-category='paragraph' style='font-size:20px'>Query-to-Questions Generator (Step 1)</p>\",\n",
       "  \"<p id='65' data-category='paragraph' style='font-size:16px'>Your task is to generate two questions based on the given text content. Ensure the questions are relevant and directly related to the<br>details provided in the text. Follow these guidelines:</p>\",\n",
       "  \"<br><p id='66' data-category='paragraph' style='font-size:18px'>1. Question Guidelines:</p>\",\n",
       "  \"<p id='67' data-category='list' style='font-size:16px'>· Make sure the questions are closely related to the main points or themes mentioned in the text.<br>· Ensure the two questions are as diverse as possible, avoiding homogeneity.<br>· Ensure the questions include all the information needed for the answers. If necessary, add introductory information to<br>the questions.<br>· The questions must be self-contained and should not require the provided text as background to be understood.</p>\",\n",
       "  \"<br><p id='68' data-category='paragraph' style='font-size:18px'>Please rewrite the following text into related questions, and output them in JSON format: Text: 0<br>Output format example:</p>\",\n",
       "  \"<br><p id='69' data-category='paragraph' style='font-size:14px'>{</p>\",\n",
       "  '<br><p id=\\'70\\' data-category=\\'paragraph\\' style=\\'font-size:14px\\'>\" questions \" [<br>:</p>',\n",
       "  \"<br><p id='71' data-category='paragraph' style='font-size:16px'>{</p>\",\n",
       "  '<br><p id=\\'72\\' data-category=\\'paragraph\\' style=\\'font-size:14px\\'>\" question \" : \" Generated question content 1 \"</p>',\n",
       "  \"<br><p id='73' data-category='paragraph' style='font-size:14px'>} ,</p>\",\n",
       "  \"<br><p id='74' data-category='paragraph' style='font-size:16px'>{</p>\",\n",
       "  '<br><p id=\\'75\\' data-category=\\'paragraph\\' style=\\'font-size:14px\\'>\" question \" : \"Generated question content 2\"</p>',\n",
       "  \"<br><p id='76' data-category='paragraph' style='font-size:14px'>}</p>\",\n",
       "  \"<br><p id='77' data-category='paragraph' style='font-size:16px'>]</p>\",\n",
       "  \"<br><p id='78' data-category='paragraph' style='font-size:14px'>}</p>\",\n",
       "  \"<footer id='79' style='font-size:20px'>17</footer>\",\n",
       "  \"<header id='80' style='font-size:20px'>MAP</header>\",\n",
       "  \"<h1 id='81' style='font-size:22px'>Query Evaluation Scorer (Step 2)</h1>\",\n",
       "  \"<p id='82' data-category='paragraph' style='font-size:16px'>Your task is to evaluate the given query based on the following criteria and output the results in JSON format. The output should<br>include three parts: quality, difficulty, and whether additional necessary information is required to answer the query. Please follow<br>the scoring standards below:</p>\",\n",
       "  \"<p id='83' data-category='paragraph' style='font-size:16px'>1. Quality (Score 1-10): Assess the clarity and accuracy of the query. If the query is a simple statement without any question<br>or instruction, score it 1-2.</p>\",\n",
       "  \"<p id='84' data-category='list' style='font-size:16px'>· 9-10: Very clear, accurate expression, no ambiguity.<br>· 7-8: Clear, accurate expression, but may have minimal ambiguity.<br>· 5-6: Fairly clear, generally accurate expression, but some ambiguity exists.<br>· 3-4: Not very clear, somewhat vague expression, with obvious ambiguity.<br>· 1-2: Unclear, very vague expression, difficult to understand or a simple statement.</p>\",\n",
       "  \"<p id='85' data-category='paragraph' style='font-size:20px'>2. Difficulty (Score 1-10): Assess the difficulty of understanding and answering the query.</p>\",\n",
       "  \"<p id='86' data-category='list' style='font-size:18px'>· 9-10: Very difficult, requires specialized knowledge and complex analysis to answer.<br>· 7-8: Quite difficult, requires some specialized knowledge and analysis.<br>· 5-6: Moderate difficulty, requires general knowledge and analysis.<br>· 3-4: Fairly simple, can be answered with basic knowledge.<br>· 1-2: Very simple, no special knowledge required to answer.</p>\",\n",
       "  \"<p id='87' data-category='paragraph' style='font-size:16px'>3. Whether additional necessary information is required to answer: Determine if extra information is needed to fully answer<br>the query.</p>\",\n",
       "  \"<p id='88' data-category='paragraph' style='font-size:20px'>Please strictly follow the format below for output: Quality: 1-10<br>Difficulty: 1-10<br>Additional Information Needed: True/False<br>Please evaluate the following query: Query: 0<br>Output format example:</p>\",\n",
       "  \"<br><p id='89' data-category='paragraph' style='font-size:16px'>{</p>\",\n",
       "  '<br><p id=\\'90\\' data-category=\\'paragraph\\' style=\\'font-size:14px\\'>\" quality\" : 8 ,<br>\" difficulty \" : 5,<br>\" additional_info_needed \" : true</p>',\n",
       "  \"<br><p id='91' data-category='paragraph' style='font-size:14px'>}</p>\",\n",
       "  \"<h1 id='92' style='font-size:22px'>Question-to-Answer Generator (Step 3)</h1>\",\n",
       "  \"<p id='93' data-category='paragraph' style='font-size:16px'>Your task is to generate an answer based on the given question. Use the background information provided in the text to assist in<br>formulating a relevant and detailed answer. Follow these guidelines:</p>\",\n",
       "  \"<p id='94' data-category='paragraph' style='font-size:16px'>1. Question Guidelines:</p>\",\n",
       "  '<p id=\\'95\\' data-category=\\'list\\' style=\\'font-size:16px\\'>· Ensure the answer is closely related to the main points or themes mentioned in the question.<br>· Utilize the text content to provide a comprehensive and accurate answer.<br>· Ensure proper formatting and readability, including the correct rendering of any LaTeX or mathematical symbols.<br>· Ensure that the answer provides a complete solution or explanation, with clear and detailed steps.<br>· Use JSON format with the key \" answer\" for easy extraction and processing.</p>',\n",
       "  \"<p id='96' data-category='paragraph' style='font-size:20px'>Text:<br>0<br>Question:<br>{}<br>Output format example:</p>\",\n",
       "  \"<p id='97' data-category='paragraph' style='font-size:14px'>{</p>\",\n",
       "  '<br><p id=\\'98\\' data-category=\\'paragraph\\' style=\\'font-size:14px\\'>\" answer \" : \" Generated answer content \"</p>',\n",
       "  \"<br><p id='99' data-category='paragraph' style='font-size:14px'>}</p>\",\n",
       "  \"<footer id='100' style='font-size:20px'>18</footer>\",\n",
       "  \"<header id='101' style='font-size:14px'>MAP</header>\",\n",
       "  \"<h1 id='102' style='font-size:20px'>D. Training parameters</h1>\",\n",
       "  \"<p id='103' data-category='paragraph' style='font-size:14px'>Table 4 presents the hyperparameters used to train the model in the AITP method, which is consistent with those used in the<br>original model's SFT version.</p>\",\n",
       "  \"<p id='104' data-category='paragraph' style='font-size:16px'>Table 4: Hyperparameters in AITP.</p>\",\n",
       "  \"<table id='105' style='font-size:14px'><tr><td>Base Model</td><td>Learning Rate</td><td>Weight Decay</td><td>Warmup Ratio</td><td>Batchsize</td><td>Epoch</td><td>Maximum Sequence Length</td></tr><tr><td>OLMo 7B-0724-hf</td><td>2e-6</td><td>0</td><td>0.03</td><td>256</td><td>3</td><td>4096</td></tr><tr><td>Pythia 12b</td><td>2e-6</td><td>0</td><td>0.03</td><td>256</td><td>3</td><td>4096</td></tr><tr><td>Neo 7b</td><td>5e-6</td><td>0</td><td>0.05</td><td>512</td><td>2</td><td>4096</td></tr></table>\",\n",
       "  \"<h1 id='106' style='font-size:18px'>E. Performances across different ratios</h1>\",\n",
       "  \"<p id='107' data-category='paragraph' style='font-size:16px'>Table 5: The results across various ratios. P-S, I-S, P-L, and I-L denote prompt-level strict accuracy, instance-level strict<br>accuracy, prompt-level loose accuracy, and instance-level loose accuracy, respectively.</p>\",\n",
       "  '<table id=\\'108\\' style=\\'font-size:14px\\'><tr><td rowspan=\"3\">Experiment Setting</td><td colspan=\"4\">Chat Benchmark</td><td colspan=\"7\">Standard Benchmark</td><td rowspan=\"3\">Average</td></tr><tr><td colspan=\"4\">IFEval</td><td colspan=\"3\">Exam</td><td colspan=\"2\">Coding</td><td colspan=\"2\">Reasoning</td></tr><tr><td>P-S</td><td>I-S</td><td>P-L</td><td>I-L</td><td>MMLU</td><td>ARC-c</td><td>GPQA-d</td><td>Human Eval</td><td>MBPP</td><td>hellaswag</td><td>gsm8k</td></tr><tr><td>OLMo-SFT</td><td>35.30</td><td>46.52</td><td>38.63</td><td>50.24</td><td>52.93</td><td>63.73</td><td>17.68</td><td>26.83</td><td>43.92</td><td>60.35</td><td>26.84</td><td>42.09</td></tr><tr><td>0.01</td><td>36.60</td><td>49.40</td><td>37.89</td><td>51.56</td><td>55.59</td><td>71.19</td><td>26.26</td><td>32.93</td><td>46.30</td><td>66.40</td><td>29.57</td><td>45.79</td></tr><tr><td>0.02</td><td>37.15</td><td>49.76</td><td>39.37</td><td>52.64</td><td>55.29</td><td>73.90</td><td>24.75</td><td>29.88</td><td>48.68</td><td>65.82</td><td>29.57</td><td>46.07</td></tr><tr><td>0.05</td><td>38.63</td><td>48.92</td><td>40.30</td><td>51.44</td><td>55.71</td><td>76.61</td><td>24.75</td><td>28.05</td><td>44.18</td><td>64.97</td><td>30.86</td><td>45.86</td></tr><tr><td>0.07</td><td>38.45</td><td>50.48</td><td>39.93</td><td>52.52</td><td>54.88</td><td>71.53</td><td>18.69</td><td>26.83</td><td>45.24</td><td>64.69</td><td>31.92</td><td>45.01</td></tr><tr><td>0.1</td><td>37.15</td><td>48.92</td><td>40.30</td><td>52.04</td><td>55.38</td><td>71.86</td><td>29.29</td><td>26.83</td><td>48.15</td><td>64.62</td><td>29.27</td><td>45.80</td></tr><tr><td>0.2</td><td>36.23</td><td>48.44</td><td>38.26</td><td>50.24</td><td>55.29</td><td>70.85</td><td>26.26</td><td>28.05</td><td>48.15</td><td>58.61</td><td>30.55</td><td>44.63</td></tr><tr><td>0.3</td><td>35.49</td><td>48.08</td><td>37.52</td><td>50.00</td><td>56.04</td><td>70.51</td><td>30.30</td><td>28.05</td><td>44.97</td><td>62.97</td><td>31.46</td><td>45.04</td></tr><tr><td>0.4</td><td>36.23</td><td>48.44</td><td>39.37</td><td>50.84</td><td>55.91</td><td>73.56</td><td>29.29</td><td>31.71</td><td>42.06</td><td>63.93</td><td>30.63</td><td>45.63</td></tr><tr><td>0.5</td><td>35.86</td><td>47.00</td><td>38.45</td><td>49.64</td><td>55.91</td><td>72.54</td><td>26.26</td><td>29.88</td><td>46.83</td><td>62.58</td><td>29.87</td><td>44.98</td></tr><tr><td>0.6</td><td>35.30</td><td>46.88</td><td>37.34</td><td>48.92</td><td>55.78</td><td>72.54</td><td>27.27</td><td>29.27</td><td>46.30</td><td>62.50</td><td>31.31</td><td>44.86</td></tr><tr><td>0.7</td><td>34.20</td><td>46.76</td><td>35.86</td><td>48.56</td><td>55.49</td><td>74.24</td><td>27.27</td><td>30.49</td><td>35.00</td><td>63.77</td><td>30.55</td><td>43.84</td></tr></table>',\n",
       "  \"<h1 id='109' style='font-size:22px'>F. Examples</h1>\",\n",
       "  \"<p id='110' data-category='paragraph' style='font-size:16px'>Examples 1, 2, and 3 represent three dense regions in the pretraining corpus, corresponding to code, scientific literature, and<br>general text data, respectively. Example 4 represents the dense region of the SFT dataset. Examples 5, 6, and 7 correspond<br>to the three dense regions in the rewritten set. Example 8 indicates points where the SFT data density is higher than that of<br>the pretraining data. Examples 9 and 10 represent points where the pretraining data density exceeds that of the SFT data.<br>Example 10 is as shown in Example 2.</p>\",\n",
       "  \"<footer id='111' style='font-size:14px'>19</footer>\",\n",
       "  \"<header id='112' style='font-size:18px'>MAP</header>\",\n",
       "  '<figure id=\\'113\\'><img style=\\'font-size:14px\\' alt=\"Example 1 in the original pretraining corpus (density estimation)\\n\\'text \\' : \\'python\\n# 응load /Users/facai/Study /book_notes/preconfig.py\\n응matplotlib inline\\nimport matplotlib.pyplot as plt\\nimport seaborn as sns\\nsns · set (color_codes=True)\\n#sns . set (font=\\' SimHei , )\\nplt · rcParams [\\' axes.grid\\' ] = False\\n#from IPython.display import SVG\\ndef show_image (filename, figsize=None, res_dir=True) :\\nif figsize:\\nplt. figure (figsize=figsize)\\nif res_dir:\\nfilename = /res/ { } , format (filename)\\n,\\n·\\n·\\nplt · imshow (plt. imread (filename) )\\nChapter 7 Regularization for Deep Learning\\n==\\nthe best fitting model is a large model that has been regularized appropriately.\\n### 7.1 Parameter Norm Penalties\\n\\\\begin{equation}\\n\\\\tilde{J} (\\\\theta; X, y) = J(\\\\theta; X, y) + \\\\alpha \\\\Omega (\\\\theta)\\n\\\\end{equation}\\nwhere $\\\\Omega ( \\\\theta) $ is a paramter norm penalty.\\ntypically, penalizes **only the weights** of the affine transformation at each layer\\nand leaves the biases unregularized.\\n#### 7.1.1 $L^2$ Parameter Regularization\\n#### 7 .1.2 $L^1$ Regularization\\nThe sparsity property induced by $L^1$ regularization => feature selection\\n### 7.2 Norm Penalties as Constrained Optimization\\nconstrain $\\\\Omega (\\\\theta) $ to be less than some constant $k$:\\n\\\\begin{equation}\\n\\\\mathcal{L} (\\\\theta, \\\\alpha; X, y) = J (\\\\theta; X, y) + \\\\alpha (  Omega ( \\\\ theta) - k)\\n\\\\end{equation}\\nIn practice, column norm limitation is always implemented as an explicit constraint\\nwith reprojection.\\n### 7.3 Regularization and Under-Constrained Problems\\nregularized matrix is guarantedd to be invertible. \\'\" data-coord=\"top-left:(124,149); bottom-right:(1130,1409)\" /></figure>',\n",
       "  \"<footer id='114' style='font-size:18px'>20</footer>\",\n",
       "  \"<header id='0' style='font-size:18px'>MAP</header>\",\n",
       "  '<p id=\\'1\\' data-category=\\'paragraph\\' style=\\'font-size:14px\\'>Example 2 in the original pretraining corpus (density estimation)<br>\"text \" \" \\\\section { \\\\label {intro} Introduction}<br>:<br>The high-precision determination of the machine luminosity at<br>{ \\\\sc lep/slc} is an essential ingredient of the success of<br>precision tests of the electroweak interactions on top of the $Z$<br>resonance \\\\cite {review}<br>As well known, the Bhabha scattering process at small angle (of the<br>order of a few degrees) is the reference reaction used for luminosity<br>monitoring at { \\\\sc lep/slc}, owing to its large cross section (dominated by<br>$t$-channel photon exchange) and its substantial independence of<br>purely electroweak effects · Experimental efforts in the development of<br>efficient, dedicated luminometry detectors, as well as precision<br>calculations of the small-angle Bhabha (hereafter { \\\\sc sabh}) scattering cross<br>section both contribute to achieve a measurement of the , `$Z$ factories\\' ,<br>luminosity with a total relative error at the $0 · 1 1%$ level \\\\cite{review, exp, common } ·<br>On the experimental side, the present total uncertainty is smaller than<br>$0 · 1 1%$ \\\\cite{exp} , close to the $0 · 05$ level \\\\cite{ward} · As far as the theory<br>contribution to the luminosity measurement is concerned, the<br>estimate of the theoretical errors, used by the { \\\\sc lep} collaborations,<br>is summarized in table \\\\ref {sabs} \\\\cite { common} for centre of mass<br>energies around and above the $Z$ resonance.<br>\\\\begin {table} [ht]<br>\\\\caption [sabs] { \\\\label {sabs}<br>Theoretical error in { \\\\sc sabh} scattering according<br>to ref · \\\\cite{common } at typical { \\\\sc lep1} and { \\\\sc 1ep2}<br>energies. }<br>\\\\medskip<br>\\\\begin { center}<br>\\\\begin { tabular} { 11 I |c|c| } \\\\hline<br>Type of correction/ error & {\\\\sc lep1} ($\\\\%$) & {\\\\sc 1ep2} ($\\\\%$) \\\\  \\\\hline \\\\hline<br>missing photonic $⌀ (\\\\alpha ^ 2L) $ & $0 . 100 $ & $0 . 200$ \\\\\\\\<br>missing photonic $⌀ (\\\\alpha A 3L ^ 3) $ & $0 · 015 $ & $0 · 030$ \\\\\\\\<br>vacuum polarization & $0 · 040 $ & $0 · 100$ \\\\\\\\<br>light pairs & $0 . 030 $ & $0 · 050$ 11<br>$Z$-exchange & $0 · 015 $ & $0 · 000$ \\\\\\\\ \\\\hline<br>total & $0 110 $ & $0 · 250$ 11 \\\\hline<br>\\\\end{tabular}<br>\\\\end { center}<br>\\\\end {table}<br>Some comments on table \\\\ref {sabs} are in order. The components of the theoretical<br>error refer to the { \\\\sc sabh} scattering cross section, for any typical event<br>selection of { \\\\sc lep} experiments, as computed by the program { \\\\tt<br>BHLUMI v4 , 03} \\\\cite{bhl}<br>The largely dominating source of theoretical error<br>is due to the missing part of $⌀ (\\\\alpha ^2 L) $ subleading photonic corrections,<br>where $L = \\\\1n (-t/m^2) $ is the collinear logarithm in $t$-channel scattering.<br>Also the contribution of the missing part of the leading $⌀ (\\\\alpha ^ 3L^3) $<br>corrections is of photonic nature. The vacuum polarization entry<br>is the effect of the uncertainty in the hadronic contribution<br>to the running of $\\\\alpha_ { / rm QED}$, when considering the parameterization and<br>relative error estimate of ref · \\\\cite{oldvacuum} .<br>The next contribution is the uncertainty introduced by the corrections due<br>to the production of light pairs, chiefly $e^ + e -$ ones. The last<br>entry refers to the uncertainty associated to the treatment of the<br>$\\\\gamma$-$Z$ interference.<br>More details about the strategy adopted in order to estimate the various<br>sources of theoretical error can be found in ref · \\\\cite{ common} .<br>After the analysis of ref · \\\\cite{common}, important theoretical<br>developments took place. Additional work in the sector of two-loop<br>photonic corrections \\\\cite{pv, kr} led to the conclusion that the<br>perturbative contribution due to the uncontrolled part of $⌀ ( \\\\alpha ^2L) $<br>corrections does not exceed the $0 . 03\\\\%$ level.<br>\"<br>· .</p>',\n",
       "  \"<footer id='2' style='font-size:18px'>21</footer>\",\n",
       "  \"<header id='3' style='font-size:18px'>MAP</header>\",\n",
       "  '<figure id=\\'4\\'><img style=\\'font-size:16px\\' alt=\"Example 3 in the original pretraining corpus (density estimation)\\n\\'text \\' : \\' # A marble dropped from a bridge strikes the water in 5. 0 S .\\nwhat is the height of the bridge? (Answer in meters) Jun 6, 2018 . $\\\\ \\\\text {122. 5 m} $ .\\n#### Explanation:\\nUse equation of motion: ${ \\\\ \\\\text {S\\' = \\'ut \\' + 1/2\\'at} } {2}$\\nWhere$\\\\ \\\\text {S =}$ Displacement covered$\\\\\\\\text {u =}$ Initial velocity\\n$\\\\ \\\\text {a =}$ Acceleration (Its ${ \\\\\\\\text {9 8 m/s} } {2}$ due to Earths gravity)\\n$ \\\\ \\\\text {t =}$ Time taken to cover displacement $\\\\\\\\text {S}$\\nMarble is dropped. It means initial velocity ($\\\\\\\\text {u}$) of marble is $0$\\nTherefore the equation becomes ${\\\\\\\\text {S\\' = 1/2\\'at}} {2}$\\ncolor (white) (\\'S\\') = 1/2 \\' 9 · 8 m/s\\'^2 \\' (5 s) \\' ^2\\ncolor (white) (\\'S\\') = 122 · 5\\\\ \\\\ \\'m\\'\\nDisplacement covered by the marble when thrown from the bridge is\\nobviously height of the bridge.\" data-coord=\"top-left:(124,149); bottom-right:(1125,468)\" /></figure>',\n",
       "  '<figure id=\\'5\\'><img style=\\'font-size:14px\\' alt=\"Example 4 in the original SFT dataset (density estimation)\\n\\' query\\' : \\'Tweet : enjoyed watching Glee, it brought back some good memories of being\\nin musical theatre, and snowflake\\nSent iment : positive\\nTweet : @dandebuf i\\'m pretty sure he\\' S every main character we , ve ever written.\\nthat or @iamnotmatt\\nSent iment : positive\\nTweet : Still no iPhone update\\nSent iment : negative\\nTweet : @jimblum must have been quite a ride to loose 44 lbs\\nSent iment : \\'\\n\\' answer \\' \\'positive\\'\\n:\" data-coord=\"top-left:(120,561); bottom-right:(1128,951)\" /></figure>',\n",
       "  \"<p id='6' data-category='paragraph' style='font-size:20px'>Example 5 in the rewritten dataset (density estimation)</p>\",\n",
       "  '<p id=\\'7\\' data-category=\\'paragraph\\' style=\\'font-size:16px\\'>\" query \" : \"What is the effect of L1 regularization on the model parameters, and how<br>does it contribute to feature selection within a deep learning model?\"</p>',\n",
       "  '<p id=\\'8\\' data-category=\\'paragraph\\' style=\\'font-size:14px\\'>\" answer\" : \"L1 regularization, also known as Lasso regularization, adds a penalty to<br>the model based on the absolute value of the model , S coefficients. Mathematically,<br>this can be represented as an addition to the loss function:</p>',\n",
       "  \"<p id='9' data-category='paragraph' style='font-size:14px'>\\\\ \\\\ (J(\\\\ \\\\theta; X, y) +  \\\\alpha \\\\ \\\\sum_{i} | \\\\ \\\\theta_i | \\\\ ) , where \\\\ ( \\\\ \\\\theta_i\\\\ \\\\ )<br>are the model parameters and \\\\ (\\\\\\\\alpha \\\\ I ) is the regularization strength.</p>\",\n",
       "  \"<p id='10' data-category='paragraph' style='font-size:14px'>The key effect of L1 regularization is that it encourages the model to set some of the<br>less important feature coefficients to zero. This property is particularly useful for<br>feature selection because it effectively removes irrelevant or less important features<br>from the model, leading to a more interpretable and potentially more robust model .</p>\",\n",
       "  '<p id=\\'11\\' data-category=\\'paragraph\\' style=\\'font-size:16px\\'>By pruning out these unimportant features, L1 regularization helps in simplifying the<br>model, reducing overfitting, and improving computational efficiency, especially in<br>high-dimensional datasets where many features might be redundant or irrelevant ·<br>\"</p>',\n",
       "  \"<footer id='12' style='font-size:18px'>22</footer>\",\n",
       "  \"<header id='13' style='font-size:18px'>MAP</header>\",\n",
       "  \"<p id='14' data-category='paragraph' style='font-size:20px'>Example 6 in the rewritten dataset (density estimation)</p>\",\n",
       "  '<p id=\\'15\\' data-category=\\'paragraph\\' style=\\'font-size:14px\\'>\" query\" : \"What are the constituent elements of carbon dioxide and how many atoms of<br>each are present in a single molecule?, \"</p>',\n",
       "  '<p id=\\'16\\' data-category=\\'paragraph\\' style=\\'font-size:14px\\'>\" answer\" : \"The constituent elements of carbon dioxide are carbon and oxygen.<br>In a single molecule of carbon dioxide (CO2) , there is one atom of carbon<br>and two atoms of oxygen. \"</p>',\n",
       "  \"<p id='17' data-category='paragraph' style='font-size:20px'>Example 7 in the rewritten dataset (density estimation)</p>\",\n",
       "  '<p id=\\'18\\' data-category=\\'paragraph\\' style=\\'font-size:16px\\'>\"query\" : \"How is the signless Laplacian matrix of a graph G defined, and what is the<br>relationship between the signless Laplacian spectrum of G and the spectrum of the<br>line graph of G?\"</p>',\n",
       "  '<p id=\\'19\\' data-category=\\'paragraph\\' style=\\'font-size:14px\\'>\" answer \" : \"The signless Laplacian matrix of a graph \\\\ ( G / ) is defined as<br>\\\\ ( Q_G = D_G + A_G \\\\) , where \\\\ ( D_G \\\\) is the diagonal matrix of vertex degrees<br>and \\\\ ( A_G \\\\) is the adjacency matrix of the graph.</p>',\n",
       "  \"<p id='20' data-category='paragraph' style='font-size:16px'>The signless Laplacian spectrum of \\\\ ( G V is the multiset of eigenvalues of \\\\ ( Q_G \\\\ ) ·<br>The relationship between the signless Laplacian spectrum of \\\\ ( G V and<br>the spectrum of the line graph of \\\\ ( G \\\\) , denoted \\\\ ( \\\\mathcal {L}_G \\\\),<br>is given by the following:</p>\",\n",
       "  '<p id=\\'21\\' data-category=\\'paragraph\\' style=\\'font-size:14px\\'>for an \\\\ ( (n, m) \\\\) -graph \\\\ ( G \\\\) , the eigenvalues of the signless Laplacian matrix<br>and the line graph are related as \\\\ ( q_i (G) = 2 + \\\\lambda_i ( \\\\mathcal{L}_G) \\\\ )<br>for \\\\ ( i = 1, 2, \\\\ldots, k \\\\) , where \\\\ ( k = \\\\min\\\\ {m, n\\\\} ) and<br>\\\\ ( \\\\lambda_i ( \\\\mathcal{L} _G) い is the \\\\ ( i い -th largest eigenvalue of the line graph.<br>Moreover, if \\\\ ( m > n V , then \\\\ ( \\\\lambda_i (\\\\mathcal{L}_G) = -2 \\\\) for \\\\ ( m \\\\geq i<br>\\\\geq n+1 \\\\) , and if \\\\ ( n > m / ) , then \\\\ ( q_i = 0 \\\\) for \\\\ ( n \\\\geq i \\\\geq m+1 \\\\) \"</p>',\n",
       "  \"<h1 id='22' style='font-size:22px'>Example 8 in the original SFT dataset (density estimation)</h1>\",\n",
       "  '<p id=\\'23\\' data-category=\\'paragraph\\' style=\\'font-size:16px\\'>\"query\" : \"Ques: Given this review : Great app . Fun and cool graphics.<br>Would you recommend this app to a friend? Not at all, No, Maybe, Yes, or Definitely?<br>Ans : Definitely</p>',\n",
       "  \"<p id='24' data-category='paragraph' style='font-size:14px'>Ques : Given this review: In Zenfone 2 ram 2gb intel processor not very well after<br>I upgrade to marshmallow . . i dont know why · · very very lag · · before in lollipop version<br>this psp game works really well . . i use default settings no problem. .<br>Would you recommend this app to a friend? Not at all, No, Maybe, Yes, or Definitely?<br>Ans : No</p>\",\n",
       "  \"<p id='25' data-category='paragraph' style='font-size:14px'>Ques : Given this review: Did not work at all To much errors<br>Would you recommend this app to a friend? Not at all, No, Maybe, Yes, or Definitely?<br>Ans : Not at all</p>\",\n",
       "  '<p id=\\'26\\' data-category=\\'paragraph\\' style=\\'font-size:14px\\'>Ques : Given this review: I like this app Open anyyy apps & anyone like this app<br>Would you recommend this app to a friend? Not at all, No, Maybe, Yes, or Definitely?<br>Ans : \"</p>',\n",
       "  '<p id=\\'27\\' data-category=\\'paragraph\\' style=\\'font-size:14px\\'>\" answer \" \"Definitely\"<br>:</p>',\n",
       "  \"<footer id='28' style='font-size:18px'>23</footer>\",\n",
       "  \"<header id='29' style='font-size:16px'>MAP</header>\",\n",
       "  '<figure id=\\'30\\'><img style=\\'font-size:14px\\' alt=\"Example 9 in the original pretraining corpus (density estimation)\\n\\'text \\' : \\' # If the length of a 46 cm spring increases to 57 cm when a 8 kg\\nweight is hanging from it , what is the spring\\\\ , constant ?\\nS\\n$ I \\\\ text { 713 N/m}$\\\\n$F = k  \\\\Delta x$ \\\\nk = F / (Deltax) = (mg) / (Deltax) =\\n( \\'8 kg 9 8 m/ S \\' 2) / ( \\' 0 57 m - 0 · 46 m ) = \\' 713 N/m\\' \\'\" data-coord=\"top-left:(116,134); bottom-right:(1131,307)\" /></figure>',\n",
       "  \"<footer id='31' style='font-size:20px'>24</footer>\",\n",
       "  \"<h1 id='0' style='font-size:22px'>Aligning Instruction Tuning with Pre-training</h1>\",\n",
       "  \"<table id='1' style='font-size:18px'><tr><td>Yiming Liang * 123</td><td>* 45 Tianyu Zheng</td><td>*45 Xinrun Du</td><td>*4 Ge Zhang</td></tr><tr><td>Jiaheng Liu 4 Xingwei Qu 4</td><td>Wenqiang Zu 12</td><td>Xingrun Xing 12</td><td>Chujie Zheng 5 Lei Ma 36</td></tr><tr><td>Wenhu Chen 4 Guoyin Wang 5</td><td>Zhaoxiang Zhang 2</td><td>Wenhao Huang 4</td><td>Xiang Yue 4 Jiajun Zhang 12</td></tr></table>\",\n",
       "  \"<p id='2' data-category='paragraph' style='font-size:20px'>Abstract</p>\",\n",
       "  \"<br><p id='3' data-category='paragraph' style='font-size:18px'>Instruction tuning enhances large language mod-<br>els (LLMs) to follow human instructions across<br>diverse tasks, relying on high-quality datasets to<br>guide behavior. However, these datasets, whether<br>manually curated or synthetically generated, are<br>often narrowly focused and misaligned with the<br>broad distributions captured during pre-training,<br>limiting LLM generalization and effective use<br>of pre-trained knowledge. We propose Aligning<br>Instruction Tuning with Pre-training (AITP), a<br>method that bridges this gap by identifying COV-<br>erage shortfalls in instruction-tuning datasets and<br>rewriting underrepresented pre-training data into<br>high-quality instruction-response pairs. This ap-<br>proach enriches dataset diversity while preserving<br>task-specific objectives. Evaluations on three fully<br>open LLMs across eight benchmarks demonstrate<br>consistent performance improvements with AITP.<br>Ablations highlight the benefits of adaptive data<br>selection, controlled rewriting, and balanced inte-<br>gration, emphasizing the importance of aligning<br>instruction tuning with pre-training distributions<br>to unlock the full potential of LLMs.</p>\",\n",
       "  \"<p id='4' data-category='paragraph' style='font-size:20px'>1. Introduction</p>\",\n",
       "  \"<br><header id='5' style='font-size:14px'>2025<br>Jan<br>20<br>[cs.AI]<br>arXiv:2501.09368v3</header>\",\n",
       "  \"<p id='7' data-category='footnote' style='font-size:18px'>* 1School of Artificial Intelligence, Uni-<br>Equal contribution<br>versity of Chinese Academy of Sciences 2Institute of Automa-<br>tion, Chinese Academy of Sciences 3BAAI 4M-A-P 501.ai<br>'Peking University. Correspondence to: Jiaheng Liu <buaalji-<br>aheng @gmail.com>, wenhaohuang <rubio8741@gmail.com>,<br>JiaJun Zhang <jjzhang@nlpr.ia.ac.cn>.</p>\",\n",
       "  \"<p id='8' data-category='paragraph' style='font-size:18px'>Preprint. Work in Progress</p>\",\n",
       "  '<br><figure id=\\'9\\'><img style=\\'font-size:14px\\' alt=\"15\\n15\\n10 10-\\n2\\n5 2\\n5\\nComponent\\n0\\n0\\n-5 Component\\nPCA\\nPCA\\n-5\\n-10\\n-10\\n-15\\n-15\\n-20\\n-20 -10 0 10 20 -20 -15 -10 -5 0 5 10 15\\nPCA Component 1 PCA Component 1\" data-coord=\"top-left:(636,413); bottom-right:(1137,661)\" /></figure>',\n",
       "  \"<p id='10' data-category='paragraph' style='font-size:18px'>Figure 1: Visualization of Projections. The red regions<br>at the bottom represent the pre-training corpus, while the<br>light blue regions above represent the SFT datasets. Darker<br>areas indicate a higher concentration of data points, whereas<br>lighter areas represent sparser distributions. Additional pro-<br>jections are shown in Appendix A.</p>\",\n",
       "  \"<p id='11' data-category='paragraph' style='font-size:18px'>on the other hand, frequently depend on expensive APIs<br>of strong models and are tightly coupled with their gener-<br>ation pipelines, limiting flexibility (Peng et al., 2023; Lian<br>et al., 2023). Additionally, manually combining open-source<br>datasets, as seen in efforts like OpenHermes-2.5 (Teknium,<br>2023) and Tulu- V2 (Ivison et al., 2023), often overlooks the<br>underlying data distributions, leading to inefficiencies.</p>\",\n",
       "  \"<p id='12' data-category='paragraph' style='font-size:18px'>Pre-training corpora, by contrast, reflect broader real-world<br>distributions and align closely with the internal knowledge<br>of LLMs, making them a rich source of high-quality super-<br>visory signals. However, current instruction-tuning methods<br>fail to leverage this alignment, creating a fundamental gap<br>in optimizing dataset coverage and distribution. Addressing<br>this challenge requires aligning instruction-tuning datasets<br>with pre-training distributions to fully exploit the knowledge<br>embedded in LLMs.</p>\",\n",
       "  \"<p id='13' data-category='paragraph' style='font-size:18px'>In this paper, we propose Aligning Instruction Tuning with<br>Pre-training (AITP), a method that systematically bridges<br>this gap. Rather than generating instruction-response pairs<br>from scratch, AITP identifies gaps in existing datasets by<br>comparing their distribution to that of the pre-training cor-<br>pus. Underrepresented data is then rewritten into high-<br>quality instruction-response pairs, enhancing dataset cover-<br>age and alignment. As shown in Figure 2, AITP involves</p>\",\n",
       "  \"<footer id='14' style='font-size:16px'>1</footer>\",\n",
       "  \"<header id='15' style='font-size:16px'>MAP</header>\",\n",
       "  '<figure id=\\'16\\'><img style=\\'font-size:14px\\' alt=\"Raw Text\\nText: # Confidence Interval calculation for\\nPower Density Estimation in MATLAB\\n,\\nAnd\\nFirst of all, I am new to these statistics stuff but\\n♥ background. I try to......\\nvery interested in the\\nPretraining Corpus Original SFT Dataset Difference Set Rewriting\\nInstruction Data\\nQ: Why does MATLAB\\'s pwelch function use 2k\\ndegrees of freedom for confidence intervals in\\npower spectral density estimation, and what is\\nSupervised + the reasoning behind this choice?\\nA: In the calculation of confidence intervals for\\npower spectral density (PSD) estimation using\\nFine-Tuning Welch\\'s method, MATLAB\\'s pwelch function\\nuses 2k degrees of freedom instead of k-1 or 2k-\\nCombined Set Original SFT Dataset Rewritten Set 1. This choice is based on\" data-coord=\"top-left:(110,131); bottom-right:(1134,389)\" /></figure>',\n",
       "  \"<p id='17' data-category='paragraph' style='font-size:16px'>Figure 2: The pipeline of AITP. AITP first generates a difference set, then rewrites the raw text into instruction-response<br>pairs to form a rewritten set, and finally combines the rewritten set with the original SFT dataset for model training.</p>\",\n",
       "  \"<p id='18' data-category='paragraph' style='font-size:16px'>three stages: (1) generating a difference set based on density<br>comparisons, (2) rewriting raw text into instruction-response<br>pairs, and (3) integrating these pairs into the original dataset<br>for fine-tuning.</p>\",\n",
       "  \"<p id='19' data-category='paragraph' style='font-size:16px'>Figure 1 visualizes the significant distributional differences<br>between instruction-tuning datasets and the pre-training cor-<br>pus, underscoring the need for such alignment. Through<br>experiments on three open-source LLMs across eight bench-<br>marks, we demonstrate that AITP consistently improves<br>model performance. Detailed ablation studies highlight<br>the effectiveness of adaptive data selection and integration,<br>showing how AITP guides instruction tuning toward more<br>effective and generalizable fine-tuned models.</p>\",\n",
       "  \"<p id='20' data-category='paragraph' style='font-size:16px'>Our contributions include: 1) Demonstrating the distribu-<br>tional gaps between instruction-tuning datasets and pre-<br>training corpora through visualization. 2) Proposing the<br>AITP method to adaptively optimize instruction-tuning<br>datasets by leveraging pre-training corpora as a reference.<br>3) Validating the effectiveness of AITP with extensive ex-<br>periments and ablation studies.</p>\",\n",
       "  \"<h1 id='21' style='font-size:20px'>2. Methods</h1>\",\n",
       "  \"<br><p id='22' data-category='paragraph' style='font-size:16px'>2.1. Difference Set Generation</p>\",\n",
       "  \"<p id='23' data-category='paragraph' style='font-size:16px'>In this section, we define the process of difference set gener-<br>ation, isolating data points from the pre-training corpora that<br>differ from those in the SFT dataset. The goal is to identify<br>regions in the pre-training data distribution that are absent<br>from or sparsely populated in the supervised fine-tuning<br>(SFT) data. This can be formalized as follows:</p>\",\n",
       "  \"<p id='24' data-category='equation'>$$D_{\\\\mathrm{diff}}=\\\\{d_{i}|d_{i}\\\\in D_{\\\\mathrm{pretrin}},\\\\Delta(d_{i},D_{\\\\mathrm{SFT}})<\\\\tau\\\\}\\\\qquad(1)$$</p>\",\n",
       "  \"<br><p id='25' data-category='paragraph' style='font-size:16px'>DSFT, Ddiff represent the pre-training<br>Where Dpretrain,<br>dataset, the SFT dataset and the resulting difference set,<br>respectively. △(di, DSFT) represents the density estimate of<br>the data point di in the SFT dataset, and T is the threshold<br>that determines whether a data point should be included in<br>the difference set. To achieve this, we outline the procedure</p>\",\n",
       "  \"<br><p id='26' data-category='paragraph' style='font-size:16px'>in three main stages: data representation, density estimation,<br>and identification of the difference set.</p>\",\n",
       "  \"<p id='27' data-category='paragraph' style='font-size:16px'>2.1.1. DATA REPRESENTATION</p>\",\n",
       "  \"<p id='28' data-category='paragraph' style='font-size:16px'>Each data point is represented as a vector derived from the<br>final-layer embedding of the model. We then apply dimen-<br>sionality reduction (DR) to project these high-dimensional<br>embeddings into two-dimensional coordinates, facilitating<br>visualization and density comparison across datasets. This<br>process can be formalized as follows:</p>\",\n",
       "  \"<p id='29' data-category='equation'>$$(x_{i},y_{i})=\\\\mathrm{DR}(\\\\mathrm{Model}(d_{i}))$$</p>\",\n",
       "  \"<p id='30' data-category='paragraph' style='font-size:14px'>Applying the same dimension reduction to both pre-training<br>and SFT embeddings results in two sets of two-dimensional<br>vectors:</p>\",\n",
       "  \"<br><caption id='31' style='font-size:22px'>(2)</caption>\",\n",
       "  \"<p id='32' data-category='equation'>$$\\\\begin{array}{l}{{Z_{\\\\mathrm{pretrain}}=\\\\{(x_{i},y_{i})\\\\mid d_{i}\\\\in D_{\\\\mathrm{pretrain}}\\\\}}}\\\\\\\\ {{Z_{\\\\mathrm{SFT}}=\\\\{(x_{i},y_{i})\\\\mid d_{i}\\\\in D_{\\\\mathrm{SFT}}\\\\}}}\\\\end{array}$$</p>\",\n",
       "  \"<p id='33' data-category='paragraph' style='font-size:16px'>2.1.2. DENSITY ESTIMATION</p>\",\n",
       "  \"<br><caption id='34' style='font-size:20px'>(3)</caption>\",\n",
       "  \"<p id='35' data-category='paragraph' style='font-size:16px'>To compare data distributions between the pre-training and<br>SFT datasets, we use Kernel Density Estimation (KDE) to<br>visualize the density of points for each dataset. The KDE<br>function f(x, y) estimates the density at any location (x,y)<br>based on neighboring points:</p>\",\n",
       "  \"<br><caption id='36' style='font-size:20px'>(4)</caption>\",\n",
       "  \"<p id='37' data-category='equation'>$$\\\\hat{f}(x,y)=\\\\frac{1}{n h_{x}h_{y}}\\\\sum_{i=1}^{n}K\\\\left(\\\\frac{x-x_{i}}{h_{x}},\\\\frac{y-y_{i}}{h_{y}}\\\\right)$$</p>\",\n",
       "  \"<br><p id='38' data-category='paragraph' style='font-size:18px'>K(·,·) is the kernel function, typically Gaussian:</p>\",\n",
       "  \"<br><caption id='39' style='font-size:20px'>(5)</caption>\",\n",
       "  \"<p id='40' data-category='equation'>$$K((x,y),(x^{\\\\prime},y^{\\\\prime}))=\\\\exp\\\\left(-\\\\frac{(x-x^{\\\\prime})^{2}+(y-y^{\\\\prime})^{2}}{2\\\\sigma^{2}}\\\\right)~(6)$$</p>\",\n",
       "  \"<p id='41' data-category='paragraph' style='font-size:16px'>Where (x, y) and (x1, y!) are two two-dimensional data<br>points, hx, hy and o are bandwidth parameters that con-<br>trol the smoothness in the x direction, y direction and kernel<br>respectively. The KDE visualization highlights distribution<br>differences, identifying regions of divergence between the<br>pretraining and SFT datasets.</p>\",\n",
       "  \"<footer id='42' style='font-size:16px'>2</footer>\",\n",
       "  \"<header id='43' style='font-size:16px'>MAP</header>\",\n",
       "  \"<p id='44' data-category='paragraph' style='font-size:16px'>2.1.3. FINDING DIFFERENCE SET</p>\",\n",
       "  \"<p id='45' data-category='paragraph' style='font-size:16px'>The difference set is identified based on the density estimates<br>from the SFT dataset. Specifically, if a point di in the<br>pre-training dataset has a low-density estimate within the<br>SFT dataset, we classify this point as absent or sparsely<br>populated in the SFT data. Such points contribute to the<br>observed distributional differences between the two datasets,<br>and we define them formally as:</p>\",\n",
       "  \"<p id='46' data-category='equation'>$$D_{\\\\mathrm{diff}}=\\\\{d_{i}|d_{i}\\\\in{\\\\cal D}_{\\\\mathrm{pretrain}},\\\\hat{f}_{\\\\mathrm{SFT}}(x_{i},y_{i})<\\\\tau\\\\}\\\\qquad(7)$$</p>\",\n",
       "  \"<br><p id='47' data-category='paragraph' style='font-size:16px'>fSFT (xi, yi) represents the density estimate of the data point<br>di from the pretrain corpus within the SFT dataset.</p>\",\n",
       "  \"<p id='48' data-category='equation'>$$\\\\hat{f}_{\\\\mathrm{SFT}}(x_{i},y_{i})=\\\\frac{1}{n h_{x}h_{y}}\\\\sum_{j=1}^{n}K\\\\left(\\\\frac{x_{i}-x_{j}}{h_{x}},\\\\frac{y_{i}-y_{j}}{h_{y}}\\\\right)$$</p>\",\n",
       "  \"<p id='49' data-category='paragraph' style='font-size:16px'>Where (xi, yi) E Zpretrain, (xj,yj) E ZSFT. n is the total<br>number of points in the SFT dataset.</p>\",\n",
       "  \"<h1 id='50' style='font-size:16px'>2.2. Data Transformation of Difference Set</h1>\",\n",
       "  \"<p id='51' data-category='paragraph' style='font-size:16px'>The data transformation phase is designed to convert raw<br>text from the pre-training data within the difference set<br>into instruction-pair data formatted for SFT. This process<br>consists of three key steps. First, we develop a query gen-<br>eration prompt to guide the model in generating relevant<br>questions from the raw text. Next, we implement a query<br>scoring prompt to assess the quality of each generated<br>query. Low-quality queries are filtered out based on these<br>scores, enabling us to eliminate unsuitable questions before<br>answer generation, thus conserving computational resources.<br>Finally, an answer generation prompt is applied to in-<br>struct the model in generating responses to the remaining<br>high-quality queries. These three processes can be formally<br>modeled as follows:</p>\",\n",
       "  \"<p id='52' data-category='equation'>$${\\\\dot{y}}_{t}^{l}={\\\\underset{\\\\mathrm{arg\\\\,max}}{\\\\operatorname{arg\\\\,max}P}}{\\\\bigl(}y_{t}\\\\mid p_{\\\\mathrm{generate}},t,y_{<t};\\\\theta{\\\\bigr)}$$</p>\",\n",
       "  \"<p id='53' data-category='equation'>$$\\\\dot{y}_{t}^{s}\\\\,=\\\\,\\\\arg\\\\operatorname*{max}_{s\\\\,t}P(y_{t}\\\\,\\\\mid p_{\\\\mathrm{score}},\\\\,i,y_{<t};\\\\theta)$$</p>\",\n",
       "  \"<br><p id='54' data-category='paragraph' style='font-size:14px'>Yt</p>\",\n",
       "  \"<br><p id='55' data-category='equation'>$$\\\\hat{y}_{t}^{a}\\\\,=\\\\,{\\\\bf a r g.}\\\\ln_{u_{t}}{\\\\bf u}.{\\\\bf0}\\\\hat{x}\\\\,P(y_{t}\\\\,\\\\mid p_{\\\\mathrm{answer}},\\\\dot{t},y_{<t};\\\\theta)$$</p>\",\n",
       "  \"<p id='56' data-category='paragraph' style='font-size:16px'>where Pgenerate, Pscore, and Panswer represent the prompts used<br>for query generation, query scoring, and answer generation,<br>respectively. Here, t denotes the raw text, 2 represents the<br>instruction, and 0 denotes the model parameters. The yi, Yt,<br>and yt represent the most probable tokens generated at time<br>step t for the instruction, score, and answer, respectively.<br>The detailed prompts utilized in this process can be found<br>in Appendix C.</p>\",\n",
       "  \"<h1 id='57' style='font-size:20px'>2.3. Training</h1>\",\n",
       "  \"<p id='58' data-category='paragraph' style='font-size:14px'>In this phase, the model is trained on a combined dataset that<br>includes both the rewritten data derived from the difference</p>\",\n",
       "  \"<br><p id='59' data-category='paragraph' style='font-size:16px'>set and the original SFT dataset. Notably, the model trained<br>on the combined dataset is the same as the one trained on the<br>pre-training corpus. This serves two main purposes: first, it<br>ensures consistency between the supplemented knowledge<br>distribution and the model's internal knowledge. Second,<br>high-quality instruction-pair data helps correct semantic<br>inaccuracies that may arise from formatting errors in the<br>pre-training corpus. The loss function for training is defined<br>as follows:</p>\",\n",
       "  \"<caption id='60' style='font-size:20px'>(12)</caption>\",\n",
       "  \"<br><p id='61' data-category='equation'>$${\\\\mathcal{L}}_{\\\\mathrm{avg}}=-{\\\\frac{1}{N}}\\\\sum_{t=1}^{N}\\\\log P(a_{t}\\\\mid i,a_{<t};\\\\theta)$$</p>\",\n",
       "  \"<p id='62' data-category='paragraph' style='font-size:20px'>(8)</p>\",\n",
       "  \"<br><p id='63' data-category='paragraph' style='font-size:16px'>where N denotes the sequence length, i and a denote the<br>instruction and response sequence, respectively.</p>\",\n",
       "  \"<p id='64' data-category='paragraph' style='font-size:22px'>3. Experiment Settings</p>\",\n",
       "  \"<br><p id='65' data-category='paragraph' style='font-size:16px'>3.1. Evaluation</p>\",\n",
       "  \"<caption id='66' style='font-size:20px'>(9)</caption>\",\n",
       "  \"<caption id='67' style='font-size:18px'>(10)</caption>\",\n",
       "  \"<br><caption id='68' style='font-size:20px'>(11)</caption>\",\n",
       "  \"<br><p id='69' data-category='paragraph' style='font-size:16px'>We evaluate the model's instruction-following ability using<br>the IFEval benchmark (Zhou et al., 2023b), which is unbi-<br>ased because it does not rely on LLM-generated evaluation<br>scores. It provides four types of accuracy scores: Prompt-<br>level Strict-accuracy (P-S), Instruction-level Strict-accuracy<br>(I-S), Prompt-level Loose-accuracy (P-L), and Instruction-<br>level Loose-accuracy (I-L). We use the OpenCompass, a<br>comprehensive, one-stop platform for LLM evaluation (Con-<br>tributors, 2023). We evaluate the effectiveness of AITP<br>across seven standard benchmarks. These benchmarks pro-<br>vide a comprehensive evaluation of the diverse capabili-<br>ties of language models across various tasks and domains.<br>MMLU (Hendrycks et al., 2021) offers a broad assessment<br>of multitask reasoning and knowledge retrieval, while ARC-<br>c (Clark et al., 2018) and GPQA-diamond (Rein et al.,<br>2023) focus on complex scientific reasoning and physics-<br>specific understanding, respectively. For code generation<br>and problem-solving, HumanEval (Chen et al., 2021) and<br>MBPP (Austin et al., 2021) measure a models ability to<br>write correct and multi-step logical solutions. Addition-<br>ally, HellaSwag (Zellers et al., 2019) tests commonsense<br>reasoning by predicting contextually appropriate continua-<br>tions, and GSM8K (Cobbe et al., 2021) challenges models<br>with elementary-level math problems, combining natural<br>language understanding with mathematical reasoning.</p>\",\n",
       "  \"<p id='70' data-category='paragraph' style='font-size:18px'>3.2. Main Setting</p>\",\n",
       "  \"<p id='71' data-category='paragraph' style='font-size:16px'>Our experiments utilize three fully open-source models:<br>OLMo (Groeneveld et al., 2024), MAP-Neo (Zhang et al.,<br>2024a) and Pythia (Biderman et al., 2023). These models<br>not only release model weights but also training datasets and<br>intermediate checkpoints, aiming to facilitate reproduction<br>and advance scientific research in LLMs. In this paper,<br>the OLMo-7B-base, MAP-Neo-7B-base, and Pythia-12B</p>\",\n",
       "  \"<footer id='72' style='font-size:16px'>3</footer>\",\n",
       "  \"<header id='73' style='font-size:14px'>MAP</header>\",\n",
       "  \"<p id='74' data-category='paragraph' style='font-size:14px'>models, along with their corresponding pre-training corpora,<br>are chosen as the foundational setup for AITP. The OLMo-<br>7B-SFT and MAP-Neo-7B-SFT-v0.1 models are used as<br>baselines to validate the effectiveness of AITP. Since the<br>SFT dataset for Pythia has not been released, we use Tulu-v2<br>for fine-tuning as the baseline for Pythia.</p>\",\n",
       "  \"<p id='75' data-category='paragraph' style='font-size:16px'>Due to the substantial storage and computational resources<br>required for the data embedding and shift phase, we don't<br>use the full pre-training corpus given resource constraints.<br>Instead, we apply reservoir sampling (Vitter, 1985), an algo-<br>rithm that enables uniform sampling from streaming data,<br>ensuring that the sampled subset maintains a distribution<br>consistent with the full pre-training corpus. The reservoir<br>sampling algorithm is described in the Appendix B.</p>\",\n",
       "  \"<br><p id='76' data-category='paragraph' style='font-size:16px'>We conduct experiments on the NVIDIA A800-SXM4-<br>80GB, with the difference set generation phase taking ap-<br>proximately 56 GPU hours. The Data Transformation Set-<br>ting phase utilizes the vLLM (Kwon et al., 2023) frame-<br>work to accelerate inference, requiring approximately 640<br>GPU hours, while the Training Setting phase, involving<br>full-parameter fine-tuning, takes approximately 256 GPU<br>hours.</p>\",\n",
       "  \"<h1 id='77' style='font-size:18px'>3.3. Difference Set Generation Setting</h1>\",\n",
       "  \"<p id='78' data-category='paragraph' style='font-size:16px'>We obtain the text embeddings using two encoding mod-<br>els: BAAI/bge-m3 (Chen et al., 2024) and sentence-<br>transformers/all-MiniLM-L6-v2 (Reimers & Gurevych,<br>2019). We choose the all-MiniLM-L6-v2 model for its<br>simplicity and ease of use, while bge-m3 can handle multi-<br>lingual input and varying input lengths, from short sentences<br>to long documents up to 8192 tokens. For the pre-training<br>corpus, we directly use the text field as input for encoding.<br>For the SFT dataset, we concatenate the instruction and<br>response fields to form a complete input text for encoding.<br>After obtaining the text embeddings, we apply principal<br>component analysis (PCA) to reduce the high-dimensional<br>data to two dimensions, thus simplifying the visualization<br>and analysis. For visualization, we employ kernel density<br>estimation (KDE), which effectively represents data density<br>by smoothing distributions and avoids the issue of point<br>overlap in dense regions that can occur in scatter plots.</p>\",\n",
       "  \"<p id='79' data-category='paragraph' style='font-size:16px'>To identify the difference set, we use two settings: density<br>estimation and density comparison. The density estimation<br>setting is presented in Equation 7 and Equation 8. In this<br>paper, the density comparison setting compares the den-<br>sity estimation of each data point in the pre-training and<br>SFT datasets, selecting difference points based on their den-<br>sity ratio. The density comparison setting is formalized as<br>follows:</p>\",\n",
       "  \"<p id='80' data-category='equation'>$$\\\\hat{f}_{\\\\mathrm{Pre}}(x_{i},y_{i})=\\\\frac{1}{m h_{x}h_{y}}\\\\sum_{k=1,k\\\\neq i}^{m}K\\\\left(\\\\frac{x_{i}-x_{k}}{h_{x}},\\\\frac{y_{i}-y_{k}}{h_{y}}\\\\right)\\\\quad(13$$</p>\",\n",
       "  \"<br><p id='81' data-category='equation'>$$D_{\\\\mathrm{dif}}=\\\\{d_{i}|d_{i}\\\\in D_{\\\\mathrm{pretrain}},\\\\frac{\\\\hat{f}_{\\\\mathrm{pre}}(x_{i},y_{i})}{\\\\hat{f}_{\\\\mathrm{SFT}}(x_{i},y_{i})}>\\\\tau\\\\}$$</p>\",\n",
       "  \"<br><caption id='82' style='font-size:22px'>(14)</caption>\",\n",
       "  \"<p id='83' data-category='paragraph' style='font-size:14px'>Where (xi, Yi), (Xk, Yk) E Zpretrain. m is the total number<br>of points in the pre-training dataset. In this paper, we set T<br>to 0.7 and 1.0 for equations (7) and (14), respectively.</p>\",\n",
       "  \"<p id='84' data-category='paragraph' style='font-size:16px'>3.4. Data Transformation Setting</p>\",\n",
       "  \"<p id='85' data-category='paragraph' style='font-size:14px'>We employ the Qwen2.5-72B-Instruct (Team, 2024) model<br>for data transformation. In the instruction generation phase,<br>we ensure that generated instructions are contextually rel-<br>evant and self-contained, meaning they should not require<br>the raw text as background for understanding. During the<br>instruction scoring phase, each instruction is assessed based<br>on three criteria: quality, difficulty, and the additional infor-<br>mation required. We rate the quality of each instruction on a<br>scale from 1 to 10 based on its clarity, assess its difficulty de-<br>pending on whether specialized knowledge is required, and<br>mark the additional information required field true or false,<br>based on whether extra information is needed to fully an-<br>swer the query. In the answer generation phase, the model is<br>prompted to produce comprehensive and accurate responses<br>informed by both the instruction and text content, ensuring<br>that the responses are detailed and well-aligned with the<br>question context.</p>\",\n",
       "  \"<p id='86' data-category='paragraph' style='font-size:18px'>3.5. Ablation Setting</p>\",\n",
       "  \"<p id='87' data-category='paragraph' style='font-size:14px'>We conduct two ablation studies to evaluate the impact of<br>dataset size and distillation during the data transformation<br>process on AITP. To determine whether the improvement<br>arises from the increased size of the SFT dataset after adding<br>the rewritten difference set, we sample a subset from the<br>combined dataset (original SFT and rewritten difference<br>set) that is equal in size to the original SFT dataset and<br>use it for training. To test whether the improvement is due<br>to distillation in the data transformation phase, we replace<br>the original SFT dataset with a subset sampled from the<br>pre-training corpus that shares a similar distribution and<br>train the model on the combined dataset (the rewritten same<br>set and the rewritten difference set). This setup aligns with<br>the approach used in LongForm (Kksal et al., 2023), which<br>trains models on fully rewritten pre-training datasets but<br>overlooks leveraging existing high-quality datasets.</p>\",\n",
       "  \"<p id='88' data-category='paragraph' style='font-size:20px'>3.6. Training Setting</p>\",\n",
       "  \"<p id='89' data-category='paragraph' style='font-size:14px'>We use combined datasets in AITP to train three open-source<br>models: OLMo, MAP-Neo, and Pythia. The rewritten differ-<br>ence set in the combined datasets is obtained by subtracting<br>the corresponding SFT datasets (TuluV2, Neo-SFT, Tulu V2)<br>from the respective pre-training corpora (Dolma, Matrix,<br>and Pile). Since the SFT dataset for Pythia has not been<br>released, we use TuluV2 as a substitute. Full-parameter</p>\",\n",
       "  \"<footer id='90' style='font-size:14px'>4</footer>\",\n",
       "  \"<header id='91' style='font-size:20px'>MAP</header>\",\n",
       "  '<figure id=\\'92\\'><img style=\\'font-size:16px\\' alt=\"15 15 15 15\\nDense region\\nDense region in pre-training\\nin difference set\\ncorpus: example ①② ③\\n10 10\\n10 10\\n 17\\n2\\n2 5\\n5 2\\n5 2\\n5\\nComponent\\n0\\n0 0 0\\n-5 Component\\n-5 Component\\n-5 Component\\n-5\\nPCA\\nPCA\\nPCA\\n-10 PCA\\n-10 -10 -10\\n-15\\n-15 Dense region in SFT dataset: Empty region -15 -15 Dense region Expanded region\\nexample ④ in difference set Dense region in rewritten set: in combined set\\nin combined set\\n-20 -20 example ⑤⑥⑦\\n-20\\n-20\\n-20 -10 0 10 20 -20 -10 0 10 20 -20 -10 0 10 20 -20 -10 0 10 20\\nPCA Component 1 PCA Component 1 PCA Component 1 PCA Component 1\" data-coord=\"top-left:(119,127); bottom-right:(1113,388)\" /></figure>',\n",
       "  \"<br><p id='93' data-category='paragraph' style='font-size:20px'>(a) Original dataset TuluV2</p>\",\n",
       "  \"<br><p id='94' data-category='paragraph' style='font-size:18px'>(b) The difference set</p>\",\n",
       "  '<figure id=\\'95\\' data-category=\\'chart\\'><img style=\\'font-size:14px\\' alt=\"15 \\nSFT dataset > Pretraining \\ncorpus in density \\n10 \\n2 \\n5 2 \\nComponent \\n0 \\n-5 Component \\nPCA \\nPCA \\n-10 \\n-15 > SFT \\nPretraining corpus \\ndataset in density \\n-20 \\n-20 -10 0 10 20 \\nPCA Component 1 \\n\" data-coord=\"top-left:(126,432); bottom-right:(391,675)\" /></figure>',\n",
       "  \"<br><p id='96' data-category='paragraph' style='font-size:18px'>(c) The rewritten set</p>\",\n",
       "  '<figure id=\\'97\\' data-category=\\'chart\\'><img style=\\'font-size:14px\\' alt=\"15 \\n10 \\n5 2 \\n0 \\n-5 Component \\nPCA \\n-10 \\n-15 Denser region \\nin difference set \\n-20 \\n-20 -10 0 10 20 \\nPCA Component 1 \\n\" data-coord=\"top-left:(383,430); bottom-right:(634,677)\" /></figure>',\n",
       "  '<br><figure id=\\'98\\'><img style=\\'font-size:14px\\' alt=\"15\\n10\\n5 2\\n0\\n-5 Component\\nPCA\\n-10\\n-15 Dense region\\nin rewritten set\\n-20\\n-20 -10 0 10 20\\nPCA Component 1\" data-coord=\"top-left:(627,431); bottom-right:(888,675)\" /></figure>',\n",
       "  \"<br><p id='99' data-category='paragraph' style='font-size:18px'>(d) The combined set</p>\",\n",
       "  \"<p id='100' data-category='paragraph' style='font-size:20px'>(e) Original dataset TuluV2</p>\",\n",
       "  \"<br><p id='101' data-category='paragraph' style='font-size:18px'>(f) The difference set (g) The rewritten set (h) The combined set</p>\",\n",
       "  '<br><figure id=\\'102\\' data-category=\\'chart\\'><img style=\\'font-size:16px\\' alt=\"15 \\n10 \\n5 \\n0 \\n-5 \\n-10 \\n-15 Dense region Expanded region \\nin combined set in combined set \\n-20 \\n-20 -10 0 10 20 \\nPCA Component 1 \\n\" data-coord=\"top-left:(875,430); bottom-right:(1121,676)\" /></figure>',\n",
       "  \"<caption id='103' style='font-size:20px'>Figure 3: Data Distribution Changes in AITP. Subfigures (a)-(d) and (e)-(h) illustrate the distribution changes of the<br>datasets under density estimation and the density comparison settings. The red region at the bottom represents the pre-<br>training corpus, Dolma, while the blue regions in the subfigures represent the projections of Tulu V2, the difference set, the<br>rewritten set, and the combined set, respectively. Darker areas indicate a higher concentration of data points, whereas lighter<br>areas signify sparser distributions. The examples in the subfigures can be found in Appendix F.</caption>\",\n",
       "  \"<p id='104' data-category='paragraph' style='font-size:20px'>fine-tuning is applied, with the detailed training parameters<br>provided in Appendix D.</p>\",\n",
       "  \"<p id='105' data-category='paragraph' style='font-size:22px'>4. Results</p>\",\n",
       "  \"<h1 id='106' style='font-size:22px'>4.1. Distribution Change Analysis</h1>\",\n",
       "  \"<p id='107' data-category='paragraph' style='font-size:20px'>In the density estimation setting, AITP focuses on the dense<br>regions of the SFT dataset and the pre-training corpus to<br>identify points in the pre-training corpus that are underrep-<br>resented in the SFT dataset. Figure 3a highlights the dense<br>regions of Tulu and Dolma (examples are provided in Ap-<br>pendix F). Dense regions 1 and 2 correspond to code and<br>scientific literature data, respectively. Figure 3b demon-<br>strates that the difference set avoids the dense regions in<br>the SFT dataset and aligns with dense regions of Dolma.<br>Figure 3c shows the narrowing of the distribution during<br>rewriting (examples are provided in Appendix F), while<br>Figure 3d indicates that the combined dataset expands the<br>original SFT distribution and highly overlaps with the dense<br>regions of the pre-training corpus. In the density compari-<br>son setting (Figure 3e-3h), AITP focuses on points where<br>the pre-training corpus has a higher density than the SFT<br>dataset. Similarly, AITP with the density comparison set-</p>\",\n",
       "  \"<br><p id='108' data-category='paragraph' style='font-size:20px'>ting can also expand the coverage of the existing dataset and<br>optimize the data distribution.</p>\",\n",
       "  \"<p id='109' data-category='paragraph' style='font-size:20px'>4.2. Main Results</p>\",\n",
       "  \"<p id='110' data-category='paragraph' style='font-size:20px'>As shown in Table 1, compared to the SFT model of OLMo,<br>MAP-Neo, and Pythia baselines, the counterparts trained<br>with AITP achieve average performance improvements<br>of 3.8, 1.1 and 0.9 across eight benchmarks. This illustrates<br>the effectiveness of AITP. We suppose that this improve-<br>ment results from AITP supplementing the original SFT<br>dataset with lacking data, expanding its coverage, and<br>optimizing its distribution.</p>\",\n",
       "  \"<p id='111' data-category='paragraph' style='font-size:20px'>Based on the analysis in subsection 4.1, we can summarize<br>two points supporting the above supposition: (1) A com-<br>parison of Figure 3a and 3b reveals that the difference set<br>includes data from the pre-training corpus that is lacking<br>in SFT datasets, such as code and scientific literature data.<br>(2) Although the distribution narrows during the rewriting<br>process (as shown in Figure 3b and 3c), the final combined<br>dataset expands the coverage of the original SFT dataset,<br>and the dense regions of the combined data align closely<br>those of the pre-training corpus (as shown in Figure 3d).</p>\",\n",
       "  \"<footer id='112' style='font-size:20px'>5</footer>\",\n",
       "  \"<header id='113' style='font-size:18px'>MAP</header>\",\n",
       "  \"<p id='114' data-category='paragraph' style='font-size:20px'>Table 1: Main Results: Experiment performance of different models across various benchmarks. △ represents the<br>change in performance when using AITP compared to the corresponding baseline. P-S, I-S, P-L, and I-L denote prompt-level<br>strict accuracy, instance-level strict accuracy, prompt-level loose accuracy, and instance-level loose accuracy, respectively.</p>\",\n",
       "  '<table id=\\'115\\' style=\\'font-size:16px\\'><tr><td rowspan=\"3\">Experiment Setting</td><td colspan=\"4\">Chat Benchmark</td><td colspan=\"7\">Standard Benchmark</td><td rowspan=\"3\">Average</td></tr><tr><td colspan=\"4\">IFEval</td><td colspan=\"3\">Exam</td><td colspan=\"2\">Coding</td><td colspan=\"2\">Reasoning</td></tr><tr><td>P-S</td><td>I-S</td><td>P-L</td><td>I-L</td><td>MMLU</td><td>ARC</td><td>GPQA</td><td>Human Eval</td><td>MBPP</td><td>Hella Swag</td><td>GSM 8K</td></tr><tr><td>OLMo-SFT</td><td>35.3</td><td>46.5</td><td>38.6</td><td>50.2</td><td>52.9</td><td>63.7</td><td>17.7</td><td>26.8</td><td>43.9</td><td>60.4</td><td>26.8</td><td>42.1</td></tr><tr><td>△ over OLMo</td><td>+3.3</td><td>+2.4</td><td>+1.7</td><td>+1.2</td><td>+2.8</td><td>+12.9</td><td>+7.1</td><td>+1.3</td><td>+0.3</td><td>+4.6</td><td>+4.1</td><td>+3.8</td></tr><tr><td>Neo-SFT</td><td>37.9</td><td>49.2</td><td>41.2</td><td>52.3</td><td>57.6</td><td>77.6</td><td>12.1</td><td>44.5</td><td>45.0</td><td>72.1</td><td>70.1</td><td>50.9</td></tr><tr><td>△ over Neo</td><td>+0.6</td><td>+0.8</td><td>+0.4</td><td>+1.1</td><td>+0.8</td><td>+3.4</td><td>+7.1</td><td>-6.1</td><td>+6.3</td><td>-3.9</td><td>+1.9</td><td>+1.1</td></tr><tr><td>Pythia-SFT</td><td>20.2</td><td>32.3</td><td>22.2</td><td>34.7</td><td>24.2</td><td>27.8</td><td>20.2</td><td>13.4</td><td>19.6</td><td>26.0</td><td>7.7</td><td>22.5</td></tr><tr><td>△ over Pythia</td><td>+1.8</td><td>+1.6</td><td>+2.4</td><td>+1.6</td><td>+1.0</td><td>-4.7</td><td>+4.6</td><td>+1.8</td><td>+0.2</td><td>+0.1</td><td>-0.1</td><td>+0.9</td></tr></table>',\n",
       "  \"<p id='116' data-category='paragraph' style='font-size:20px'>Table 2: The Results of Various Difference Set Generation setting. bge and MiniLM represent the embedding model, and<br>estimation and comparison represent the setting of choosing difference sets. P-S, I-S, P-L, and I-L denote prompt-level strict<br>accuracy, instance-level strict accuracy, prompt-level loose accuracy, and instance-level loose accuracy, respectively.</p>\",\n",
       "  '<table id=\\'117\\' style=\\'font-size:14px\\'><tr><td rowspan=\"3\">Experiment Setting</td><td colspan=\"4\">Chat Benchmark</td><td colspan=\"7\">Standard Benchmark</td><td rowspan=\"3\">Average</td></tr><tr><td colspan=\"4\">IFEval</td><td colspan=\"3\">Exam</td><td colspan=\"2\">Coding</td><td colspan=\"2\">Reasoning</td></tr><tr><td>P-S</td><td>I-S</td><td>P-L</td><td>I-L</td><td>MMLU</td><td>ARC</td><td>GPQA</td><td>Human Eval</td><td>MBPP</td><td>Hella Swag</td><td>GSM 8K</td></tr><tr><td>OLMo-SFT</td><td>35.3</td><td>46.5</td><td>38.6</td><td>50.2</td><td>52.9</td><td>63.7</td><td>17.7</td><td>26.8</td><td>43.9</td><td>60.4</td><td>26.8</td><td>42.1</td></tr><tr><td>bge-estimation (△)</td><td>+3.3</td><td>+2.4</td><td>+1.7</td><td>+1.2</td><td>+2.8</td><td>+12.9</td><td>+7.1</td><td>+1.3</td><td>+0.3</td><td>+4.6</td><td>+4.1</td><td>+3.8</td></tr><tr><td>bge-comparison (△)</td><td>+2.6</td><td>+2.5</td><td>+1.1</td><td>+1.1</td><td>+2.8</td><td>+10.5</td><td>+10.6</td><td>+4.9</td><td>+3.7</td><td>+2.9</td><td>+4.7</td><td>+4.3</td></tr><tr><td>MiniLM-estimation (△)</td><td>-0.7</td><td>+0.5</td><td>-2.0</td><td>-0.9</td><td>+2.6</td><td>+10.5</td><td>+9.1</td><td>+3.1</td><td>+2.7</td><td>+4.1</td><td>+3.5</td><td>+3.0</td></tr><tr><td>MiniLM-comparison (△)</td><td>+0.9</td><td>+1.0</td><td>-0.1</td><td>+0.2</td><td>+2.6</td><td>+10.9</td><td>+8.6</td><td>+1.9</td><td>+0.5</td><td>+3.1</td><td>+4.8</td><td>+3.1</td></tr></table>',\n",
       "  \"<p id='118' data-category='paragraph' style='font-size:18px'>Table 3: The Ablation Results on Data Size and Distillation. P-S, I-S, P-L, and I-L denote prompt-level strict accuracy,<br>instance-level strict accuracy, prompt-level loose accuracy, and instance-level loose accuracy, respectively.</p>\",\n",
       "  '<table id=\\'119\\' style=\\'font-size:16px\\'><tr><td rowspan=\"3\">Experiment Setting</td><td colspan=\"4\">Chat Benchmark</td><td colspan=\"7\">Standard Benchmark</td><td rowspan=\"3\">Average</td></tr><tr><td colspan=\"4\">IFEval</td><td colspan=\"3\">Exam</td><td colspan=\"2\">Coding</td><td colspan=\"2\">Reasoning</td></tr><tr><td>P-S</td><td>I-S</td><td>P-L</td><td>I-L</td><td>MMLU</td><td>ARC</td><td>GPQA</td><td>Human Eval</td><td>MBPP</td><td>Hella Swag</td><td>GSM 8K</td></tr><tr><td>OLMo-SFT</td><td>35.3</td><td>46.5</td><td>38.6</td><td>50.2</td><td>52.9</td><td>63.7</td><td>17.7</td><td>26.8</td><td>43.9</td><td>60.4</td><td>26.8</td><td>42.1</td></tr><tr><td>Distillation (△)</td><td>-4.1</td><td>-3.8</td><td>-4.6</td><td>-4.5</td><td>+0.9</td><td>+4.1</td><td>+4.0</td><td>-3.6</td><td>-2.6</td><td>-6.9</td><td>+14.1</td><td>-0.6</td></tr><tr><td>Same Size (△)</td><td>+0.4</td><td>+0.1</td><td>-0.5</td><td>-1.0</td><td>+2.6</td><td>+10.5</td><td>+12.6</td><td>-2.4</td><td>-0.3</td><td>-0.9</td><td>+1.9</td><td>+2.1</td></tr><tr><td>OLMo (△)</td><td>+3.3</td><td>+2.4</td><td>+1.7</td><td>+1.2</td><td>+2.8</td><td>+12.9</td><td>+7.1</td><td>+1.3</td><td>+0.3</td><td>+4.6</td><td>+4.1</td><td>+3.8</td></tr></table>',\n",
       "  \"<h1 id='120' style='font-size:22px'>4.3. Difference Set Generation Setting Results</h1>\",\n",
       "  \"<p id='121' data-category='paragraph' style='font-size:18px'>Table 2 presents the experimental results for various em-<br>bedding models and different set generation settings. As<br>shown in Table 2, the four AITP variants show improve-<br>ments over the baseline model OLMo-SFT across various<br>settings: using the bge model with density estimation to<br>identify the difference set achieves an average absolute im-<br>provement of 3.8; using bge with density comparison yields<br>an improvement of 4.3; using MiniLM with density compar-<br>ison results in an improvement of 3.0; and using bge with<br>density comparison achieves an improvement of 3.1. These</p>\",\n",
       "  \"<br><p id='122' data-category='paragraph' style='font-size:18px'>results suggest that AITP is robust across various choices of<br>embedding model and difference set generation method.</p>\",\n",
       "  \"<p id='123' data-category='paragraph' style='font-size:20px'>4.4. Ablation Results</p>\",\n",
       "  \"<p id='124' data-category='paragraph' style='font-size:18px'>To verify whether the gains of AITP result from the in-<br>creased size of the SFT dataset after adding the rewritten dif-<br>ference set, we sample a subset from the combined dataset<br>(original SFT and rewritten difference set) that is equal in<br>size to the original SFT dataset and use it for training. Com-<br>paring the first and third rows in Table 3, the AITP method<br>achieves an average absolute improvement of 2.1, even with</p>\",\n",
       "  \"<footer id='125' style='font-size:18px'>6</footer>\",\n",
       "  \"<header id='126' style='font-size:18px'>MAP</header>\",\n",
       "  '<figure id=\\'127\\' data-category=\\'chart\\'><img style=\\'font-size:16px\\' alt=\"Hellaswag GSM8k GPQA Avg \\nP-S I-S P-L - I-L Avg HumanEval MBPP Avg \\n52.5 \\n60 \\n50.0 45 \\n47.5 \\nAccuracy 50 \\nAccuracy \\n45.0 40 \\n42.5 40 \\n35 \\n40.0 Accuracy \\n30 \\n37.5 \\n30 \\n35.0 20 \\n000 0.05 0.07 0.1 10 る 70 0~5 0.6 0.7 000 0.05 0.07 0.1 20 10 0.4 50 00 0.7 000 0.05 0.07 10 10 : 0.4 15 00 0.7 \\n33 \\n33 \\n33 \\nRatio Ratio Ratio \\n(a) IFEval across different ratios (b) Coding across different ratios (c) Reasoning across different ratios \\n\" data-coord=\"top-left:(112,121); bottom-right:(1125,393)\" /></figure>',\n",
       "  \"<caption id='128' style='font-size:18px'>Figure 4: Line graph across different ratios. The x-label represents the ratio of the rewritten set to the original SFT dataset,<br>while the y-label shows accuracy across different benchmarks. More results can be found in Appendix E.</caption>\",\n",
       "  '<figure id=\\'129\\' data-category=\\'chart\\'><img style=\\'font-size:14px\\' alt=\"sft_ data \\nrewrite_ data \\n100 \\n50 \\n2 \\nComponent \\n0 \\nt-SNE \\n-50 \\n-100 \\n-150 \\n- 150 -100 -50 0 50 100 150 \\nt-SNE Component 1 \\n\" data-coord=\"top-left:(128,510); bottom-right:(568,842)\" /></figure>',\n",
       "  \"<caption id='130' style='font-size:18px'>Figure 5: The t-SNE Visualization of SFT and Rewritten<br>Data. The red points and blue points represent the original<br>SFT data and the rewritten data, respectively.</caption>\",\n",
       "  \"<p id='131' data-category='paragraph' style='font-size:18px'>the same dataset size. Comparing the third and fourth rows,<br>the improvement for the same dataset size setting is smaller<br>than the final AITP improvement.</p>\",\n",
       "  \"<p id='132' data-category='paragraph' style='font-size:18px'>Additionally, to test whether the improvement arises from<br>distillation by a stronger model during the rewriting phase,<br>we replace the original SFT dataset with the rewritten dataset<br>from the same distribution and train the model on a com-<br>bined dataset (rewritten same distribution set and rewritten<br>difference set). Comparing the first and second rows in Ta-<br>ble 3, the distillation setting does not outperform the OLMo-<br>SFT baseline, likely because the quality of the rewritten data<br>is lower than that of the original SFT dataset. This indicates<br>that the improvement does not result from distillation by an<br>aligned model.</p>\",\n",
       "  \"<h1 id='133' style='font-size:20px'>4.5. Ratio Results</h1>\",\n",
       "  \"<p id='134' data-category='paragraph' style='font-size:18px'>We further investigate the effect of incorporating various<br>ratios of rewritten difference data on AITP. As shown in<br>Figure 4, the AITP achieves excellent performance with a<br>rewritten data set comprising less than 10 % of the original</p>\",\n",
       "  \"<br><p id='135' data-category='paragraph' style='font-size:18px'>SFT dataset. However, performance declines as the size<br>of the rewritten set increases. We hypothesize that incor-<br>porating a small amount of rewritten data improves model<br>performance significantly by filling gaps in the original SFT<br>data. On the other hand, the quality of the rewritten data<br>might be low, which could degrade the overall data quality<br>when the rewritten ratio is increased. This is consistent with<br>the ablation study on data size in Section 4.4, which shows<br>that the quality of the rewritten data is lower than that of the<br>original SFT dataset and that the improvement in AITP is<br>not due to the increased data size.</p>\",\n",
       "  \"<h1 id='136' style='font-size:18px'>4.6. Visualization</h1>\",\n",
       "  \"<p id='137' data-category='paragraph' style='font-size:20px'>Figure 5 illustrates that the manually combined original<br>SFT dataset (Tulu) forms multiple distinct clusters, indi-<br>cating a high level of diversity within the original dataset.<br>The rewritten data is densely distributed in areas underrep-<br>resented by the original SFT dataset, while intentionally<br>avoiding regions where the original SFT dataset is densely<br>populated. This result clearly demonstrates the effectiveness<br>of the difference set generated by AITP in optimizing data<br>coverage.</p>\",\n",
       "  \"<p id='138' data-category='paragraph' style='font-size:22px'>5. Related Work</p>\",\n",
       "  \"<p id='139' data-category='paragraph' style='font-size:22px'>5.1. Open-Source Large Language Model</p>\",\n",
       "  \"<p id='140' data-category='paragraph' style='font-size:18px'>Current models like GPT-4 (OpenAI et al., 2023), Gemini<br>(Team et al., 2023), and Claude (Anthropic, 2024) have<br>demonstrated impressive performance across various fields.<br>However, their closed-source nature and API-only access<br>limit deployment flexibility. To address this, several open-<br>source models, such as LLaMA (Touvron et al., 2023) ,<br>Qwen (Yang et al., 2024a), DeepSeek(DeepSeek-AI et al.,<br>2024), ChatGLM (GLM et al., 2024), Mixtral (Jiang et al.,<br>2024a), and Yi (AI et al., 2024) have emerged, offering<br>freely accessible model weights. Furthermore, some open-<br>source communities have introduced fully transparent mod-<br>els, such as OLMo (Groeneveld et al., 2024), Map-Neo</p>\",\n",
       "  \"<footer id='141' style='font-size:18px'>7</footer>\",\n",
       "  \"<header id='142' style='font-size:14px'>MAP</header>\",\n",
       "  \"<p id='143' data-category='paragraph' style='font-size:16px'>(Zhang et al., 2024a), LLM360 (Liu et al., 2023), and Pythia<br>(Biderman et al., 2023), which go beyond sharing model<br>weights by providing accessible pre-training corpora, SFT<br>datasets, data-cleaning processes, intermediate checkpoints,<br>and reproducible code, fostering a more open and repro-<br>ducible research ecosystem. In this paper, we primarily<br>conduct experiments on fully transparent open-source mod-<br>els due to their accessible pre-training and SFT datasets.<br>Notably, our method can also be applied to enhance the<br>performance of closed-source models or those that provide<br>open-access weights.</p>\",\n",
       "  \"<h1 id='144' style='font-size:18px'>5.2. Instruction Tuning</h1>\",\n",
       "  \"<p id='145' data-category='paragraph' style='font-size:16px'>Instruction tuning evolves from relying on human-annotated<br>data to incorporating synthetic data, aiming to enhance the<br>adaptability and generalization of pre-trained language mod-<br>els. Initially, instruction tuning involves training models on<br>diverse instruction-response pairs from manually curated<br>datasets, such as FLAN (Wei et al., 2021) and T0 (Sanh<br>et al., 2021), which significantly improve zero-shot and few-<br>shot learning performance. To further enhance cross-task<br>generalization, multi-task learning approaches, like Uni-<br>fiedQA (Khashabi et al., 2020) and FLAN-T5 (Chung et al.,<br>2024), present multiple tasks as instructions, reducing the<br>need for task-specific data and manual prompt engineer-<br>ing. As instruction tuning progresses, the importance of<br>large-scale, diverse datasets becomes evident. Datasets like<br>Super-Natural Instructions (Wang et al., 2022b) provide<br>extensive coverage across tasks, domains, and instruction<br>styles, improving model robustness and mitigating biases.<br>Additionally, the exploration of synthetic data generation<br>techniques augments training sets, enabling models to better<br>handle rare or complex instructions (Xie et al., 2024; Asai<br>et al., 2023). These approaches, which leverage language<br>models to generate additional training samples, demonstrate<br>significant improvements in both performance and general-<br>ization.</p>\",\n",
       "  \"<h1 id='146' style='font-size:18px'>5.3. Improving LLM Using Synthetic Data</h1>\",\n",
       "  \"<p id='147' data-category='paragraph' style='font-size:16px'>Some methods enhance model capabilities by synthesiz-<br>ing data using external signals, such as seed data (Wang<br>et al., 2022a; Sun et al., 2023; Kang et al., 2024; Liang<br>et al., 2024; Taori et al., 2023), pre-training data (Li et al.,<br>2023; Zheng et al., 2024), query data (Huang et al., 2023;<br>Madaan et al., 2023; Yu et al., 2023), feedback data (Lu<br>et al., 2023; Scheurer et al., 2022), and retrieval-augmented<br>generation (RAG) (Asai et al., 2023). These methods can<br>be classified into two types: those that generate synthetic<br>data using the model itself (Liang et al., 2024; Wang et al.,<br>2022a; Sun et al., 2023) and those that use a teacher model<br>for data synthesis (Lee et al., 2024; Li et al., 2024; Taori<br>et al., 2023). While synthetic data approaches effectively<br>mitigate the limitations of supervised dataset sizes, they also</p>\",\n",
       "  \"<br><p id='148' data-category='paragraph' style='font-size:16px'>introduce challenges such as increased hallucinations, lack<br>of diversity, low quality, and distribution misalignment (Liu<br>et al., 2024). Training models iteratively with this synthetic<br>data can lead to issues like model collapse, increased hal-<br>lucinations, and reduced generalizability (Shumailov et al.,<br>2023; Alemohammad et al., 2023; Guo et al., 2024).</p>\",\n",
       "  \"<p id='149' data-category='paragraph' style='font-size:16px'>Recent studies address these limitations through various<br>methods. Some methods aim to improve the quality of gen-<br>erated instruction pairs using self-consistency(Huang et al.,<br>2023), reflection(Renze & Guven, 2024; Li et al., 2024),<br>filtering (Liang et al., 2024; Yuan et al., 2024), and Monte<br>Carlo tree search (MCTS) (Xie et al., 2024; Gao et al., 2024).<br>Others focus on enhancing diversity of generated instruction<br>pairs (Ge et al., 2024; O'Neill et al., 2023), reducing hal-<br>lucinations (Chung et al., 2023; Zhang et al., 2024b; Jones<br>et al., 2023), or optimizing synthetic data distribution (Lu-<br>pidi et al., 2024; Jiang et al., 2024b; Yang et al., 2024b). Our<br>method mainly focuses on further enhancing the diversity of<br>synthetic data after combining existing datasets manually.</p>\",\n",
       "  \"<p id='150' data-category='paragraph' style='font-size:20px'>6. Conclusion</p>\",\n",
       "  \"<p id='151' data-category='paragraph' style='font-size:16px'>The existing SFT datasets exhibit significant differences<br>from the pre-training corpus in terms of coverage and distri-<br>bution. In this paper, we present the AITP method, which<br>adaptively fills the gaps in current manually-assembled SFT<br>datasets by identifying the difference set between the pre-<br>training corpus and the SFT dataset. This approach utilizes<br>existing high-quality SFT data and offers guidance for syn-<br>thesizing lacking data of existing SFT datasets. Our experi-<br>ments demonstrate the effectiveness of AITP, showing that<br>bridging the gap between SFT and pre-training datasets can<br>be achieved by adding a small amount of difference data<br>(less than 10 %). This feature makes AITP a cost-effective<br>and practical solution for real-world applications.</p>\",\n",
       "  \"<p id='152' data-category='paragraph' style='font-size:22px'>References</p>\",\n",
       "  \"<p id='153' data-category='paragraph' style='font-size:18px'>AI, · , : , Young, A., Chen, B., Li, C., Huang, C., Zhang, G.,<br>Zhang, G., Li, H., Zhu, J., Chen, J., Chang, J., Yu, K.,<br>Liu, P., Liu, Q., Yue, S., Yang, S., Yang, S., Yu, T., Xie,<br>W., Huang, W., Hu, X., Ren, X., Niu, X., Nie, P., Xu, Y.,<br>Liu, Y., Wang, Y., Cai, Y., Gu, Z., Liu, Z., and Dai, Z. Yi:<br>Open foundation models by 01.ai. arXiv preprint arXiv:<br>2403.04652, 2024.</p>\",\n",
       "  \"<p id='154' data-category='paragraph' style='font-size:16px'>Alemohammad, S., Casco-Rodriguez, J., Luzi, L., Hu-<br>mayun, A. I., Babaei, H., LeJeune, D., Siahkoohi, A.,<br>and Baraniuk, R. G. Self-consuming generative models<br>go mad. arXiv preprint arXiv: 2307.01850, 2023.</p>\",\n",
       "  \"<p id='155' data-category='paragraph' style='font-size:14px'>Anthropic. Claude 3 haiku: Our fastest model yet,<br>2024. Available at: https : / / www · anthropic.<br>com/ news / claude-3-haiku.</p>\",\n",
       "  \"<footer id='156' style='font-size:14px'>8</footer>\",\n",
       "  \"<header id='157' style='font-size:14px'>MAP</header>\",\n",
       "  \"<p id='158' data-category='paragraph' style='font-size:16px'>Asai, A., Wu, Z., Wang, Y., Sil, A., and Hajishirzi, H. Self-<br>rag: Learning to retrieve, generate, and critique through<br>self-reflection. arXiv preprint arXiv: 2310.11511, 2023.</p>\",\n",
       "  \"<p id='159' data-category='paragraph' style='font-size:18px'>Austin, J., Odena, A., Nye, M., Bosma, M., Michalewski,<br>H., Dohan, D., Jiang, E., Cai, C., Terry, M., Le, Q., and<br>Sutton, C. Program synthesis with large language models.<br>arXiv preprint arXiv: 2108.07732, 2021.</p>\",\n",
       "  \"<p id='160' data-category='paragraph' style='font-size:16px'>Biderman, S., Schoelkopf, H., Anthony, Q., Bradley, H.,<br>O'Brien, K., Hallahan, E., Khan, M. A., Purohit, S.,<br>Prashanth, U. S., Raff, E., Skowron, A., Sutawika, L., and<br>van der Wal, 0. Pythia: A suite for analyzing large lan-<br>guage models across training and scaling. arXiv preprint<br>arXiv: 2304.01373, 2023.</p>\",\n",
       "  \"<p id='161' data-category='paragraph' style='font-size:20px'>Chen, J., Xiao, S., Zhang, P., Luo, K., Lian, D., and<br>Liu, Z. Bge m3-embedding: Multi-lingual, multi-<br>functionality, multi-granularity text embeddings through<br>self-knowledge distillation, 2024.</p>\",\n",
       "  \"<p id='162' data-category='list' style='font-size:18px'>Chen, M., Tworek, J., Jun, H., Yuan, Q., de Oliveira Pinto,<br>H. P., Kaplan, J., Edwards, H., Burda, Y., Joseph, N.,<br>Brockman, G., Ray, A., Puri, R., Krueger, G., Petrov,<br>M., Khlaaf, H., Sastry, G., Mishkin, P., Chan, B., Gray,<br>S., Ryder, N., Pavlov, M., Power, A., Kaiser, L., Bavar-<br>ian, M., Winter, C., Tillet, P., Such, F. P., Cummings, D.,<br>Plappert, M., Chantzis, F., Barnes, E., Herbert- Voss, A.,<br>Guss, W. H., Nichol, A., Paino, A., Tezak, N., Tang,<br>J., Babuschkin, I., Balaji, S., Jain, S., Saunders, W.,<br>Hesse, C., Carr, A. N., Leike, J., Achiam, J., Misra,<br>V., Morikawa, E., Radford, A., Knight, M., Brundage,<br>M., Murati, M., Mayer, K., Welinder, P., McGrew, B.,<br>Amodei, D., McCandlish, S., Sutskever, I., and Zaremba,<br>W. Evaluating large language models trained on code.<br>arXiv preprint arXiv: 2107.03374, 2021.</p>\",\n",
       "  \"<p id='163' data-category='paragraph' style='font-size:18px'>Chung, H. W., Hou, L., Longpre, S., Zoph, B., Tay, Y., Fe-<br>dus, W., Li, Y., Wang, X., Dehghani, M., Brahma, S., et al.<br>Scaling instruction-finetuned language models. Journal<br>of Machine Learning Research, 25(70):1-53, 2024.</p>\",\n",
       "  \"<p id='164' data-category='paragraph' style='font-size:16px'>Chung, J. J. Y., Kamar, E., and Amershi, S. Increasing<br>diversity while maintaining accuracy: Text data genera-<br>tion with large language models and human interventions.<br>arXiv preprint arXiv: 2306.04140, 2023.</p>\",\n",
       "  \"<p id='165' data-category='paragraph' style='font-size:16px'>Clark, P., Cowhey, I., Etzioni, 0., Khot, T., Sabharwal, A.,<br>Schoenick, C., and Tafjord, 0. Think you have solved<br>question answering? try arc, the ai2 reasoning challenge.<br>arXiv preprint arXiv: 1803.05457, 2018.</p>\",\n",
       "  \"<p id='166' data-category='paragraph' style='font-size:18px'>Cobbe, K., Kosaraju, V., Bavarian, M., Chen, M., Jun, H.,<br>Kaiser, L., Plappert, M., Tworek, J., Hilton, J., Nakano,<br>R., Hesse, C., and Schulman, J. Training verifiers to solve<br>math word problems. arXiv preprint arXiv: 2110.14168,<br>2021.</p>\",\n",
       "  \"<br><p id='167' data-category='paragraph' style='font-size:16px'>Contributors, 0. Opencompass: A universal evaluation<br>platform for foundation models. https : / / github.<br>com/ open-compass / opencompass, 2023.</p>\",\n",
       "  \"<p id='168' data-category='paragraph' style='font-size:18px'>DeepSeek-AI, : , Bi, X., Chen, D., Chen, G., Chen, S., Dai,<br>D., Deng, C., Ding, H., Dong, K., Du, Q., Fu, Z., Gao,<br>H., Gao, K., Gao, W., Ge, R., Guan, K., Guo, D. , Guo, J.,<br>Hao, G., Hao, Z., He, Y., Hu, W., Huang, P., Li, E., Li,<br>G., Li, J., Li, Y., Li, Y. K., Liang, W., Lin, F., Liu, A. X.,<br>Liu, B., Liu, W., Liu, X., Liu, X., Liu, Y., Lu, H., Lu, S.,<br>Luo, F., Ma, S., Nie, X., Pei, T., Piao, Y., Qiu, J., Qu,<br>H., Ren, T., Ren, Z., Ruan, C., Sha, Z., Shao, Z., Song,<br>J., Su, X., Sun, J., Sun, Y., Tang, M., Wang, B., Wang,<br>P., Wang, S., Wang, Y., Wang, Y., Wu, T., Wu, Y., Xie,<br>X., Xie, Z., Xie, Z., Xiong, Y., Xu, H., Xu, R. X., Xu,<br>Y., Yang, D., You, Y., Yu, S., Yu, X., Zhang, B., Zhang,<br>H., Zhang, L., Zhang, L., Zhang, M., Zhang, M., Zhang,<br>W., Zhang, Y., Zhao, C., Zhao, Y., Zhou, S., Zhou, S.,<br>Zhu, Q., and Zou, Y. Deepseek llm: Scaling open-source<br>language models with longtermism. arXiv preprint arXiv:<br>2401.02954, 2024.</p>\",\n",
       "  \"<p id='169' data-category='paragraph' style='font-size:16px'>Gao, Z., Niu, B., He, X., Xu, H., Liu, H., Liu, A., Hu,<br>X., and Wen, L. Interpretable contrastive monte carlo<br>tree search reasoning. arXiv preprint arXiv: 2410.01707,<br>2024.</p>\",\n",
       "  \"<p id='170' data-category='paragraph' style='font-size:16px'>Ge, T., Chan, X., Wang, X., Yu, D., Mi, H., and Yu, D. Scal-<br>ing synthetic data creation with 1,000,000,000 personas.<br>arXiv preprint arXiv: 2406.20094, 2024.</p>\",\n",
       "  \"<p id='171' data-category='paragraph' style='font-size:18px'>GLM, T., : , Zeng, A., Xu, B., Wang, B., Zhang, C., Yin, D.,<br>Zhang, D., Rojas, D., Feng, G., Zhao, H., Lai, H., Yu, H.,<br>Wang, H., Sun, J., Zhang, J., Cheng, J., Gui, J., Tang, J.,<br>Zhang, J., Sun, J., Li, J., Zhao, L., Wu, L., Zhong, L., Liu,<br>M., Huang, M., Zhang, P., Zheng, Q., Lu, R., Duan, S.,<br>Zhang, S., Cao, S., Yang, S., Tam, W. L., Zhao, W., Liu,<br>X., Xia, X., Zhang, X., Gu, X., Lv, X., Liu, X., Liu, X.,<br>Yang, X., Song, X., Zhang, X., An, Y., Xu, Y., Niu, Y.,<br>Yang, Y., Li, Y., Bai, Y., Dong, Y., Qi, Z., Wang, Z., Yang,<br>Z., Du, Z., Hou, Z., and Wang, Z. Chatglm: A family of<br>large language models from glm-130b to glm-4 all tools.<br>arXiv preprint arXiv: 2406.12793, 2024.</p>\",\n",
       "  \"<p id='172' data-category='paragraph' style='font-size:18px'>Groeneveld, D., Beltagy, I., Walsh, P., Bhagia, A., Kin-<br>ney, R., Tafjord, O., Jha, A., Ivison, H., Magnusson, I.,<br>Wang, Y., Arora, S., Atkinson, D., Authur, R., Chandu,<br>K. R., Cohan, A., Dumas, J., Elazar, Y., Gu, Y., Hessel, J.,<br>Khot, T., Merrill, W., Morrison, J. D., Muennighoff, N.,<br>Naik, A., Nam, C., Peters, M. E., Pyatkin, V., Ravichan-<br>der, A., Schwenk, D., Shah, S. , Smith, W., Strubell, E.,<br>Subramani, N., Wortsman, M., Dasigi, P., Lambert, N.,<br>Richardson, K., Zettlemoyer, L. S., Dodge, J., Lo, K.,<br>Soldaini, L., Smith, N. A., and Hajishirzi, H. Olmo:<br>Accelerating the science of language models. Annual</p>\",\n",
       "  \"<footer id='173' style='font-size:14px'>9</footer>\",\n",
       "  \"<header id='174' style='font-size:14px'>MAP</header>\",\n",
       "  \"<p id='175' data-category='paragraph' style='font-size:20px'>Meeting of the Associationfor Computational Linguistics,<br>2024. doi: 10.48550/arXiv.2402.00838.</p>\",\n",
       "  \"<p id='176' data-category='paragraph' style='font-size:16px'>Guo, Y., Shang, G., Vazirgiannis, M., and Clavel, C. The<br>curious decline of linguistic diversity: Training language<br>models on synthetic text. In Duh, K., Gomez, H., and<br>Bethard, S. (eds.), Findings of the Associationfor Compu-<br>tational Linguistics: NAACL 2024, pp. 3589-3604, Mex-<br>ico City, Mexico, June 2024. Association for Computa-<br>tional Linguistics. doi: 10.18653/v 1/2024.findings-naacl.<br>228. URL https : / / aclanthology · org/2024.<br>findings-naacl · 228.</p>\",\n",
       "  \"<p id='177' data-category='paragraph' style='font-size:18px'>Hendrycks, D., Burns, C., Basart, S., Zou, A., Mazeika, M.,<br>Song, D., and Steinhardt, J. Measuring massive multitask<br>language understanding. Proceedings of the International<br>Conference on Learning Representations (ICLR), 2021.</p>\",\n",
       "  \"<p id='178' data-category='paragraph' style='font-size:16px'>Huang, J., Gu, S., Hou, L., Wu, Y., Wang, X., Yu, H., and<br>Han, J. Large language models can self-improve. In<br>Bouamor, H., Pino, J., and Bali, K. (eds.), Proceedings<br>of the 2023 Conference on Empirical Methods in Natural<br>Language Processing, pp· 1051-1068, Singapore, De-<br>cember 2023. Association for Computational Linguistics.<br>doi: 10.18653/v1/2023.emnip-main.67. URL https :<br>/ / aclanthology · org/2023 · emnlp-main · 67.</p>\",\n",
       "  \"<p id='179' data-category='paragraph' style='font-size:18px'>Ivison, H., Wang, Y., Pyatkin, V., Lambert, N., Peters, M.,<br>Dasigi, P., Jang, J., Wadden, D., Smith, N. A., Beltagy,<br>I., and Hajishirzi, H. Camels in a changing climate:<br>Enhancing lm adaptation with tulu 2. arXiv preprint<br>arXiv: 2311.10702, 2023.</p>\",\n",
       "  \"<p id='180' data-category='paragraph' style='font-size:18px'>Jiang, A. Q., Sablayrolles, A., Roux, A., Mensch, A.,<br>Savary, B., Bamford, C., Chaplot, D. S., de las Casas,<br>D., Hanna, E. B., Bressand, F., Lengyel, G., Bour, G.,<br>Lample, G., Lavaud, L. R., Saulnier, L., Lachaux, M.-A.,<br>Stock, P., Subramanian, S., Yang, S., Antoniak, S., Scao,<br>T. L., Gervet, T., Lavril, T., Wang, T., Lacroix, T., and<br>Sayed, W. E. Mixtral of experts. arXiv preprint arXiv:<br>2401.04088, 2024a.</p>\",\n",
       "  \"<p id='181' data-category='paragraph' style='font-size:18px'>Jiang, C., min Chan, C., Xue, W., Liu, Q., and Guo, Y.<br>Importance weighting can help large language models<br>self-improve. arXiv preprint arXiv: 2408.09849, 2024b.</p>\",\n",
       "  \"<p id='182' data-category='paragraph' style='font-size:16px'>Jones, E., Palangi, H., Simes, C., Chandrasekaran, V.,<br>Mukherjee, S., Mitra, A., Awadallah, A., and Kamar,<br>E. Teaching language models to hallucinate less with<br>synthetic tasks. arXiv preprint arXiv: 2310.06827, 2023.</p>\",\n",
       "  \"<p id='183' data-category='paragraph' style='font-size:18px'>Kang, J., Luo, H., Zhu, Y., Hansen, J., Glass, J., Cox,<br>D., Ritter, A., Feris, R., and Karlinsky, L. Self-<br>specialization: Uncovering latent expertise within large<br>language models. In Ku, L.-W., Martins, A., and<br>Srikumar, V. (eds.), Findings of the Association for<br>Computational Linguistics: ACL 2024, pp. 2681-2706,</p>\",\n",
       "  \"<br><p id='184' data-category='paragraph' style='font-size:14px'>Bangkok, Thailand, aug 2024. Association for Computa-<br>tional Linguistics. doi: 10.18653/v1/2024.findings-acl.<br>157. URL https : / / aclanthology · org/2024 .<br>findings-acl · 157.</p>\",\n",
       "  \"<p id='185' data-category='paragraph' style='font-size:18px'>Khashabi, D., Min, S., Khot, T., Sabharwal, A., Tafjord, O.,<br>Clark, P., and Hajishirzi, H. Unifiedqa: Crossing format<br>boundaries with a single qa system. arXiv preprint arXiv:<br>2005.00700, 2020.</p>\",\n",
       "  \"<p id='186' data-category='paragraph' style='font-size:18px'>Kwon, W., Li, Z., Zhuang, S., Sheng, Y., Zheng, L., Yu,<br>C. H., Gonzalez, J. E., Zhang, H., and Stoica, I. Efficient<br>memory management for large language model serving<br>with pagedattention. In Proceedings of the ACM SIGOPS<br>29th Symposium on Operating Systems Principles, 2023.</p>\",\n",
       "  \"<p id='187' data-category='paragraph' style='font-size:16px'>Kksal, A., Schick, T., Korhonen, A., and Schtze, H. Long-<br>form: Effective instruction tuning with reverse instruc-<br>tions. Conference on Empirical Methods in Natural<br>Language Processing, 2023. doi: 10.18653/v1/2024.<br>findings-emnlp.414.</p>\",\n",
       "  \"<p id='188' data-category='paragraph' style='font-size:16px'>Lee, N., Wattanawong, T., Kim, S., Mangalam, K., Shen, S.,<br>Anumanchipalli, G., Mahoney, M. W., Keutzer, K., and<br>Gholami, A. Llm21lm: Boosting llms with novel iterative<br>data enhancement. arXiv preprint arXiv: 2403.15042,<br>2024.</p>\",\n",
       "  \"<p id='189' data-category='paragraph' style='font-size:16px'>Li, M., Chen, L., Chen, J., He, S., Gu, J., and Zhou, T.<br>Selective reflection-tuning: Student-selected data recy-<br>cling for LLM instruction-tuning. In Ku, L., Martins,<br>A., and Srikumar, V. (eds.), Findings of the Associa-<br>tion for Computational Linguistics, ACL 2024, Bangkok,<br>Thailand and virtual meeting, August 11-16, 2024, pp.<br>16189-16211. Association for Computational Linguis-<br>tics, 2024. doi: 10.18653/V1/2024.FINDINGS-ACL.<br>958. URL https : / / doi · org/10 · 18653/v1/<br>2024 · findings-acl · 958.</p>\",\n",
       "  \"<p id='190' data-category='paragraph' style='font-size:18px'>Li, X., Yu, P., Zhou, C., Schick, T., Levy, 0., Zettlemoyer,<br>L., Weston, J., and Lewis, M. Self-alignment with instruc-<br>tion backtranslation. arXiv preprint arXiv: 2308.06259,<br>2023.</p>\",\n",
       "  '<p id=\\'191\\' data-category=\\'paragraph\\' style=\\'font-size:16px\\'>Lian, W., Goodson, B., Pentland, E., Cook, A., Vong, C.,<br>and \"Teknium\". Openorca: An open dataset of gpt<br>augmented flan reasoning traces. https : / /https:<br>/ /huggingface · co/ Open-Orca/ OpenOrca,<br>2023.</p>',\n",
       "  \"<p id='192' data-category='paragraph' style='font-size:18px'>Liang, Y., Zhang, G., Qu, X., Zheng, T., Guo, J., Du, X.,<br>Yang, Z., Liu, J., Lin, C., Ma, L., Huang, W., and Zhang,<br>J. I-sheep: Self-alignment of llm from scratch through<br>an iterative self-enhancement paradigm. arXiv preprint<br>arXiv: 2408.08072, 2024.</p>\",\n",
       "  \"<footer id='193' style='font-size:16px'>10</footer>\",\n",
       "  \"<header id='0' style='font-size:14px'>MAP</header>\",\n",
       "  \"<caption id='1' style='font-size:16px'>Liu, R., Wei, J., Liu, F., Si, C., Zhang, Y., Rao, J., Zheng,<br>S., Peng, D., Yang, D., Zhou, D., and Dai, A. M. Best<br>practices and lessons learned on synthetic data. arXiv<br>preprint arXiv: 2404.07503, 2024.</caption>\",\n",
       "  \"<p id='2' data-category='paragraph' style='font-size:20px'>Liu, Z., Qiao, A., Neiswanger, W., Wang, H., Tan, B., Tao,<br>T., Li, J., Wang, Y., Sun, S., Pangarkar, O., Fan, R., Gu,<br>Y., Miller, V., Zhuang, Y., He, G., Li, H., Koto, F., Tang,<br>L., Ranjan, N., Shen, Z., Ren, X., Iriondo, R., Mu, C.,<br>Hu, Z., Schulze, M., Nakov, P., Baldwin, T., and Xing,<br>E. P. Llm360: Towards fully transparent open-source<br>llms. arXiv preprint arXiv: 2312.06550, 2023.</p>\",\n",
       "  \"<p id='3' data-category='paragraph' style='font-size:20px'>Lu, J., Zhong, W., Huang, W., Wang, Y., Zhu, Q., Mi, F.,<br>Wang, B., Wang, W., Zeng, X., Shang, L., Jiang, X., and<br>Liu, Q. Self: Self-evolution with language feedback.<br>arXiv preprint arXiv: 2310.00533, 2023.</p>\",\n",
       "  \"<p id='4' data-category='paragraph' style='font-size:16px'>Lupidi, A., Gemmell, C., Cancedda, N., Dwivedi-Yu, J.,<br>Weston, J., Foerster, J., Raileanu, R., and Lomeli, M.<br>Source2synth: Synthetic data generation and curation<br>grounded in real data sources. arXiv preprint arXiv:<br>2409.08239, 2024.</p>\",\n",
       "  \"<p id='5' data-category='paragraph' style='font-size:20px'>Madaan, A., Tandon, N., Gupta, P., Hallinan, S., Gao, L.,<br>Wiegreffe, S., Alon, U., Dziri, N., Prabhumoye, S., Yang,<br>Y., Gupta, S., Majumder, B. P., Hermann, K., Welleck,<br>S., Yazdanbakhsh, A., and Clark, P. Self-refine: Itera-<br>tive refinement with self-feedback. arXiv preprint arXiv:<br>2303.17651, 2023.</p>\",\n",
       "  \"<p id='6' data-category='paragraph' style='font-size:20px'>O'Neill, C., Ting, Y.-S., Ciuca, I., Miller, J., and Bui, T.<br>Steering language generation: Harnessing contrastive<br>expert guidance and negative prompting for coherent and<br>diverse synthetic data generation. arXiv preprint arXiv:<br>2308.07645, 2023.</p>\",\n",
       "  \"<p id='7' data-category='paragraph' style='font-size:20px'>OpenAI, Achiam, J., Adler, S., Agarwal, S., Ahmad, L.,<br>Akkaya, I., Aleman, F. L., Almeida, D., Altenschmidt, J.,<br>Altman, S., Anadkat, S., Avila, R., Babuschkin, I., Bal-<br>aji, S., Balcom, V., Baltescu, P., Bao, H., Bavarian, M.,<br>Belgum, J., Bello, I., Berdine, J., Bernadett-Shapiro, G.,<br>Berner, C., Bogdonoff, L., Boiko, 0., Boyd, M., Brakman,<br>A.-L., Brockman, G., Brooks, T., Brundage, M., Button,<br>K., Cai, T., Campbell, R., Cann, A., Carey, B., Carlson,<br>C., Carmichael, R., Chan, B., Chang, C., Chantzis, F.,<br>Chen, D., Chen, S., Chen, R., Chen, J., Chen, M., Chess,<br>B., Cho, C., Chu, C., Chung, H. W., Cummings, D., Cur-<br>rier, J., Dai, Y., Decareaux, C., Degry, T., Deutsch, N.,<br>Deville, D., Dhar, A., Dohan, D., Dowling, S., Dunning,<br>S., Ecoffet, A., Eleti, A., Eloundou, T., Farhi, D., Fedus,<br>L., Felix, N., Fishman, S. P., Forte, J., Fulford, I., Gao, L.,<br>Georges, E., Gibson, C., Goel, V., Gogineni, T., Goh, G.,<br>Gontijo-Lopes, R., Gordon, J., Grafstein, M., Gray, S.,<br>Greene, R., Gross, J., Gu, S. S., Guo, Y., Hallacy, C., Han,<br>J., Harris, J., He, Y., Heaton, M., Heidecke, J., Hesse,</p>\",\n",
       "  \"<br><p id='8' data-category='paragraph' style='font-size:20px'>C., Hickey, A., Hickey, W., Hoeschele, P., Houghton, B.,<br>Hsu, K., Hu, S., Hu, X., Huizinga, J., Jain, S., Jain, S.,<br>Jang, J., Jiang, A., Jiang, R., Jin, H., Jin, D., Jomoto, S.,<br>Jonn, B., Jun, H., Kaftan, T., ukasz Kaiser, Kamali, A.,<br>Kanitscheider, I., Keskar, N. S., Khan, T., Kilpatrick, L.,<br>Kim, J. W., Kim, C., Kim, Y., Kirchner, J. H., Kiros, J.,<br>Knight, M., Kokotajlo, D., ukasz Kondraciuk, Kondrich,<br>A., Konstantinidis, A., Kosic, K., Krueger, G., Kuo, V.,<br>Lampe, M., Lan, I., Lee, T., Leike, J., Leung, J., Levy, D.,<br>Li, C. M., Lim, R., Lin, M., Lin, S., Litwin, M., Lopez, T.,<br>Lowe, R., Lue, P., Makanju, A., Malfacini, K., Manning,<br>S., Markov, T., Markovski, Y., Martin, B., Mayer, K.,<br>Mayne, A., McGrew, B., McKinney, S. M., McLeavey, C.,<br>McMillan, P., McNeil, J., Medina, D., Mehta, A., Menick,<br>J., Metz, L., Mishchenko, A., Mishkin, P., Monaco, V.,<br>Morikawa, E., Mossing, D., Mu, T., Murati, M., Murk, 0.,<br>Mly, D., Nair, A., Nakano, R., Nayak, R., Neelakantan,<br>A., Ngo, R., Noh, H., Ouyang, L., O'Keefe, C., Pachocki,<br>J., Paino, A., Palermo, J., Pantuliano, A., Parascandolo,<br>G., Parish, J., Parparita, E., Passos, A., Pavlov, M., Peng,<br>A., Perelman, A., de Avila Belbute Peres, F., Petrov, M.,<br>de Oliveira Pinto, H. P., Michael, Pokorny, Pokrass, M.,<br>Pong, V. H., Powell, T. Power, A., Power, B., Proehl, E.,<br>Puri, R., Radford, A., Rae, J., Ramesh, A., Raymond, C.,<br>Real, F., Rimbach, K., Ross, C., Rotsted, B., Roussez,<br>H., Ryder, N., Saltarelli, M., Sanders, T., Santurkar, S.,<br>Sastry, G., Schmidt, H., Schnurr, D., Schulman, J., Sel-<br>sam, D. , Sheppard, K., Sherbakov, T., Shieh, J. , Shoker,<br>S., Shyam, P., Sidor, S., Sigler, E., Simens, M., Sitkin,<br>J., Slama, K., Sohl, I., Sokolowsky, B., Song, Y., Stau-<br>dacher, N., Such, F. P., Summers, N., Sutskever, I., Tang,<br>J., Tezak, N., Thompson, M. B., Tillet, P., Tootoonchian,<br>A., Tseng, E., Tuggle, P., Turley, N., Tworek, J., Uribe, J.<br>F. C., Vallone, A., Vijayvergiya, A., Voss, C., Wainwright,<br>C., Wang, J. J., Wang, A., Wang, B., Ward, J., Wei, J.,<br>Weinmann, C., Welihinda, A., Welinder, P., Weng, J.,<br>Weng, L., Wiethoff, M., Willner, D., Winter, C., Wolrich,<br>S., Wong, H., Workman, L., Wu, S., Wu, J., Wu, M.,<br>Xiao, K., Xu, T., Yoo, S., Yu, K., Yuan, Q., Zaremba,<br>W., Zellers, R., Zhang, C., Zhang, M., Zhao, S., Zheng,<br>T., Zhuang, J., Zhuk, W., and Zoph, B. Gpt-4 technical<br>report. arXiv preprint arXiv: 2303.08774, 2023.</p>\",\n",
       "  \"<p id='9' data-category='paragraph' style='font-size:16px'>Peng, B., Li, C., He, P., Galley, M., and Gao, J. Instruction<br>tuning with gpt-4. arXiv preprint arXiv: 2304.03277,<br>2023.</p>\",\n",
       "  \"<p id='10' data-category='paragraph' style='font-size:14px'>Reimers, N. and Gurevych, I. Sentence-bert: Sentence em-<br>beddings using siamese bert-networks. In Proceedings<br>of the 2019 Conference on Empirical Methods in Natu-<br>ral Language Processing. Association for Computational<br>Linguistics, 11 2019. URL https : / /arxiv.org/<br>abs/ 1908 · 10084.</p>\",\n",
       "  \"<p id='11' data-category='paragraph' style='font-size:20px'>Rein, D., Hou, B. L., Stickland, A. C., Petty, J., Pang,</p>\",\n",
       "  \"<footer id='12' style='font-size:14px'>11</footer>\",\n",
       "  \"<header id='13' style='font-size:14px'>MAP</header>\",\n",
       "  \"<p id='14' data-category='paragraph' style='font-size:16px'>R. Y., Dirani, J., Michael, J., and Bowman, S. R. Gpqa:<br>A graduate-level google-proof q&a benchmark. arXiv<br>preprint arXiv: 2311.12022, 2023.</p>\",\n",
       "  \"<p id='15' data-category='paragraph' style='font-size:16px'>Renze, M. and Guven, E. Self-reflection in Ilm agents:<br>Effects on problem-solving performance. arXiv preprint<br>arXiv: 2405.06682, 2024.</p>\",\n",
       "  \"<p id='16' data-category='paragraph' style='font-size:20px'>Sanh, V., Webson, A., Raffel, C., Bach, S. H., Sutawika, L.,<br>Alyafeai, Z., Chaffin, A., Stiegler, A., Scao, T. L., Raja,<br>A., Dey, M., Bari, M. S., Xu, C., Thakker, U., Sharma,<br>S. S., Szczechla, E., Kim, T., Chhablani, G., Nayak, N.,<br>Datta, D., Chang, J., Jiang, M. T.-J., Wang, H., Manica,<br>M., Shen, S., Yong, Z. X., Pandey, H., Bawden, R., Wang,<br>T., Neeraj, T., Rozen, J., Sharma, A., Santilli, A., Fevry,<br>T., Fries, J. A., Teehan, R., Bers, T., Biderman, S., Gao, L.,<br>Wolf, T., and Rush, A. M. Multitask prompted training<br>enables zero-shot task generalization. arXiv preprint<br>arXiv: 2110.08207, 2021.</p>\",\n",
       "  \"<p id='17' data-category='paragraph' style='font-size:20px'>Scheurer, J., Campos, J. A., Chan, J. S., Chen, A., Cho, K.,<br>and Perez, E. Training language models with language<br>feedback. arXiv preprint arXiv: 2204.14146, 2022.</p>\",\n",
       "  \"<p id='18' data-category='paragraph' style='font-size:16px'>Shumailov, I., Shumaylov, Z., Zhao, Y., Gal, Y., Papernot,<br>N., and Anderson, R. The curse of recursion: Training<br>on generated data makes models forget. arXiv preprint<br>arXiv: 2305.17493, 2023.</p>\",\n",
       "  \"<p id='19' data-category='paragraph' style='font-size:20px'>Sun, Z., Shen, Y., Zhou, Q., Zhang, H., Chen, Z., Cox, D.,<br>Yang, Y., and Gan, C. Principle-driven self-alignment<br>of language models from scratch with minimal human<br>supervision. arXiv preprint arXiv: 2305.03047, 2023.</p>\",\n",
       "  \"<p id='20' data-category='paragraph' style='font-size:16px'>Taori, R., Gulrajani, I., Zhang, T., Dubois, Y., Li,<br>X., Guestrin, C., Liang, P., and Hashimoto, T. B.<br>Stanford alpaca: An instruction-following llama<br>model. https : / /github · com/tatsu-lab/<br>stanford_alpaca, 2023.</p>\",\n",
       "  \"<p id='21' data-category='paragraph' style='font-size:20px'>Team, G., Anil, R., Borgeaud, S., Alayrac, J.-B., Yu, J.,<br>Soricut, R., Schalkwyk, J., Dai, A. M., Hauth, A., Milli-<br>can, K., Silver, D., Johnson, M., Antonoglou, I., Schrit-<br>twieser, J., Glaese, A., Chen, J., Pitler, E., Lillicrap, T.,<br>Lazaridou, A., Firat, O., Molloy, J., Isard, M., Barham,<br>P. R., Hennigan, T., Lee, B., Viola, F., Reynolds, M.,<br>Xu, Y., Doherty, R., Collins, E., Meyer, C., Rutherford,<br>E., Moreira, E., Ayoub, K., Goel, M., Krawczyk, J.,<br>Du, C., Chi, E., Cheng, H.-T., Ni, E., Shah, P., Kane,<br>P., Chan, B., Faruqui, M., Severyn, A., Lin, H., Li, Y.,<br>Cheng, Y., Ittycheriah, A., Mahdieh, M., Chen, M., Sun,<br>P., Tran, D., Bagri, S., Lakshminarayanan, B., Liu, J.,<br>Orban, A., Gra, F., Zhou, H., Song, X., Boffy, A., Gana-<br>pathy, H., Zheng, S., Choe, H., goston Weisz, Zhu, T.,<br>Lu, Y., Gopal, S., Kahn, J., Kula, M., Pitman, J., Shah,<br>R., Taropa, E., Merey, M. A., Baeuml, M., Chen, Z.,</p>\",\n",
       "  \"<br><p id='22' data-category='paragraph' style='font-size:20px'>Shafey, L. E., Zhang, Y., Sercinoglu, O., Tucker, G., Pi-<br>queras, E., Krikun, M., Barr, I., Savinov, N., Danihelka,<br>I., Roelofs, B., White, A., Andreassen, A., von Glehn,<br>T., Yagati, L., Kazemi, M., Gonzalez, L., Khalman, M.,<br>Sygnowski, J., Frechette, A., Smith, C., Culp, L., Proleev,<br>L., Luan, Y., Chen, X., Lottes, J., Schucher, N., Lebron,<br>F., Rrustemi, A., Clay, N., Crone, P., Kocisky, T., Zhao,<br>J., Perz, B., Yu, D., Howard, H., Bloniarz, A., Rae, J. W.,<br>Lu, H., Sifre, L., Maggioni, M., Alcober, F., Garrette,<br>D., Barnes, M., Thakoor, S., Austin, J., Barth-Maron, G.,<br>Wong, W., Joshi, R., Chaabouni, R., Fatiha, D., Ahuja,<br>A., Tomar, G. S., Senter, E., Chadwick, M., Kornakov,<br>I., Attaluri, N., Iturrate, I., Liu, R., Li, Y., Cogan, S.,<br>Chen, J., Jia, C., Gu, C., Zhang, Q., Grimstad, J., Hart-<br>man, A. J., Garcia, X., Pillai, T. S., Devlin, J., Laskin, M.,<br>de Las Casas, D., Valter, D., Tao, C., Blanco, L., Badia,<br>A. P., Reitter, D., Chen, M., Brennan, J., Rivera, C., Brin,<br>S., Iqbal, S., Surita, G., Labanowski, J., Rao, A., Winkler,<br>S., Parisotto, E., Gu, Y., Olszewska, K., Addanki, R.,<br>Miech, A., Louis, A., Teplyashin, D., Brown, G., Catt, E.,<br>Balaguer, J., Xiang, J., Wang, P., Ashwood, Z., Briukhov,<br>A., Webson, A., Ganapathy, S., Sanghavi, S., Kannan,<br>A., Chang, M.-W., Stjerngren, A., Djolonga, J., Sun, Y.,<br>Bapna, A., Aitchison, M., Pejman, P., Michalewski, H.,<br>Yu, T., Wang, C., Love, J., Ahn, J., Bloxwich, D., Han,<br>K., Humphreys, P., Sellam, T., Bradbury, J., Godbole, V.,<br>Samangooei, S., Damoc, B., Kaskasoli, A., Arnold, S.<br>M. R., Vasudevan, V., Agrawal, S., Riesa, J., Lepikhin,<br>D., Tanburn, R., Srinivasan, S., Lim, H., Hodkinson, S.,<br>Shyam, P., Ferret, J., Hand, S., Garg, A., Paine, T. L.,<br>Li, J., Li, Y., Giang, M., Neitz, A., Abbas, Z., York, S.,<br>Reid, M., Cole, E., Chowdhery, A., Das, D., Rogoziska,<br>D., Nikolaev, V., Sprechmann, P., Nado, Z., Zilka, L.,<br>Prost, F., He, L., Monteiro, M., Mishra, G., Welty, C.,<br>Newlan, J., Jia, D., Allamanis, M., Hu, C. H., de Liedek-<br>erke, R., Gilmer, J., Saroufim, C., Rijhwani, S., Hou, S.,<br>Shrivastava, D., Baddepudi, A., Goldin, A., Ozturel, A.,<br>Cassirer, A., Xu, Y., Sohn, D., Sachan, D., Amplayo,<br>R. K., Swanson, C., Petrova, D., Narayan, S., Guez, A.,<br>Brahma, S., Landon, J., Patel, M., Zhao, R., Villela, K.,<br>Wang, L., Jia, W., Rahtz, M., Gimnez, M., Yeung, L.,<br>Keeling, J., Georgiev, P., Mincu, D., Wu, B., Haykal, S.,<br>Saputro, R., Vodrahalli, K., Qin, J., Cankara, Z., Sharma,<br>A., Fernando, N., Hawkins, W., Neyshabur, B., Kim, S.,<br>Hutter, A., Agrawal, P., Castro-Ros, A., van den Driess-<br>che, G., Wang, T., Yang, F., yiin Chang, S., Komarek, P.,<br>McIlroy, R., Lui, M., Zhang, G., Farhan, W., Sharman,<br>M., Natsev, P., Michel, P., Bansal, Y., Qiao, S., Cao, K.,<br>Shakeri, S., Butterfield, C., Chung, J., Rubenstein, P. K.,<br>Agrawal, S., Mensch, A., Soparkar, K., Lenc, K., Chung,<br>T., Pope, A., Maggiore, L., Kay, J., Jhakra, P., Wang, S.,<br>Maynez, J., Phuong, M., Tobin, T., Tacchetti, A., Trebacz,<br>M., Robinson, K., Katariya, Y., Riedel, S., Bailey, P.,<br>Xiao, K., Ghelani, N., Aroyo, L., Slone, A., Houlsby, N.,</p>\",\n",
       "  \"<footer id='23' style='font-size:16px'>12</footer>\",\n",
       "  \"<header id='24' style='font-size:14px'>MAP</header>\",\n",
       "  \"<p id='25' data-category='paragraph' style='font-size:18px'>Xiong, X., Yang, Z., Gribovskaya, E., Adler, J., Wirth,<br>M., Lee, L., Li, M., Kagohara, T., Pavagadhi, J., Bridgers,<br>S., Bortsova, A., Ghemawat, S., Ahmed, Z., Liu, T., Pow-<br>ell, R., Bolina, V., Iinuma, M., Zablotskaia, P., Besley, J.,<br>Chung, D.-W., Dozat, T., Comanescu, R., Si, X., Greer,<br>J., Su, G., Polacek, M., Kaufman, R. L., Tokumine, S.,<br>Hu, H., Buchatskaya, E., Miao, Y., Elhawaty, M., Sid-<br>dhant, A., Tomasev, N., Xing, J., Greer, C., Miller, H.,<br>Ashraf, S., Roy, A., Zhang, Z., Ma, A., Filos, A., Besta,<br>M., Blevins, R., Klimenko, T., Yeh, C.-K., Changpinyo,<br>S., Mu, J., Chang, 0., Pajarskas, M., Muir, C., Cohen, V.,<br>Lan, C. L., Haridasan, K., Marathe, A., Hansen, S., Dou-<br>glas, S., Samuel, R., Wang, M., Austin, S., Lan, C., Jiang,<br>J., Chiu, J., Lorenzo, J. A., Sjsund, L. L., Cevey, S., Gle-<br>icher, Z., Avrahami, T., Boral, A., Srinivasan, H., Selo, V.,<br>May, R., Aisopos, K., Hussenot, L., Soares, L. B., Baumli,<br>K., Chang, M. B., Recasens, A., Caine, B., Pritzel, A.,<br>Pavetic, F. Pardo, F., Gergely, A., Frye, J., Ramasesh,<br>V., Horgan, D., Badola, K., Kassner, N., Roy, S., Dyer,<br>E., Campos, V. C., Tomala, A., Tang, Y., Badawy, D. E.,<br>White, E., Mustafa, B., Lang, O., Jindal, A., Vikram, S.,<br>Gong, Z., Caelles, S., Hemsley, R., Thornton, G., Feng,<br>F. Stokowiec, W., Zheng, C., Thacker, P., alar nl, Zhang,<br>Z., Saleh, M., Svensson, J., Bileschi, M., Patil, P., Anand,<br>A., Ring, R., Tsihlas, K., Vezer, A., Selvi, M., Shevlane,<br>T., Rodriguez, M., Kwiatkowski, T., Daruki, S., Rong,<br>K., Dafoe, A., FitzGerald, N., Gu-Lemberg, K., Khan,<br>M., Hendricks, L. A., Pellat, M., Feinberg, V., Cobon-<br>Kerr, J., Sainath, T., Rauh, M., Hashemi, S. H., Ives,<br>R., Hasson, Y., Noland, E., Cao, Y., Byrd, N., Hou, L.,<br>Wang, Q., Sottiaux, T., Paganini, M., Lespiau, J.-B., Mou-<br>farek, A., Hassan, S., Shivakumar, K., van Amersfoort, J.,<br>Mandhane, A., Joshi, P., Goyal, A., Tung, M., Brock, A.,<br>Sheahan, H., Misra, V., Li, C., Rakievi, N., Dehghani, M.,<br>Liu, F., Mittal, S., Oh, J., Noury, S., Sezener, E., Huot, F.,<br>Lamm, M., Cao, N. D., Chen, C., Mudgal, S., Stella, R.,<br>Brooks, K., Vasudevan, G., Liu, C., Chain, M., Melink-<br>eri, N., Cohen, A., Wang, V., Seymore, K., Zubkov, S.,<br>Goel, R., Yue, S., Krishnakumaran, S., Albert, B., Hurley,<br>N., Sano, M., Mohananey, A., Joughin, J., Filonov, E.,<br>Kpa, T., Eldawy, Y., Lim, J., Rishi, R., Badiezadegan, S.,<br>Bos, T., Chang, J., Jain, S., Padmanabhan, S. G. S., Putta-<br>gunta, S., Krishna, K., Baker, L., Kalb, N., Bedapudi, V.,<br>Kurzrok, A., Lei, S., Yu, A., Litvin, O., Zhou, X., Wu, Z.,<br>Sobell, S., Siciliano, A., Papir, A., Neale, R., Bragagnolo,<br>J., Toor, T., Chen, T., Anklin, V., Wang, F., Feng, R.,<br>Gholami, M., Ling, K., Liu, L., Walter, J., Moghaddam,<br>H., Kishore, A., Adamek, J., Mercado, T., Mallinson, J.,<br>Wandekar, S., Cagle, S., Ofek, E., Garrido, G., Lombriser,<br>C., Mukha, M., Sun, B., Mohammad, H. R., Matak, J.,<br>Qian, Y., Peswani, V., Janus, P., Yuan, Q., Schelin, L.,<br>David, 0., Garg, A., He, Y., Duzhyi, 0., lgmyr, A., Lottaz,<br>T., Li, Q., Yadav, V., Xu, L., Chinien, A., Shivanna, R.,<br>Chuklin, A., Li, J., Spadine, C., Wolfe, T., Mohamed, K.,</p>\",\n",
       "  \"<br><p id='26' data-category='paragraph' style='font-size:18px'>Das, S., Dai, Z., He, K., von Dincklage, D., Upadhyay, S.,<br>Maurya, A., Chi, L., Krause, S., Salama, K., Rabinovitch,<br>P. G., M, P. K. R., Selvan, A., Dektiarev, M., Ghiasi, G.,<br>Guven, E., Gupta, H., Liu, B., Sharma, D., Shtacher, I. H.,<br>Paul, S., Akerlund, O., Aubet, F.-X., Huang, T., Zhu, C.,<br>Zhu, E., Teixeira, E., Fritze, M., Bertolini, F., Marinescu,<br>L.-E., Blle, M., Paulus, D., Gupta, K., Latkar, T., Chang,<br>M., Sanders, J., Wilson, R., Wu, X., Tan, Y.-X., Thiet,<br>L. N., Doshi, T., Lall, S., Mishra, S., Chen, W., Luong, T.,<br>Benjamin, S., Lee, J., Andrejczuk, E., Rabiej, D., Ranjan,<br>V., Styrc, K., Yin, P., Simon, J., Harriott, M. R., Bansal,<br>M., Robsky, A., Bacon, G., Greene, D., Mirylenka, D.,<br>Zhou, C., Sarvana, O., Goyal, A., Andermatt, S., Siegler,<br>P., Horn, B., Israel, A., Pongetti, F., Chen, C.-W. L., Sel-<br>vatici, M., Silva, P., Wang, K., Tolins, J., Guu, K., Yogev,<br>R., Cai, X., Agostini, A., Shah, M., Nguyen, H., Don-<br>naile, N. , Pereira, S., Friso, L., Stambler, A., Kurzrok,<br>A., Kuang, C., Romanikhin, Y., Geller, M., Yan, Z., Jang,<br>K., Lee, C.-C., Fica, W., Malmi, E., Tan, Q., Banica,<br>D., Balle, D., Pham, R., Huang, Y., Avram, D., Shi, H.,<br>Singh, J., Hidey, C., Ahuja, N., Saxena, P., Dooley, D.,<br>Potharaju, S. P., O'Neill, E., Gokulchandran, A., Foley,<br>R., Zhao, K., Dusenberry, M., Liu, Y., Mehta, P., Kotikala-<br>pudi, R., Safranek-Shrader, C., Goodman, A., Kessinger,<br>J., Globen, E., Kolhar, P., Gorgolewski, C., Ibrahim, A.,<br>Song, Y., Eichenbaum, A., Brovelli, T., Potluri, S., La-<br>hoti, P., Baetu, C., Ghorbani, A., Chen, C., Crawford, A.,<br>Pal, S., Sridhar, M., Gurita, P., Mujika, A., Petrovski, I.,<br>Cedoz, P.-L., Li, C., Chen, S., Santo, N. D., Goyal, S.,<br>Punjabi, J., Kappaganthu, K., Kwak, C., LV,P., Velury, S.,<br>Choudhury, H., Hall, J., Shah, P., Figueira, R., Thomas,<br>M., Lu, M., Zhou, T., Kumar, C., Jurdi, T., Chikkerur, S.,<br>Ma, Y., Yu, A., Kwak, S., hdel, V., Rajayogam, S., Choma,<br>T., Liu, F., Barua, A., Ji, C., Park, J. H., Hellendoorn, V.,<br>Bailey, A., Bilal, T., Zhou, H., Khatir, M., Sutton, C.,<br>Rzadkowski, W., Macintosh, F., Shagin, K., Medina, P.,<br>Liang, C., Zhou, J., Shah, P., Bi, Y., Dankovics, A., Banga,<br>S., Lehmann, S., Bredesen, M., Lin, Z., Hoffmann, J. E.,<br>Lai, J., Chung, R., Yang, K., Balani, N., Brainskas, A.,<br>Sozanschi, A., Hayes, M., Alcalde, H. F., Makarov, P.,<br>Chen, W., Stella, A., Snijders, L., Mandl, M., Krrman,<br>A., Nowak, P., Wu, X., Dyck, A., Vaidyanathan, K., R,<br>R., Mallet, J., Rudominer, M., Johnston, E., Mittal, S.,<br>Udathu, A., Christensen, J., Verma, V., Irving, Z., San-<br>tucci, A., Elsayed, G., Davoodi, E., Georgiev, M., Tenney,<br>I., Hua, N., Cideron, G., Leurent, E., Alnahlawi, M.,<br>Georgescu, I., Wei, N., Zheng, I., Scandinaro, D., Jiang,<br>H., Snoek, J., Sundararajan, M., Wang, X., Ontiveros, Z.,<br>Karo, I., Cole, J., Rajashekhar, V., Tumeh, L., Ben-David,<br>E., Jain, R., Uesato, J., Datta, R., Bunyan, O., Wu, S.,<br>Zhang, J., Stanczyk, P., Zhang, Y., Steiner, D., Naskar,<br>S., Azzam, M., Johnson, M., Paszke, A., Chiu, C.-C.,<br>Elias, J. S., Mohiuddin, A., Muhammad, F., Miao, J.,<br>Lee, A., Vieillard, N., Park, J., Zhang, J., Stanway, J.,</p>\",\n",
       "  \"<footer id='27' style='font-size:14px'>13</footer>\",\n",
       "  \"<header id='28' style='font-size:14px'>MAP</header>\",\n",
       "  \"<p id='29' data-category='paragraph' style='font-size:18px'>Garmon, D., Karmarkar, A., Dong, Z., Lee, J., Kumar,<br>A., Zhou, L., Evens, J., Isaac, W., Irving, G., Loper, E.,<br>Fink, M., Arkatkar, I., Chen, N., Shafran, I., Petrychenko,<br>I., Chen, Z., Jia, J., Levskaya, A., Zhu, Z., Grabowski,<br>P., Mao, Y., Magni, A., Yao, K., Snaider, J., Casagrande,<br>N., Palmer, E., Suganthan, P., Castao, A., Giannoumis, I.,<br>Kim, W., Rybiski, M., Sreevatsa, A., Prendki, J., Soergel,<br>D., Goedeckemeyer, A., Gierke, W., Jafari, M., Gaba,<br>M., Wiesner, J., Wright, D. G., Wei, Y., Vashisht, H.,<br>Kulizhskaya, Y., Hoover, J., Le, M., Li, L., Iwuanyanwu,<br>C., Liu, L., Ramirez, K., Khorlin, A., Cui, A., LIN, T.,<br>Wu, M., Aguilar, R., Pallo, K., Chakladar, A., Perng, G.,<br>Abellan, E. A., Zhang, M., Dasgupta, I., Kushman, N.,<br>Penchev, I., Repina, A., Wu, X., van der Weide, T., Pon-<br>napalli, P., Kaplan, C., Simsa, J., Li, S., Dousse, 0., Yang,<br>F., Piper, J., Ie, N., Pasumarthi, R., Lintz, N., Vijayaku-<br>mar, A., Andor, D., Valenzuela, P., Lui, M., Paduraru,<br>C., Peng, D., Lee, K., Zhang, S., Greene, S., Nguyen,<br>D. D., Kurylowicz, P., Hardin, C., Dixon, L., Janzer, L.,<br>Choo, K., Feng, Z., Zhang, B., Singhal, A., Du, D., McK-<br>innon, D., Antropova, N., Bolukbasi, T., Keller, O., Reid,<br>D., Finchelstein, D., Raad, M. A., Crocker, R., Hawkins,<br>P., Dadashi, R., Gaffney, C., Franko, K., Bulanova, A.,<br>Leblond, R., Chung, S., Askham, H., Cobo, L. C., Xu,<br>K., Fischer, F., Xu, J., Sorokin, C., Alberti, C., Lin, C.-<br>C., Evans, C., Dimitriev, A., Forbes, H., Banarse, D.,<br>Tung, Z., Omernick, M., Bishop, C., Sterneck, R., Jain,<br>R., Xia, J., Amid, E., Piccinno, F., Wang, X., Banzal, P.,<br>Mankowitz, D. J., Polozov, A., Krakovna, V., Brown, S.,<br>Bateni, M., Duan, D., Firoiu, V., Thotakuri, M., Natan,<br>T., Geist, M., tan Girgin, S., Li, H., Ye, J., Roval, 0.,<br>Tojo, R., Kwong, M., Lee-Thorp, J., Yew, C., Sinopal-<br>nikov, D., Ramos, S., Mellor, J., Sharma, A., Wu, K.,<br>Miller, D., Sonnerat, N., Vnukov, D., Greig, R., Beattie,<br>J., Caveness, E., Bai, L., Eisenschlos, J., Korchemniy,<br>A., Tsai, T., Jasarevic, M., Kong, W., Dao, P., Zheng, Z.,<br>Liu, F., Yang, F., Zhu, R., Teh, T. H., Sanmiya, J., Glad-<br>chenko, E., Trdin, N., Toyama, D., Rosen, E., Tavakkol,<br>S., Xue, L., Elkind, C., Woodman, 0., Carpenter, J., Papa-<br>makarios, G., Kemp, R., Kafle, S., Grunina, T., Sinha, R.,<br>Talbert, A., Wu, D., Owusu-Afriyie, D., Du, C., Thorn-<br>ton, C., Pont-Tuset, J., Narayana, P., Li, J., Fatehi, S.,<br>Wieting, J., Ajmeri, O., Uria, B., Ko, Y., Knight, L.,<br>Hliou, A., Niu, N., Gu, S., Pang, C., Li, Y., Levine, N.,<br>Stolovich, A., Santamaria-Fernandez, R., Goenka, S.,<br>Yustalim, W., Strudel, R., Elqursh, A., Deck, C., Lee,<br>H., Li, Z., Levin, K., Hoffmann, R., Holtmann-Rice, D.,<br>Bachem, 0., Arora, S., Koh, C., Yeganeh, S. H., Pder, S.,<br>Tariq, M., Sun, Y., Ionita, L., Seyedhosseini, M., Tafti, P.,<br>Liu, Z., Gulati, A., Liu, J., Ye, X., Chrzaszcz, B., Wang,<br>L., Sethi, N., Li, T. Brown, B., Singh, S., Fan, W., Parisi,<br>A., Stanton, J., Koverkathu, V., Choquette-Choo, C. A.,<br>Li, Y., Lu, T., Ittycheriah, A., Shroff, P., Varadarajan, M.,<br>Bahargam, S., Willoughby, R., Gaddy, D., Desjardins,</p>\",\n",
       "  \"<br><p id='30' data-category='paragraph' style='font-size:18px'>G., Cornero, M., Robenek, B., Mittal, B., Albrecht, B.,<br>Shenoy, A., Moiseev, F., Jacobsson, H., Ghaffarkhah,<br>A., Rivire, M., Walton, A., Crepy, C., Parrish, A., Zhou,<br>Z., Farabet, C., Radebaugh, C., Srinivasan, P., van der<br>Salm, C., Fidjeland, A., Scellato, S., Latorre-Chimoto,<br>E., Klimczak-Pluciska, H., Bridson, D., de Cesare, D.,<br>Hudson, T., Mendolicchio, P., Walker, L., Morris, A.,<br>Mauger, M., Guseynov, A., Reid, A., Odoom, S., Loher,<br>L., Cotruta, V., Yenugula, M., Grewe, D., Petrushkina, A.,<br>Duerig, T., Sanchez, A., Yadlowsky, S., Shen, A., Glober-<br>son, A., Webb, L., Dua, S., Li, D., Bhupatiraju, S., Hurt,<br>D., Qureshi, H., Agarwal, A., Shani, T., Eyal, M., Khare,<br>A., Belle, S. R., Wang, L., Tekur, C., Kale, M. S., Wei, J.,<br>Sang, R., Saeta, B., Liechty, T., Sun, Y., Zhao, Y., Lee, S.,<br>Nayak, P., Fritz, D., Vuyyuru, M. R., Aslanides, J., Vyas,<br>N., Wicke, M., Ma, X., Eltyshev, E., Martin, N., Cate, H.,<br>Manyika, J., Amiri, K., Kim, Y., Xiong, X., Kang, K.,<br>Luisier, F., Tripuraneni, N., Madras, D., Guo, M., Waters,<br>A., Wang, 0., Ainslie, J., Baldridge, J., Zhang, H., Pruthi,<br>G., Bauer, J., Yang, F., Mansour, R., Gelman, J., Xu, Y.,<br>Polovets, G., Liu, J., Cai, H., Chen, W., Sheng, X., Xue,<br>E., Ozair, S., Angermueller, C., Li, X., Sinha, A., Wang,<br>W., Wiesinger, J., Koukoumidis, E., Tian, Y., Iyer, A.,<br>Gurumurthy, M., Goldenson, M., Shah, P., Blake, M., Yu,<br>H., Urbanowicz, A., Palomaki, J., Fernando, C., Durden,<br>K., Mehta, H., Momchev, N., Rahimtoroghi, E., Geor-<br>gaki, M., Raul, A., Ruder, S., Redshaw, M., Lee, J., Zhou,<br>D., Jalan, K., Li, D., Hechtman, B., Schuh, P., Nasr, M.,<br>Milan, K., Mikulik, V., Franco, J., Green, T., Nguyen,<br>N., Kelley, J., Mahendru, A., Hu, A., Howland, J., Var-<br>gas, B., Hui, J., Bansal, K., Rao, V., Ghiya, R., Wang,<br>E., Ye, K., Sarr, J. M., Preston, M. M., Elish, M., Li, S.,<br>Kaku, A., Gupta, J., Pasupat, I., Juan, D.-C., Someswar,<br>M., M., T., Chen, X., Amini, A., Fabrikant, A., Chu, E.,<br>Dong, X., Muthal, A., Buthpitiya, S., Jauhari, S., Hua, N.,<br>Khandelwal, U., Hitron, A., Ren, J., Rinaldi, L., Drath,<br>S., Dabush, A., Jiang, N.-J., Godhia, H., Sachs, U., Chen,<br>A., Fan, Y., Taitelbaum, H., Noga, H., Dai, Z., Wang, J.,<br>Liang, C., Hamer, J., Ferng, C.-S., Elkind, C., Atias, A.,<br>Lee, P., Listk, V., Carlen, M., van de Kerkhof, J., Pikus,<br>M., Zaher, K., Mller, P., Zykova, S., Stefanec, R., Gatsko,<br>V., Hirnschall, C., Sethi, A., Xu, X. F. Ahuja, C., Tsai,<br>B., Stefanoiu, A., Feng, B., Dhandhania, K., Katyal, M.,<br>Gupta, A., Parulekar, A., Pitta, D., Zhao, J., Bhatia, V.,<br>Bhavnani, Y., Alhadlaq, O., Li, X., Danenberg, P., Tu,<br>D., Pine, A., Filippova, V., Ghosh, A., Limonchik, B.,<br>Urala, B., Lanka, C. K., Clive, D., Sun, Y., Li, E., Wu,<br>H., Hongtongsak, K., Li, I., Thakkar, K., Omarov, K.,<br>Majmundar, K., Alverson, M., Kucharski, M., Patel, M.,<br>Jain, M., Zabelin, M., Pelagatti, P., Kohli, R., Kumar,<br>S., Kim, J., Sankar, S., Shah, V., Ramachandruni, L.,<br>Zeng, X., Bariach, B., Weidinger, L., Vu, T., Andreev,<br>A., He, A., Hui, K., Kashem, S., Subramanya, A., Hsiao,<br>S., Hassabis, D., Kavukcuoglu, K., Sadovsky, A., Le, Q.,</p>\",\n",
       "  \"<footer id='31' style='font-size:14px'>14</footer>\",\n",
       "  \"<header id='32' style='font-size:16px'>MAP</header>\",\n",
       "  \"<p id='33' data-category='paragraph' style='font-size:18px'>Strohman, T. Wu, Y., Petrov, S., Dean, J., and Vinyals, 0.<br>Gemini: A family of highly capable multimodal models.<br>arXiv preprint arXiv: 2312.11805, 2023.</p>\",\n",
       "  \"<p id='34' data-category='paragraph' style='font-size:16px'>Team, Q. Qwen2.5: A party of foundation models, Septem-<br>ber 2024. URL https : / / qwenlm · github io/<br>blog/ qwen2 · 5/.</p>\",\n",
       "  \"<p id='35' data-category='paragraph' style='font-size:16px'>Teknium. Openhermes 2.5: An open dataset of<br>synthetic data for generalist llm assistants, 2023.<br>URL https : / /huggingface · co/ datasets/<br>teknium/ OpenHermes-2 . 5.</p>\",\n",
       "  \"<p id='36' data-category='paragraph' style='font-size:20px'>Touvron, H., Lavril, T., Izacard, G., Martinet, X., Lachaux,<br>M.-A., Lacroix, T., Rozire, B., Goyal, N., Hambro, E.,<br>Azhar, F., Rodriguez, A., Joulin, A., Grave, E., and Lam-<br>ple, G. Llama: Open and efficient foundation language<br>models. arXiv preprint arXiv: 2302.13971, 2023.</p>\",\n",
       "  \"<p id='37' data-category='paragraph' style='font-size:14px'>Vitter, J. S. Random sampling with a reservoir. ACM Trans.<br>Math. Softw., 11(1):3757, March 1985. ISSN 0098-3500.<br>doi: 10.1145/3147.3165. URL https : / / doi · org/<br>10 · 1145/3147 · 3165.</p>\",\n",
       "  \"<p id='38' data-category='paragraph' style='font-size:20px'>Wang, Y., Kordi, Y., Mishra, S., Liu, A., Smith, N. A.,<br>Khashabi, D., and Hajishirzi, H. Self-instruct: Aligning<br>language models with self-generated instructions. arXiv<br>preprint arXiv: 2212.10560, 2022a.</p>\",\n",
       "  \"<p id='39' data-category='paragraph' style='font-size:18px'>Wang, Y., Mishra, S., Alipoormolabashi, P., Ko-<br>rdi, Y., Mirzaei, A., Arunkumar, A., Ashok, A.,<br>Dhanasekaran, A. S., Naik, A., Stap, D., et al. Super-<br>naturalinstructions:generalization via declarative instruc-<br>tions on 1600+ tasks. In EMNLP, 2022b.</p>\",\n",
       "  \"<p id='40' data-category='paragraph' style='font-size:18px'>Wei, J., Bosma, M., Zhao, V., Guu, K., Yu, A. W., Lester,<br>B., Du, N., Dai, A. M., and Le, Q. V. Finetuned language<br>models are zero-shot learners. International Conference<br>on Learning Representations, 2021.</p>\",\n",
       "  \"<p id='41' data-category='paragraph' style='font-size:20px'>Xie, Y., Goyal, A., Zheng, W., Kan, M.-Y., Lillicrap, T. P.,<br>Kawaguchi, K., and Shieh, M. Monte carlo tree search<br>boosts reasoning via iterative preference learning. arXiv<br>preprint arXiv: 2405.00451, 2024.</p>\",\n",
       "  \"<p id='42' data-category='paragraph' style='font-size:20px'>Yang, A., Yang, B., Hui, B., Zheng, B., Yu, B., Zhou, C., Li,<br>C., Li, C., Liu, D. , Huang, F., Dong, G., Wei, H., Lin, H.,<br>Tang, J., Wang, J., Yang, J., Tu, J., Zhang, J. , Ma, J., Yang,<br>J., Xu, J., Zhou, J., Bai, J., He, J., Lin, J., Dang, K., Lu,<br>K., Chen, K., Yang, K., Li, M., Xue, M., Ni, N., Zhang,<br>P., Wang, P., Peng, R., Men, R., Gao, R., Lin, R., Wang,<br>S., Bai, S. Tan, S. , Zhu, T., Li, T., Liu, T., Ge, W., Deng,<br>,<br>X., Zhou, X., Ren, X., Zhang, X., Wei, X., Ren, X., Liu,<br>X., Fan, Y., Yao, Y., Zhang, Y., Wan, Y., Chu, Y., Liu, Y.,<br>Cui, Z., Zhang, Z., Guo, Z., and Fan, Z. Qwen2 technical<br>report. arXiv preprint arXiv: 2407.10671, 2024a.</p>\",\n",
       "  \"<br><p id='43' data-category='paragraph' style='font-size:20px'>Yang, Z., Pang, T., Feng, H., Wang, H., Chen, W., Zhu,<br>M., and Liu, Q. Self-distillation bridges distribution gap<br>in language model fine-tuning. arXiv preprint arXiv:<br>2402.13669, 2024b.</p>\",\n",
       "  \"<p id='44' data-category='paragraph' style='font-size:18px'>Yu, L., Jiang, W., Shi, H., Yu,J., Liu, Z., Zhang, Y., Kwok,<br>J. T., Li, Z., Weller, A., and Liu, W. Metamath: Boot-<br>strap your own mathematical questions for large language<br>models. International Conference on Learning Represen-<br>tations, 2023. doi: 10.48550/arXiv.2309.12284.</p>\",\n",
       "  \"<p id='45' data-category='paragraph' style='font-size:20px'>Yuan, W., Pang, R. Y., Cho, K., Li, X., Sukhbaatar, S., Xu,<br>J., and Weston, J. Self-rewarding language models. arXiv<br>preprint arXiv: 2401.10020, 2024.</p>\",\n",
       "  \"<p id='46' data-category='paragraph' style='font-size:18px'>Zellers, R., Holtzman, A., Bisk, Y., Farhadi, A., and Choi,<br>Y. Hellaswag: Can a machine really finish your sentence?<br>Annual Meeting of the Association for Computational<br>Linguistics, 2019. doi: 10.18653/v1/P19-1472.</p>\",\n",
       "  \"<p id='47' data-category='paragraph' style='font-size:20px'>Zhang, G., Qu, S., Liu, J., Zhang, C., Lin, C., Yu, C. L.,<br>Pan, D., Cheng, E., Liu, J., Lin, Q., Yuan, R., Zheng, T.,<br>Pang, W., Du, X., Liang, Y., Ma, Y., Li, Y., Ma, Z., Lin,<br>B., Benetos, E., Yang, H., Zhou, J., Ma, K., Liu, M., Niu,<br>M., Wang, N., Que, Q., Liu, R., Liu, S., Guo, S., Gao, S.,<br>Zhou, W., Zhang, X., Zhou, Y., Wang, Y., Bai, Y., Zhang,<br>Y., Zhang, Y., Wang, Z., Yang, Z., Zhao, Z., Zhang, J.,<br>Ouyang, W., Huang, W., and Chen, W. Map-neo: Highly<br>capable and transparent bilingual large language model<br>series. arXiv preprint arXiv: 2405.19327, 2024a.</p>\",\n",
       "  \"<p id='48' data-category='paragraph' style='font-size:20px'>Zhang, J., Juan, D.-C., Rashtchian, C., Ferng, C.-S., Jiang,<br>H., and Chen, Y. Sled: Self logits evolution decoding<br>for improving factuality in large language models. arXiv<br>preprint arXiv: 2411.02433, 2024b.</p>\",\n",
       "  \"<p id='49' data-category='paragraph' style='font-size:18px'>Zheng, T., Guo, S., Qu, X., Guo, J., Du, X., Jia, Q., Lin,<br>C., Huang, W., Fu, J., and Zhang, G. Kun: Answer pol-<br>ishment for chinese self-alignment with instruction back-<br>translation. arXiv preprint arXiv: 2401.06477, 2024.</p>\",\n",
       "  \"<p id='50' data-category='paragraph' style='font-size:20px'>Zhou, C., Liu, P., Xu, P., Iyer, S., Sun, J., Mao, Y., Ma, X.,<br>Efrat, A., Yu, P., Yu, L., Zhang, S., Ghosh, G., Lewis, M.,<br>Zettlemoyer, L., and Levy, 0. Lima: Less is more for<br>alignment. arXiv preprint arXiv: 2305.11206, 2023a.</p>\",\n",
       "  \"<p id='51' data-category='paragraph' style='font-size:20px'>Zhou, J., Lu, T., Mishra, S., Brahma, S., Basu, S., Luan,<br>Y., Zhou, D., and Hou, L. Instruction-following evalu-<br>ation for large language models. arXiv preprint arXiv:<br>2311.07911, 2023b.</p>\",\n",
       "  \"<footer id='52' style='font-size:16px'>15</footer>\",\n",
       "  \"<header id='53' style='font-size:16px'>MAP</header>\",\n",
       "  \"<p id='54' data-category='paragraph' style='font-size:20px'>A. Visualization of SFT Dataset Projections onto the Pre-training Corpus</p>\",\n",
       "  '<figure id=\\'55\\'><img style=\\'font-size:14px\\' alt=\"15 15 15\\n10 10 10\\n2\\n5\\n5 2\\n5 2\\nComponent\\nComponent\\n0 0 0\\n-5 Component\\n-5 -5\\nPCA\\nPCA\\nPCA\\n10 - 10 -10\\n-15 -15 -15\\n-20 -20 -20\\n20 10 0 10 20 - 20 - 10 0 10 20 - 20 -10 0 10 20\\nPCA Component 1 PCA Component 1 PCA Component 1\\n(a) Dolly VS Dolma (b) EvolInstruct VS Dolma (c) Neo-SFT VS Dolma\\n15 15 15\\n10 10 10\\n2\\n5 2\\n5\\n5 2\\nComponent\\nComponent\\n0 0 0\\n-5 Component\\n-5 -5\\nPCA\\nPCA\\n-10 PCA\\n-10 -10\\n-15 -15 -15\\n-20 -20 -20\\n- 20 - 10 0 10 20 20 - 10 0 10 20 20 - 10 0 10 20\\nPCA Component 1 PCA Component 1 PCA Component 1\\n(d) OpenHermes VS Dolma (e) Tulu VS Dolma (f) WildChat VS Dolma\\n15 15 15\\n10 10 10\\n2\\n2\\n2\\nComponent\\nComponent\\nComponent\\n5 5 5\\n0 0 0\\nPCA\\nPCA\\nPCA\\n-5 -5 -5\\n-10 -10 -10\\n- 15 -15 -15\\n20 -15 -10 -5 0 5 10 15 - 20 - 15 -10 -5 0 5 10 15 -20 -15 -10 -5 0 5 10 15\\nPCA Component 1 PCA Component 1 PCA Component 1\\n(g) Dolly VS Cosmopedia (h) Neo-SFT VS Cosmopedia (i) OpenHermes VS Cosmopedia\" data-coord=\"top-left:(111,204); bottom-right:(1142,1332)\" /></figure>',\n",
       "  \"<br><caption id='56' style='font-size:18px'>Figure 6: Visualization of data distribution changes in AITP. The red regions at the bottom denote the pre-training<br>corpus, while the light blue regions above represent the SFT datasets. Darker areas indicate a higher concentration of data<br>points, whereas lighter areas signify sparser distributions.</caption>\",\n",
       "  \"<footer id='57' style='font-size:16px'>16</footer>\",\n",
       "  \"<header id='58' style='font-size:20px'>MAP</header>\",\n",
       "  \"<h1 id='59' style='font-size:22px'>B. Reservoir sampling algorithm</h1>\",\n",
       "  \"<p id='60' data-category='paragraph' style='font-size:20px'>Reservoir Sampling is an efficient streaming data sampling method that enables uniform sampling of k items from a data<br>stream without knowing the total size of the stream. It is particularly suited for scenarios with memory constraints or<br>uncertain stream sizes, allowing for equal-probability sampling in a single pass over the data.</p>\",\n",
       "  \"<table id='61' style='font-size:18px'><tr><td>Algorithm 1 Reservoir Sampling</td></tr><tr><td>Input: stream of data x1, x2, · · · , sample size k</td></tr><tr><td>Output: a random sample of size k</td></tr><tr><td>Initialize an empty reservoir array R of size k</td></tr><tr><td>for i = 1 to k do</td></tr><tr><td>R[i] ← Xi</td></tr><tr><td>end for</td></tr><tr><td>for i = k + 1 to n do</td></tr><tr><td>j ← random integer from 1 to i</td></tr><tr><td>if j ≤ k then</td></tr><tr><td>R[j] ← xi</td></tr><tr><td>end if</td></tr><tr><td>end for</td></tr><tr><td>return R</td></tr></table>\",\n",
       "  \"<h1 id='62' style='font-size:22px'>C. Prompts for data transformation phase</h1>\",\n",
       "  \"<p id='63' data-category='paragraph' style='font-size:20px'>This section introduces the prompts defined in our data transformation phase, including the question generation prompt, the<br>question evaluation prompt, and the answer generation prompt.</p>\",\n",
       "  \"<p id='64' data-category='paragraph' style='font-size:20px'>Query-to-Questions Generator (Step 1)</p>\",\n",
       "  \"<p id='65' data-category='paragraph' style='font-size:16px'>Your task is to generate two questions based on the given text content. Ensure the questions are relevant and directly related to the<br>details provided in the text. Follow these guidelines:</p>\",\n",
       "  \"<br><p id='66' data-category='paragraph' style='font-size:18px'>1. Question Guidelines:</p>\",\n",
       "  \"<p id='67' data-category='list' style='font-size:16px'>· Make sure the questions are closely related to the main points or themes mentioned in the text.<br>· Ensure the two questions are as diverse as possible, avoiding homogeneity.<br>· Ensure the questions include all the information needed for the answers. If necessary, add introductory information to<br>the questions.<br>· The questions must be self-contained and should not require the provided text as background to be understood.</p>\",\n",
       "  \"<br><p id='68' data-category='paragraph' style='font-size:18px'>Please rewrite the following text into related questions, and output them in JSON format: Text: 0<br>Output format example:</p>\",\n",
       "  \"<br><p id='69' data-category='paragraph' style='font-size:14px'>{</p>\",\n",
       "  '<br><p id=\\'70\\' data-category=\\'paragraph\\' style=\\'font-size:14px\\'>\" questions \" [<br>:</p>',\n",
       "  \"<br><p id='71' data-category='paragraph' style='font-size:16px'>{</p>\",\n",
       "  '<br><p id=\\'72\\' data-category=\\'paragraph\\' style=\\'font-size:14px\\'>\" question \" : \" Generated question content 1 \"</p>',\n",
       "  \"<br><p id='73' data-category='paragraph' style='font-size:14px'>} ,</p>\",\n",
       "  \"<br><p id='74' data-category='paragraph' style='font-size:16px'>{</p>\",\n",
       "  '<br><p id=\\'75\\' data-category=\\'paragraph\\' style=\\'font-size:14px\\'>\" question \" : \"Generated question content 2\"</p>',\n",
       "  \"<br><p id='76' data-category='paragraph' style='font-size:14px'>}</p>\",\n",
       "  \"<br><p id='77' data-category='paragraph' style='font-size:16px'>]</p>\",\n",
       "  \"<br><p id='78' data-category='paragraph' style='font-size:14px'>}</p>\",\n",
       "  \"<footer id='79' style='font-size:20px'>17</footer>\",\n",
       "  \"<header id='80' style='font-size:20px'>MAP</header>\",\n",
       "  \"<h1 id='81' style='font-size:22px'>Query Evaluation Scorer (Step 2)</h1>\",\n",
       "  \"<p id='82' data-category='paragraph' style='font-size:16px'>Your task is to evaluate the given query based on the following criteria and output the results in JSON format. The output should<br>include three parts: quality, difficulty, and whether additional necessary information is required to answer the query. Please follow<br>the scoring standards below:</p>\",\n",
       "  \"<p id='83' data-category='paragraph' style='font-size:16px'>1. Quality (Score 1-10): Assess the clarity and accuracy of the query. If the query is a simple statement without any question<br>or instruction, score it 1-2.</p>\",\n",
       "  \"<p id='84' data-category='list' style='font-size:16px'>· 9-10: Very clear, accurate expression, no ambiguity.<br>· 7-8: Clear, accurate expression, but may have minimal ambiguity.<br>· 5-6: Fairly clear, generally accurate expression, but some ambiguity exists.<br>· 3-4: Not very clear, somewhat vague expression, with obvious ambiguity.<br>· 1-2: Unclear, very vague expression, difficult to understand or a simple statement.</p>\",\n",
       "  \"<p id='85' data-category='paragraph' style='font-size:20px'>2. Difficulty (Score 1-10): Assess the difficulty of understanding and answering the query.</p>\",\n",
       "  \"<p id='86' data-category='list' style='font-size:18px'>· 9-10: Very difficult, requires specialized knowledge and complex analysis to answer.<br>· 7-8: Quite difficult, requires some specialized knowledge and analysis.<br>· 5-6: Moderate difficulty, requires general knowledge and analysis.<br>· 3-4: Fairly simple, can be answered with basic knowledge.<br>· 1-2: Very simple, no special knowledge required to answer.</p>\",\n",
       "  \"<p id='87' data-category='paragraph' style='font-size:16px'>3. Whether additional necessary information is required to answer: Determine if extra information is needed to fully answer<br>the query.</p>\",\n",
       "  \"<p id='88' data-category='paragraph' style='font-size:20px'>Please strictly follow the format below for output: Quality: 1-10<br>Difficulty: 1-10<br>Additional Information Needed: True/False<br>Please evaluate the following query: Query: 0<br>Output format example:</p>\",\n",
       "  \"<br><p id='89' data-category='paragraph' style='font-size:16px'>{</p>\",\n",
       "  '<br><p id=\\'90\\' data-category=\\'paragraph\\' style=\\'font-size:14px\\'>\" quality\" : 8 ,<br>\" difficulty \" : 5,<br>\" additional_info_needed \" : true</p>',\n",
       "  \"<br><p id='91' data-category='paragraph' style='font-size:14px'>}</p>\",\n",
       "  \"<h1 id='92' style='font-size:22px'>Question-to-Answer Generator (Step 3)</h1>\",\n",
       "  \"<p id='93' data-category='paragraph' style='font-size:16px'>Your task is to generate an answer based on the given question. Use the background information provided in the text to assist in<br>formulating a relevant and detailed answer. Follow these guidelines:</p>\",\n",
       "  \"<p id='94' data-category='paragraph' style='font-size:16px'>1. Question Guidelines:</p>\",\n",
       "  '<p id=\\'95\\' data-category=\\'list\\' style=\\'font-size:16px\\'>· Ensure the answer is closely related to the main points or themes mentioned in the question.<br>· Utilize the text content to provide a comprehensive and accurate answer.<br>· Ensure proper formatting and readability, including the correct rendering of any LaTeX or mathematical symbols.<br>· Ensure that the answer provides a complete solution or explanation, with clear and detailed steps.<br>· Use JSON format with the key \" answer\" for easy extraction and processing.</p>',\n",
       "  \"<p id='96' data-category='paragraph' style='font-size:20px'>Text:<br>0<br>Question:<br>{}<br>Output format example:</p>\",\n",
       "  \"<p id='97' data-category='paragraph' style='font-size:14px'>{</p>\",\n",
       "  '<br><p id=\\'98\\' data-category=\\'paragraph\\' style=\\'font-size:14px\\'>\" answer \" : \" Generated answer content \"</p>',\n",
       "  \"<br><p id='99' data-category='paragraph' style='font-size:14px'>}</p>\",\n",
       "  \"<footer id='100' style='font-size:20px'>18</footer>\",\n",
       "  \"<header id='101' style='font-size:14px'>MAP</header>\",\n",
       "  \"<h1 id='102' style='font-size:20px'>D. Training parameters</h1>\",\n",
       "  \"<p id='103' data-category='paragraph' style='font-size:14px'>Table 4 presents the hyperparameters used to train the model in the AITP method, which is consistent with those used in the<br>original model's SFT version.</p>\",\n",
       "  \"<p id='104' data-category='paragraph' style='font-size:16px'>Table 4: Hyperparameters in AITP.</p>\",\n",
       "  \"<table id='105' style='font-size:14px'><tr><td>Base Model</td><td>Learning Rate</td><td>Weight Decay</td><td>Warmup Ratio</td><td>Batchsize</td><td>Epoch</td><td>Maximum Sequence Length</td></tr><tr><td>OLMo 7B-0724-hf</td><td>2e-6</td><td>0</td><td>0.03</td><td>256</td><td>3</td><td>4096</td></tr><tr><td>Pythia 12b</td><td>2e-6</td><td>0</td><td>0.03</td><td>256</td><td>3</td><td>4096</td></tr><tr><td>Neo 7b</td><td>5e-6</td><td>0</td><td>0.05</td><td>512</td><td>2</td><td>4096</td></tr></table>\",\n",
       "  \"<h1 id='106' style='font-size:18px'>E. Performances across different ratios</h1>\",\n",
       "  \"<p id='107' data-category='paragraph' style='font-size:16px'>Table 5: The results across various ratios. P-S, I-S, P-L, and I-L denote prompt-level strict accuracy, instance-level strict<br>accuracy, prompt-level loose accuracy, and instance-level loose accuracy, respectively.</p>\",\n",
       "  '<table id=\\'108\\' style=\\'font-size:14px\\'><tr><td rowspan=\"3\">Experiment Setting</td><td colspan=\"4\">Chat Benchmark</td><td colspan=\"7\">Standard Benchmark</td><td rowspan=\"3\">Average</td></tr><tr><td colspan=\"4\">IFEval</td><td colspan=\"3\">Exam</td><td colspan=\"2\">Coding</td><td colspan=\"2\">Reasoning</td></tr><tr><td>P-S</td><td>I-S</td><td>P-L</td><td>I-L</td><td>MMLU</td><td>ARC-c</td><td>GPQA-d</td><td>Human Eval</td><td>MBPP</td><td>hellaswag</td><td>gsm8k</td></tr><tr><td>OLMo-SFT</td><td>35.30</td><td>46.52</td><td>38.63</td><td>50.24</td><td>52.93</td><td>63.73</td><td>17.68</td><td>26.83</td><td>43.92</td><td>60.35</td><td>26.84</td><td>42.09</td></tr><tr><td>0.01</td><td>36.60</td><td>49.40</td><td>37.89</td><td>51.56</td><td>55.59</td><td>71.19</td><td>26.26</td><td>32.93</td><td>46.30</td><td>66.40</td><td>29.57</td><td>45.79</td></tr><tr><td>0.02</td><td>37.15</td><td>49.76</td><td>39.37</td><td>52.64</td><td>55.29</td><td>73.90</td><td>24.75</td><td>29.88</td><td>48.68</td><td>65.82</td><td>29.57</td><td>46.07</td></tr><tr><td>0.05</td><td>38.63</td><td>48.92</td><td>40.30</td><td>51.44</td><td>55.71</td><td>76.61</td><td>24.75</td><td>28.05</td><td>44.18</td><td>64.97</td><td>30.86</td><td>45.86</td></tr><tr><td>0.07</td><td>38.45</td><td>50.48</td><td>39.93</td><td>52.52</td><td>54.88</td><td>71.53</td><td>18.69</td><td>26.83</td><td>45.24</td><td>64.69</td><td>31.92</td><td>45.01</td></tr><tr><td>0.1</td><td>37.15</td><td>48.92</td><td>40.30</td><td>52.04</td><td>55.38</td><td>71.86</td><td>29.29</td><td>26.83</td><td>48.15</td><td>64.62</td><td>29.27</td><td>45.80</td></tr><tr><td>0.2</td><td>36.23</td><td>48.44</td><td>38.26</td><td>50.24</td><td>55.29</td><td>70.85</td><td>26.26</td><td>28.05</td><td>48.15</td><td>58.61</td><td>30.55</td><td>44.63</td></tr><tr><td>0.3</td><td>35.49</td><td>48.08</td><td>37.52</td><td>50.00</td><td>56.04</td><td>70.51</td><td>30.30</td><td>28.05</td><td>44.97</td><td>62.97</td><td>31.46</td><td>45.04</td></tr><tr><td>0.4</td><td>36.23</td><td>48.44</td><td>39.37</td><td>50.84</td><td>55.91</td><td>73.56</td><td>29.29</td><td>31.71</td><td>42.06</td><td>63.93</td><td>30.63</td><td>45.63</td></tr><tr><td>0.5</td><td>35.86</td><td>47.00</td><td>38.45</td><td>49.64</td><td>55.91</td><td>72.54</td><td>26.26</td><td>29.88</td><td>46.83</td><td>62.58</td><td>29.87</td><td>44.98</td></tr><tr><td>0.6</td><td>35.30</td><td>46.88</td><td>37.34</td><td>48.92</td><td>55.78</td><td>72.54</td><td>27.27</td><td>29.27</td><td>46.30</td><td>62.50</td><td>31.31</td><td>44.86</td></tr><tr><td>0.7</td><td>34.20</td><td>46.76</td><td>35.86</td><td>48.56</td><td>55.49</td><td>74.24</td><td>27.27</td><td>30.49</td><td>35.00</td><td>63.77</td><td>30.55</td><td>43.84</td></tr></table>',\n",
       "  \"<h1 id='109' style='font-size:22px'>F. Examples</h1>\",\n",
       "  \"<p id='110' data-category='paragraph' style='font-size:16px'>Examples 1, 2, and 3 represent three dense regions in the pretraining corpus, corresponding to code, scientific literature, and<br>general text data, respectively. Example 4 represents the dense region of the SFT dataset. Examples 5, 6, and 7 correspond<br>to the three dense regions in the rewritten set. Example 8 indicates points where the SFT data density is higher than that of<br>the pretraining data. Examples 9 and 10 represent points where the pretraining data density exceeds that of the SFT data.<br>Example 10 is as shown in Example 2.</p>\",\n",
       "  \"<footer id='111' style='font-size:14px'>19</footer>\",\n",
       "  \"<header id='112' style='font-size:18px'>MAP</header>\",\n",
       "  '<figure id=\\'113\\'><img style=\\'font-size:14px\\' alt=\"Example 1 in the original pretraining corpus (density estimation)\\n\\'text \\' : \\'python\\n# 응load /Users/facai/Study /book_notes/preconfig.py\\n응matplotlib inline\\nimport matplotlib.pyplot as plt\\nimport seaborn as sns\\nsns · set (color_codes=True)\\n#sns . set (font=\\' SimHei , )\\nplt · rcParams [\\' axes.grid\\' ] = False\\n#from IPython.display import SVG\\ndef show_image (filename, figsize=None, res_dir=True) :\\nif figsize:\\nplt. figure (figsize=figsize)\\nif res_dir:\\nfilename = /res/ { } , format (filename)\\n,\\n·\\n·\\nplt · imshow (plt. imread (filename) )\\nChapter 7 Regularization for Deep Learning\\n==\\nthe best fitting model is a large model that has been regularized appropriately.\\n### 7.1 Parameter Norm Penalties\\n\\\\begin{equation}\\n\\\\tilde{J} (\\\\theta; X, y) = J(\\\\theta; X, y) + \\\\alpha \\\\Omega (\\\\theta)\\n\\\\end{equation}\\nwhere $\\\\Omega ( \\\\theta) $ is a paramter norm penalty.\\ntypically, penalizes **only the weights** of the affine transformation at each layer\\nand leaves the biases unregularized.\\n#### 7.1.1 $L^2$ Parameter Regularization\\n#### 7 .1.2 $L^1$ Regularization\\nThe sparsity property induced by $L^1$ regularization => feature selection\\n### 7.2 Norm Penalties as Constrained Optimization\\nconstrain $\\\\Omega (\\\\theta) $ to be less than some constant $k$:\\n\\\\begin{equation}\\n\\\\mathcal{L} (\\\\theta, \\\\alpha; X, y) = J (\\\\theta; X, y) + \\\\alpha (  Omega ( \\\\ theta) - k)\\n\\\\end{equation}\\nIn practice, column norm limitation is always implemented as an explicit constraint\\nwith reprojection.\\n### 7.3 Regularization and Under-Constrained Problems\\nregularized matrix is guarantedd to be invertible. \\'\" data-coord=\"top-left:(124,149); bottom-right:(1130,1409)\" /></figure>',\n",
       "  \"<footer id='114' style='font-size:18px'>20</footer>\",\n",
       "  \"<header id='0' style='font-size:18px'>MAP</header>\",\n",
       "  '<p id=\\'1\\' data-category=\\'paragraph\\' style=\\'font-size:14px\\'>Example 2 in the original pretraining corpus (density estimation)<br>\"text \" \" \\\\section { \\\\label {intro} Introduction}<br>:<br>The high-precision determination of the machine luminosity at<br>{ \\\\sc lep/slc} is an essential ingredient of the success of<br>precision tests of the electroweak interactions on top of the $Z$<br>resonance \\\\cite {review}<br>As well known, the Bhabha scattering process at small angle (of the<br>order of a few degrees) is the reference reaction used for luminosity<br>monitoring at { \\\\sc lep/slc}, owing to its large cross section (dominated by<br>$t$-channel photon exchange) and its substantial independence of<br>purely electroweak effects · Experimental efforts in the development of<br>efficient, dedicated luminometry detectors, as well as precision<br>calculations of the small-angle Bhabha (hereafter { \\\\sc sabh}) scattering cross<br>section both contribute to achieve a measurement of the , `$Z$ factories\\' ,<br>luminosity with a total relative error at the $0 · 1 1%$ level \\\\cite{review, exp, common } ·<br>On the experimental side, the present total uncertainty is smaller than<br>$0 · 1 1%$ \\\\cite{exp} , close to the $0 · 05$ level \\\\cite{ward} · As far as the theory<br>contribution to the luminosity measurement is concerned, the<br>estimate of the theoretical errors, used by the { \\\\sc lep} collaborations,<br>is summarized in table \\\\ref {sabs} \\\\cite { common} for centre of mass<br>energies around and above the $Z$ resonance.<br>\\\\begin {table} [ht]<br>\\\\caption [sabs] { \\\\label {sabs}<br>Theoretical error in { \\\\sc sabh} scattering according<br>to ref · \\\\cite{common } at typical { \\\\sc lep1} and { \\\\sc 1ep2}<br>energies. }<br>\\\\medskip<br>\\\\begin { center}<br>\\\\begin { tabular} { 11 I |c|c| } \\\\hline<br>Type of correction/ error & {\\\\sc lep1} ($\\\\%$) & {\\\\sc 1ep2} ($\\\\%$) \\\\  \\\\hline \\\\hline<br>missing photonic $⌀ (\\\\alpha ^ 2L) $ & $0 . 100 $ & $0 . 200$ \\\\\\\\<br>missing photonic $⌀ (\\\\alpha A 3L ^ 3) $ & $0 · 015 $ & $0 · 030$ \\\\\\\\<br>vacuum polarization & $0 · 040 $ & $0 · 100$ \\\\\\\\<br>light pairs & $0 . 030 $ & $0 · 050$ 11<br>$Z$-exchange & $0 · 015 $ & $0 · 000$ \\\\\\\\ \\\\hline<br>total & $0 110 $ & $0 · 250$ 11 \\\\hline<br>\\\\end{tabular}<br>\\\\end { center}<br>\\\\end {table}<br>Some comments on table \\\\ref {sabs} are in order. The components of the theoretical<br>error refer to the { \\\\sc sabh} scattering cross section, for any typical event<br>selection of { \\\\sc lep} experiments, as computed by the program { \\\\tt<br>BHLUMI v4 , 03} \\\\cite{bhl}<br>The largely dominating source of theoretical error<br>is due to the missing part of $⌀ (\\\\alpha ^2 L) $ subleading photonic corrections,<br>where $L = \\\\1n (-t/m^2) $ is the collinear logarithm in $t$-channel scattering.<br>Also the contribution of the missing part of the leading $⌀ (\\\\alpha ^ 3L^3) $<br>corrections is of photonic nature. The vacuum polarization entry<br>is the effect of the uncertainty in the hadronic contribution<br>to the running of $\\\\alpha_ { / rm QED}$, when considering the parameterization and<br>relative error estimate of ref · \\\\cite{oldvacuum} .<br>The next contribution is the uncertainty introduced by the corrections due<br>to the production of light pairs, chiefly $e^ + e -$ ones. The last<br>entry refers to the uncertainty associated to the treatment of the<br>$\\\\gamma$-$Z$ interference.<br>More details about the strategy adopted in order to estimate the various<br>sources of theoretical error can be found in ref · \\\\cite{ common} .<br>After the analysis of ref · \\\\cite{common}, important theoretical<br>developments took place. Additional work in the sector of two-loop<br>photonic corrections \\\\cite{pv, kr} led to the conclusion that the<br>perturbative contribution due to the uncontrolled part of $⌀ ( \\\\alpha ^2L) $<br>corrections does not exceed the $0 . 03\\\\%$ level.<br>\"<br>· .</p>',\n",
       "  \"<footer id='2' style='font-size:18px'>21</footer>\",\n",
       "  \"<header id='3' style='font-size:18px'>MAP</header>\",\n",
       "  '<figure id=\\'4\\'><img style=\\'font-size:16px\\' alt=\"Example 3 in the original pretraining corpus (density estimation)\\n\\'text \\' : \\' # A marble dropped from a bridge strikes the water in 5. 0 S .\\nwhat is the height of the bridge? (Answer in meters) Jun 6, 2018 . $\\\\ \\\\text {122. 5 m} $ .\\n#### Explanation:\\nUse equation of motion: ${ \\\\ \\\\text {S\\' = \\'ut \\' + 1/2\\'at} } {2}$\\nWhere$\\\\ \\\\text {S =}$ Displacement covered$\\\\\\\\text {u =}$ Initial velocity\\n$\\\\ \\\\text {a =}$ Acceleration (Its ${ \\\\\\\\text {9 8 m/s} } {2}$ due to Earths gravity)\\n$ \\\\ \\\\text {t =}$ Time taken to cover displacement $\\\\\\\\text {S}$\\nMarble is dropped. It means initial velocity ($\\\\\\\\text {u}$) of marble is $0$\\nTherefore the equation becomes ${\\\\\\\\text {S\\' = 1/2\\'at}} {2}$\\ncolor (white) (\\'S\\') = 1/2 \\' 9 · 8 m/s\\'^2 \\' (5 s) \\' ^2\\ncolor (white) (\\'S\\') = 122 · 5\\\\ \\\\ \\'m\\'\\nDisplacement covered by the marble when thrown from the bridge is\\nobviously height of the bridge.\" data-coord=\"top-left:(124,149); bottom-right:(1125,468)\" /></figure>',\n",
       "  '<figure id=\\'5\\'><img style=\\'font-size:14px\\' alt=\"Example 4 in the original SFT dataset (density estimation)\\n\\' query\\' : \\'Tweet : enjoyed watching Glee, it brought back some good memories of being\\nin musical theatre, and snowflake\\nSent iment : positive\\nTweet : @dandebuf i\\'m pretty sure he\\' S every main character we , ve ever written.\\nthat or @iamnotmatt\\nSent iment : positive\\nTweet : Still no iPhone update\\nSent iment : negative\\nTweet : @jimblum must have been quite a ride to loose 44 lbs\\nSent iment : \\'\\n\\' answer \\' \\'positive\\'\\n:\" data-coord=\"top-left:(120,561); bottom-right:(1128,951)\" /></figure>',\n",
       "  \"<p id='6' data-category='paragraph' style='font-size:20px'>Example 5 in the rewritten dataset (density estimation)</p>\",\n",
       "  '<p id=\\'7\\' data-category=\\'paragraph\\' style=\\'font-size:16px\\'>\" query \" : \"What is the effect of L1 regularization on the model parameters, and how<br>does it contribute to feature selection within a deep learning model?\"</p>',\n",
       "  '<p id=\\'8\\' data-category=\\'paragraph\\' style=\\'font-size:14px\\'>\" answer\" : \"L1 regularization, also known as Lasso regularization, adds a penalty to<br>the model based on the absolute value of the model , S coefficients. Mathematically,<br>this can be represented as an addition to the loss function:</p>',\n",
       "  \"<p id='9' data-category='paragraph' style='font-size:14px'>\\\\ \\\\ (J(\\\\ \\\\theta; X, y) +  \\\\alpha \\\\ \\\\sum_{i} | \\\\ \\\\theta_i | \\\\ ) , where \\\\ ( \\\\ \\\\theta_i\\\\ \\\\ )<br>are the model parameters and \\\\ (\\\\\\\\alpha \\\\ I ) is the regularization strength.</p>\",\n",
       "  \"<p id='10' data-category='paragraph' style='font-size:14px'>The key effect of L1 regularization is that it encourages the model to set some of the<br>less important feature coefficients to zero. This property is particularly useful for<br>feature selection because it effectively removes irrelevant or less important features<br>from the model, leading to a more interpretable and potentially more robust model .</p>\",\n",
       "  '<p id=\\'11\\' data-category=\\'paragraph\\' style=\\'font-size:16px\\'>By pruning out these unimportant features, L1 regularization helps in simplifying the<br>model, reducing overfitting, and improving computational efficiency, especially in<br>high-dimensional datasets where many features might be redundant or irrelevant ·<br>\"</p>',\n",
       "  \"<footer id='12' style='font-size:18px'>22</footer>\",\n",
       "  \"<header id='13' style='font-size:18px'>MAP</header>\",\n",
       "  \"<p id='14' data-category='paragraph' style='font-size:20px'>Example 6 in the rewritten dataset (density estimation)</p>\",\n",
       "  '<p id=\\'15\\' data-category=\\'paragraph\\' style=\\'font-size:14px\\'>\" query\" : \"What are the constituent elements of carbon dioxide and how many atoms of<br>each are present in a single molecule?, \"</p>',\n",
       "  '<p id=\\'16\\' data-category=\\'paragraph\\' style=\\'font-size:14px\\'>\" answer\" : \"The constituent elements of carbon dioxide are carbon and oxygen.<br>In a single molecule of carbon dioxide (CO2) , there is one atom of carbon<br>and two atoms of oxygen. \"</p>',\n",
       "  \"<p id='17' data-category='paragraph' style='font-size:20px'>Example 7 in the rewritten dataset (density estimation)</p>\",\n",
       "  '<p id=\\'18\\' data-category=\\'paragraph\\' style=\\'font-size:16px\\'>\"query\" : \"How is the signless Laplacian matrix of a graph G defined, and what is the<br>relationship between the signless Laplacian spectrum of G and the spectrum of the<br>line graph of G?\"</p>',\n",
       "  '<p id=\\'19\\' data-category=\\'paragraph\\' style=\\'font-size:14px\\'>\" answer \" : \"The signless Laplacian matrix of a graph \\\\ ( G / ) is defined as<br>\\\\ ( Q_G = D_G + A_G \\\\) , where \\\\ ( D_G \\\\) is the diagonal matrix of vertex degrees<br>and \\\\ ( A_G \\\\) is the adjacency matrix of the graph.</p>',\n",
       "  \"<p id='20' data-category='paragraph' style='font-size:16px'>The signless Laplacian spectrum of \\\\ ( G V is the multiset of eigenvalues of \\\\ ( Q_G \\\\ ) ·<br>The relationship between the signless Laplacian spectrum of \\\\ ( G V and<br>the spectrum of the line graph of \\\\ ( G \\\\) , denoted \\\\ ( \\\\mathcal {L}_G \\\\),<br>is given by the following:</p>\",\n",
       "  '<p id=\\'21\\' data-category=\\'paragraph\\' style=\\'font-size:14px\\'>for an \\\\ ( (n, m) \\\\) -graph \\\\ ( G \\\\) , the eigenvalues of the signless Laplacian matrix<br>and the line graph are related as \\\\ ( q_i (G) = 2 + \\\\lambda_i ( \\\\mathcal{L}_G) \\\\ )<br>for \\\\ ( i = 1, 2, \\\\ldots, k \\\\) , where \\\\ ( k = \\\\min\\\\ {m, n\\\\} ) and<br>\\\\ ( \\\\lambda_i ( \\\\mathcal{L} _G) い is the \\\\ ( i い -th largest eigenvalue of the line graph.<br>Moreover, if \\\\ ( m > n V , then \\\\ ( \\\\lambda_i (\\\\mathcal{L}_G) = -2 \\\\) for \\\\ ( m \\\\geq i<br>\\\\geq n+1 \\\\) , and if \\\\ ( n > m / ) , then \\\\ ( q_i = 0 \\\\) for \\\\ ( n \\\\geq i \\\\geq m+1 \\\\) \"</p>',\n",
       "  \"<h1 id='22' style='font-size:22px'>Example 8 in the original SFT dataset (density estimation)</h1>\",\n",
       "  '<p id=\\'23\\' data-category=\\'paragraph\\' style=\\'font-size:16px\\'>\"query\" : \"Ques: Given this review : Great app . Fun and cool graphics.<br>Would you recommend this app to a friend? Not at all, No, Maybe, Yes, or Definitely?<br>Ans : Definitely</p>',\n",
       "  \"<p id='24' data-category='paragraph' style='font-size:14px'>Ques : Given this review: In Zenfone 2 ram 2gb intel processor not very well after<br>I upgrade to marshmallow . . i dont know why · · very very lag · · before in lollipop version<br>this psp game works really well . . i use default settings no problem. .<br>Would you recommend this app to a friend? Not at all, No, Maybe, Yes, or Definitely?<br>Ans : No</p>\",\n",
       "  \"<p id='25' data-category='paragraph' style='font-size:14px'>Ques : Given this review: Did not work at all To much errors<br>Would you recommend this app to a friend? Not at all, No, Maybe, Yes, or Definitely?<br>Ans : Not at all</p>\",\n",
       "  '<p id=\\'26\\' data-category=\\'paragraph\\' style=\\'font-size:14px\\'>Ques : Given this review: I like this app Open anyyy apps & anyone like this app<br>Would you recommend this app to a friend? Not at all, No, Maybe, Yes, or Definitely?<br>Ans : \"</p>',\n",
       "  '<p id=\\'27\\' data-category=\\'paragraph\\' style=\\'font-size:14px\\'>\" answer \" \"Definitely\"<br>:</p>',\n",
       "  \"<footer id='28' style='font-size:18px'>23</footer>\",\n",
       "  \"<header id='29' style='font-size:16px'>MAP</header>\",\n",
       "  '<figure id=\\'30\\'><img style=\\'font-size:14px\\' alt=\"Example 9 in the original pretraining corpus (density estimation)\\n\\'text \\' : \\' # If the length of a 46 cm spring increases to 57 cm when a 8 kg\\nweight is hanging from it , what is the spring\\\\ , constant ?\\nS\\n$ I \\\\ text { 713 N/m}$\\\\n$F = k  \\\\Delta x$ \\\\nk = F / (Deltax) = (mg) / (Deltax) =\\n( \\'8 kg 9 8 m/ S \\' 2) / ( \\' 0 57 m - 0 · 46 m ) = \\' 713 N/m\\' \\'\" data-coord=\"top-left:(116,134); bottom-right:(1131,307)\" /></figure>',\n",
       "  \"<footer id='31' style='font-size:20px'>24</footer>\"],\n",
       " 'uris': None,\n",
       " 'data': None,\n",
       " 'metadatas': [{'category': 'heading1',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 0,\n",
       "   'page': 1,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'table',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 1,\n",
       "   'page': 1,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 2,\n",
       "   'page': 1,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 3,\n",
       "   'page': 1,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 4,\n",
       "   'page': 1,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'header',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 5,\n",
       "   'page': 1,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'footnote',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 7,\n",
       "   'page': 1,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 8,\n",
       "   'page': 1,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'figure',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 9,\n",
       "   'page': 1,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 10,\n",
       "   'page': 1,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 11,\n",
       "   'page': 1,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 12,\n",
       "   'page': 1,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 13,\n",
       "   'page': 1,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'footer',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 14,\n",
       "   'page': 1,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'header',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 15,\n",
       "   'page': 2,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'figure',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 16,\n",
       "   'page': 2,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 17,\n",
       "   'page': 2,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 18,\n",
       "   'page': 2,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 19,\n",
       "   'page': 2,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 20,\n",
       "   'page': 2,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'heading1',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 21,\n",
       "   'page': 2,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 22,\n",
       "   'page': 2,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 23,\n",
       "   'page': 2,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'equation',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 24,\n",
       "   'page': 2,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 25,\n",
       "   'page': 2,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 26,\n",
       "   'page': 2,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 27,\n",
       "   'page': 2,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 28,\n",
       "   'page': 2,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'equation',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 29,\n",
       "   'page': 2,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 30,\n",
       "   'page': 2,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'caption',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 31,\n",
       "   'page': 2,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'equation',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 32,\n",
       "   'page': 2,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 33,\n",
       "   'page': 2,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'caption',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 34,\n",
       "   'page': 2,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 35,\n",
       "   'page': 2,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'caption',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 36,\n",
       "   'page': 2,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'equation',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 37,\n",
       "   'page': 2,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 38,\n",
       "   'page': 2,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'caption',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 39,\n",
       "   'page': 2,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'equation',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 40,\n",
       "   'page': 2,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 41,\n",
       "   'page': 2,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'footer',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 42,\n",
       "   'page': 2,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'header',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 43,\n",
       "   'page': 3,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 44,\n",
       "   'page': 3,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 45,\n",
       "   'page': 3,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'equation',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 46,\n",
       "   'page': 3,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 47,\n",
       "   'page': 3,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'equation',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 48,\n",
       "   'page': 3,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 49,\n",
       "   'page': 3,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'heading1',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 50,\n",
       "   'page': 3,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 51,\n",
       "   'page': 3,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'equation',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 52,\n",
       "   'page': 3,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'equation',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 53,\n",
       "   'page': 3,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 54,\n",
       "   'page': 3,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'equation',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 55,\n",
       "   'page': 3,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 56,\n",
       "   'page': 3,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'heading1',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 57,\n",
       "   'page': 3,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 58,\n",
       "   'page': 3,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 59,\n",
       "   'page': 3,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'caption',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 60,\n",
       "   'page': 3,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'equation',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 61,\n",
       "   'page': 3,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 62,\n",
       "   'page': 3,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 63,\n",
       "   'page': 3,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 64,\n",
       "   'page': 3,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 65,\n",
       "   'page': 3,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'caption',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 66,\n",
       "   'page': 3,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'caption',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 67,\n",
       "   'page': 3,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'caption',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 68,\n",
       "   'page': 3,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 69,\n",
       "   'page': 3,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 70,\n",
       "   'page': 3,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 71,\n",
       "   'page': 3,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'footer',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 72,\n",
       "   'page': 3,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'header',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 73,\n",
       "   'page': 4,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 74,\n",
       "   'page': 4,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 75,\n",
       "   'page': 4,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 76,\n",
       "   'page': 4,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'heading1',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 77,\n",
       "   'page': 4,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 78,\n",
       "   'page': 4,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 79,\n",
       "   'page': 4,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'equation',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 80,\n",
       "   'page': 4,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'equation',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 81,\n",
       "   'page': 4,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'caption',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 82,\n",
       "   'page': 4,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 83,\n",
       "   'page': 4,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 84,\n",
       "   'page': 4,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 85,\n",
       "   'page': 4,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 86,\n",
       "   'page': 4,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 87,\n",
       "   'page': 4,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 88,\n",
       "   'page': 4,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 89,\n",
       "   'page': 4,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'footer',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 90,\n",
       "   'page': 4,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'header',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 91,\n",
       "   'page': 5,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'figure',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 92,\n",
       "   'page': 5,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 93,\n",
       "   'page': 5,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 94,\n",
       "   'page': 5,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'figure',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 95,\n",
       "   'page': 5,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 96,\n",
       "   'page': 5,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'figure',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 97,\n",
       "   'page': 5,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'figure',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 98,\n",
       "   'page': 5,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 99,\n",
       "   'page': 5,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 100,\n",
       "   'page': 5,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 101,\n",
       "   'page': 5,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'figure',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 102,\n",
       "   'page': 5,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'caption',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 103,\n",
       "   'page': 5,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 104,\n",
       "   'page': 5,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 105,\n",
       "   'page': 5,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'heading1',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 106,\n",
       "   'page': 5,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 107,\n",
       "   'page': 5,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 108,\n",
       "   'page': 5,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 109,\n",
       "   'page': 5,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 110,\n",
       "   'page': 5,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 111,\n",
       "   'page': 5,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'footer',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 112,\n",
       "   'page': 5,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'header',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 113,\n",
       "   'page': 6,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 114,\n",
       "   'page': 6,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'table',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 115,\n",
       "   'page': 6,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 116,\n",
       "   'page': 6,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'table',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 117,\n",
       "   'page': 6,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 118,\n",
       "   'page': 6,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'table',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 119,\n",
       "   'page': 6,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'heading1',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 120,\n",
       "   'page': 6,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 121,\n",
       "   'page': 6,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 122,\n",
       "   'page': 6,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 123,\n",
       "   'page': 6,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 124,\n",
       "   'page': 6,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'footer',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 125,\n",
       "   'page': 6,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'header',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 126,\n",
       "   'page': 7,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'figure',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 127,\n",
       "   'page': 7,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'caption',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 128,\n",
       "   'page': 7,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'figure',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 129,\n",
       "   'page': 7,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'caption',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 130,\n",
       "   'page': 7,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 131,\n",
       "   'page': 7,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 132,\n",
       "   'page': 7,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'heading1',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 133,\n",
       "   'page': 7,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 134,\n",
       "   'page': 7,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 135,\n",
       "   'page': 7,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'heading1',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 136,\n",
       "   'page': 7,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 137,\n",
       "   'page': 7,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 138,\n",
       "   'page': 7,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 139,\n",
       "   'page': 7,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 140,\n",
       "   'page': 7,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'footer',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 141,\n",
       "   'page': 7,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'header',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 142,\n",
       "   'page': 8,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 143,\n",
       "   'page': 8,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'heading1',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 144,\n",
       "   'page': 8,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 145,\n",
       "   'page': 8,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'heading1',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 146,\n",
       "   'page': 8,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 147,\n",
       "   'page': 8,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 148,\n",
       "   'page': 8,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 149,\n",
       "   'page': 8,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 150,\n",
       "   'page': 8,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 151,\n",
       "   'page': 8,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 152,\n",
       "   'page': 8,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 153,\n",
       "   'page': 8,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 154,\n",
       "   'page': 8,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 155,\n",
       "   'page': 8,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'footer',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 156,\n",
       "   'page': 8,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'header',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 157,\n",
       "   'page': 9,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 158,\n",
       "   'page': 9,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 159,\n",
       "   'page': 9,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 160,\n",
       "   'page': 9,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 161,\n",
       "   'page': 9,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'list',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 162,\n",
       "   'page': 9,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 163,\n",
       "   'page': 9,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 164,\n",
       "   'page': 9,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 165,\n",
       "   'page': 9,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 166,\n",
       "   'page': 9,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 167,\n",
       "   'page': 9,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 168,\n",
       "   'page': 9,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 169,\n",
       "   'page': 9,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 170,\n",
       "   'page': 9,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 171,\n",
       "   'page': 9,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 172,\n",
       "   'page': 9,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'footer',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 173,\n",
       "   'page': 9,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'header',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 174,\n",
       "   'page': 10,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 175,\n",
       "   'page': 10,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 176,\n",
       "   'page': 10,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 177,\n",
       "   'page': 10,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 178,\n",
       "   'page': 10,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 179,\n",
       "   'page': 10,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 180,\n",
       "   'page': 10,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 181,\n",
       "   'page': 10,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 182,\n",
       "   'page': 10,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 183,\n",
       "   'page': 10,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 184,\n",
       "   'page': 10,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 185,\n",
       "   'page': 10,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 186,\n",
       "   'page': 10,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 187,\n",
       "   'page': 10,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 188,\n",
       "   'page': 10,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 189,\n",
       "   'page': 10,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 190,\n",
       "   'page': 10,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 191,\n",
       "   'page': 10,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 192,\n",
       "   'page': 10,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'footer',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 193,\n",
       "   'page': 10,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'header',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 0,\n",
       "   'page': 11,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'caption',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 1,\n",
       "   'page': 11,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 2,\n",
       "   'page': 11,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 3,\n",
       "   'page': 11,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 4,\n",
       "   'page': 11,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 5,\n",
       "   'page': 11,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 6,\n",
       "   'page': 11,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 7,\n",
       "   'page': 11,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 8,\n",
       "   'page': 11,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 9,\n",
       "   'page': 11,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 10,\n",
       "   'page': 11,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 11,\n",
       "   'page': 11,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'footer',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 12,\n",
       "   'page': 11,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'header',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 13,\n",
       "   'page': 12,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 14,\n",
       "   'page': 12,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 15,\n",
       "   'page': 12,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 16,\n",
       "   'page': 12,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 17,\n",
       "   'page': 12,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 18,\n",
       "   'page': 12,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 19,\n",
       "   'page': 12,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 20,\n",
       "   'page': 12,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 21,\n",
       "   'page': 12,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 22,\n",
       "   'page': 12,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'footer',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 23,\n",
       "   'page': 12,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'header',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 24,\n",
       "   'page': 13,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 25,\n",
       "   'page': 13,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 26,\n",
       "   'page': 13,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'footer',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 27,\n",
       "   'page': 13,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'header',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 28,\n",
       "   'page': 14,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 29,\n",
       "   'page': 14,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 30,\n",
       "   'page': 14,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'footer',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 31,\n",
       "   'page': 14,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'header',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 32,\n",
       "   'page': 15,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 33,\n",
       "   'page': 15,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 34,\n",
       "   'page': 15,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 35,\n",
       "   'page': 15,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 36,\n",
       "   'page': 15,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 37,\n",
       "   'page': 15,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 38,\n",
       "   'page': 15,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 39,\n",
       "   'page': 15,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 40,\n",
       "   'page': 15,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 41,\n",
       "   'page': 15,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 42,\n",
       "   'page': 15,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 43,\n",
       "   'page': 15,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 44,\n",
       "   'page': 15,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 45,\n",
       "   'page': 15,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 46,\n",
       "   'page': 15,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 47,\n",
       "   'page': 15,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 48,\n",
       "   'page': 15,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 49,\n",
       "   'page': 15,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 50,\n",
       "   'page': 15,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 51,\n",
       "   'page': 15,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'footer',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 52,\n",
       "   'page': 15,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'header',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 53,\n",
       "   'page': 16,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 54,\n",
       "   'page': 16,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'figure',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 55,\n",
       "   'page': 16,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'caption',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 56,\n",
       "   'page': 16,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'footer',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 57,\n",
       "   'page': 16,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'header',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 58,\n",
       "   'page': 17,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'heading1',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 59,\n",
       "   'page': 17,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 60,\n",
       "   'page': 17,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'table',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 61,\n",
       "   'page': 17,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'heading1',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 62,\n",
       "   'page': 17,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 63,\n",
       "   'page': 17,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 64,\n",
       "   'page': 17,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 65,\n",
       "   'page': 17,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 66,\n",
       "   'page': 17,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'list',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 67,\n",
       "   'page': 17,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 68,\n",
       "   'page': 17,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 69,\n",
       "   'page': 17,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 70,\n",
       "   'page': 17,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 71,\n",
       "   'page': 17,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 72,\n",
       "   'page': 17,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 73,\n",
       "   'page': 17,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 74,\n",
       "   'page': 17,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 75,\n",
       "   'page': 17,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 76,\n",
       "   'page': 17,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 77,\n",
       "   'page': 17,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 78,\n",
       "   'page': 17,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'footer',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 79,\n",
       "   'page': 17,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'header',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 80,\n",
       "   'page': 18,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'heading1',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 81,\n",
       "   'page': 18,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 82,\n",
       "   'page': 18,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 83,\n",
       "   'page': 18,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'list',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 84,\n",
       "   'page': 18,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 85,\n",
       "   'page': 18,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'list',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 86,\n",
       "   'page': 18,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 87,\n",
       "   'page': 18,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 88,\n",
       "   'page': 18,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 89,\n",
       "   'page': 18,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 90,\n",
       "   'page': 18,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 91,\n",
       "   'page': 18,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'heading1',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 92,\n",
       "   'page': 18,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 93,\n",
       "   'page': 18,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 94,\n",
       "   'page': 18,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'list',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 95,\n",
       "   'page': 18,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 96,\n",
       "   'page': 18,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 97,\n",
       "   'page': 18,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 98,\n",
       "   'page': 18,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 99,\n",
       "   'page': 18,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'footer',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 100,\n",
       "   'page': 18,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'header',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 101,\n",
       "   'page': 19,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'heading1',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 102,\n",
       "   'page': 19,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 103,\n",
       "   'page': 19,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 104,\n",
       "   'page': 19,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'table',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 105,\n",
       "   'page': 19,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'heading1',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 106,\n",
       "   'page': 19,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 107,\n",
       "   'page': 19,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'table',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 108,\n",
       "   'page': 19,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'heading1',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 109,\n",
       "   'page': 19,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 110,\n",
       "   'page': 19,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'footer',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 111,\n",
       "   'page': 19,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'header',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 112,\n",
       "   'page': 20,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'figure',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 113,\n",
       "   'page': 20,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'footer',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 114,\n",
       "   'page': 20,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'header',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 0,\n",
       "   'page': 21,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 1,\n",
       "   'page': 21,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'footer',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 2,\n",
       "   'page': 21,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'header',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 3,\n",
       "   'page': 22,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'figure',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 4,\n",
       "   'page': 22,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'figure',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 5,\n",
       "   'page': 22,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 6,\n",
       "   'page': 22,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 7,\n",
       "   'page': 22,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 8,\n",
       "   'page': 22,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 9,\n",
       "   'page': 22,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 10,\n",
       "   'page': 22,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 11,\n",
       "   'page': 22,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'footer',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 12,\n",
       "   'page': 22,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'header',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 13,\n",
       "   'page': 23,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 14,\n",
       "   'page': 23,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 15,\n",
       "   'page': 23,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 16,\n",
       "   'page': 23,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 17,\n",
       "   'page': 23,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 18,\n",
       "   'page': 23,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 19,\n",
       "   'page': 23,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 20,\n",
       "   'page': 23,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 21,\n",
       "   'page': 23,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'heading1',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 22,\n",
       "   'page': 23,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 23,\n",
       "   'page': 23,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 24,\n",
       "   'page': 23,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 25,\n",
       "   'page': 23,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 26,\n",
       "   'page': 23,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 27,\n",
       "   'page': 23,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'footer',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 28,\n",
       "   'page': 23,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'header',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 29,\n",
       "   'page': 24,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'figure',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 30,\n",
       "   'page': 24,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'footer',\n",
       "   'date': '2025-01-23T10:52:18.347465',\n",
       "   'id': 31,\n",
       "   'page': 24,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'heading1',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 0,\n",
       "   'page': 1,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'table',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 1,\n",
       "   'page': 1,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 2,\n",
       "   'page': 1,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 3,\n",
       "   'page': 1,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 4,\n",
       "   'page': 1,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'header',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 5,\n",
       "   'page': 1,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'footnote',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 7,\n",
       "   'page': 1,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 8,\n",
       "   'page': 1,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'figure',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 9,\n",
       "   'page': 1,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 10,\n",
       "   'page': 1,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 11,\n",
       "   'page': 1,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 12,\n",
       "   'page': 1,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 13,\n",
       "   'page': 1,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'footer',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 14,\n",
       "   'page': 1,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'header',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 15,\n",
       "   'page': 2,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'figure',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 16,\n",
       "   'page': 2,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 17,\n",
       "   'page': 2,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 18,\n",
       "   'page': 2,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 19,\n",
       "   'page': 2,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 20,\n",
       "   'page': 2,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'heading1',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 21,\n",
       "   'page': 2,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 22,\n",
       "   'page': 2,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 23,\n",
       "   'page': 2,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'equation',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 24,\n",
       "   'page': 2,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 25,\n",
       "   'page': 2,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 26,\n",
       "   'page': 2,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 27,\n",
       "   'page': 2,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 28,\n",
       "   'page': 2,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'equation',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 29,\n",
       "   'page': 2,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 30,\n",
       "   'page': 2,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'caption',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 31,\n",
       "   'page': 2,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'equation',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 32,\n",
       "   'page': 2,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 33,\n",
       "   'page': 2,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'caption',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 34,\n",
       "   'page': 2,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 35,\n",
       "   'page': 2,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'caption',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 36,\n",
       "   'page': 2,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'equation',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 37,\n",
       "   'page': 2,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 38,\n",
       "   'page': 2,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'caption',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 39,\n",
       "   'page': 2,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'equation',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 40,\n",
       "   'page': 2,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 41,\n",
       "   'page': 2,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'footer',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 42,\n",
       "   'page': 2,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'header',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 43,\n",
       "   'page': 3,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 44,\n",
       "   'page': 3,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 45,\n",
       "   'page': 3,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'equation',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 46,\n",
       "   'page': 3,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 47,\n",
       "   'page': 3,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'equation',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 48,\n",
       "   'page': 3,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 49,\n",
       "   'page': 3,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'heading1',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 50,\n",
       "   'page': 3,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 51,\n",
       "   'page': 3,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'equation',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 52,\n",
       "   'page': 3,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'equation',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 53,\n",
       "   'page': 3,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 54,\n",
       "   'page': 3,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'equation',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 55,\n",
       "   'page': 3,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 56,\n",
       "   'page': 3,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'heading1',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 57,\n",
       "   'page': 3,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 58,\n",
       "   'page': 3,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 59,\n",
       "   'page': 3,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'caption',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 60,\n",
       "   'page': 3,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'equation',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 61,\n",
       "   'page': 3,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 62,\n",
       "   'page': 3,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 63,\n",
       "   'page': 3,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 64,\n",
       "   'page': 3,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 65,\n",
       "   'page': 3,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'caption',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 66,\n",
       "   'page': 3,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'caption',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 67,\n",
       "   'page': 3,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'caption',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 68,\n",
       "   'page': 3,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 69,\n",
       "   'page': 3,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 70,\n",
       "   'page': 3,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 71,\n",
       "   'page': 3,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'footer',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 72,\n",
       "   'page': 3,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'header',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 73,\n",
       "   'page': 4,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 74,\n",
       "   'page': 4,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 75,\n",
       "   'page': 4,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 76,\n",
       "   'page': 4,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'heading1',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 77,\n",
       "   'page': 4,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 78,\n",
       "   'page': 4,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 79,\n",
       "   'page': 4,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'equation',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 80,\n",
       "   'page': 4,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'equation',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 81,\n",
       "   'page': 4,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'caption',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 82,\n",
       "   'page': 4,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 83,\n",
       "   'page': 4,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 84,\n",
       "   'page': 4,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 85,\n",
       "   'page': 4,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 86,\n",
       "   'page': 4,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 87,\n",
       "   'page': 4,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 88,\n",
       "   'page': 4,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 89,\n",
       "   'page': 4,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'footer',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 90,\n",
       "   'page': 4,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'header',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 91,\n",
       "   'page': 5,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'figure',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 92,\n",
       "   'page': 5,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 93,\n",
       "   'page': 5,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 94,\n",
       "   'page': 5,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'figure',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 95,\n",
       "   'page': 5,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 96,\n",
       "   'page': 5,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'figure',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 97,\n",
       "   'page': 5,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'figure',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 98,\n",
       "   'page': 5,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 99,\n",
       "   'page': 5,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 100,\n",
       "   'page': 5,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 101,\n",
       "   'page': 5,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'figure',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 102,\n",
       "   'page': 5,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'caption',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 103,\n",
       "   'page': 5,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 104,\n",
       "   'page': 5,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 105,\n",
       "   'page': 5,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'heading1',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 106,\n",
       "   'page': 5,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 107,\n",
       "   'page': 5,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 108,\n",
       "   'page': 5,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 109,\n",
       "   'page': 5,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 110,\n",
       "   'page': 5,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 111,\n",
       "   'page': 5,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'footer',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 112,\n",
       "   'page': 5,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'header',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 113,\n",
       "   'page': 6,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 114,\n",
       "   'page': 6,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'table',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 115,\n",
       "   'page': 6,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 116,\n",
       "   'page': 6,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'table',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 117,\n",
       "   'page': 6,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 118,\n",
       "   'page': 6,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'table',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 119,\n",
       "   'page': 6,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'heading1',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 120,\n",
       "   'page': 6,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 121,\n",
       "   'page': 6,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 122,\n",
       "   'page': 6,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 123,\n",
       "   'page': 6,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 124,\n",
       "   'page': 6,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'footer',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 125,\n",
       "   'page': 6,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'header',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 126,\n",
       "   'page': 7,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'figure',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 127,\n",
       "   'page': 7,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'caption',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 128,\n",
       "   'page': 7,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'figure',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 129,\n",
       "   'page': 7,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'caption',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 130,\n",
       "   'page': 7,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 131,\n",
       "   'page': 7,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 132,\n",
       "   'page': 7,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'heading1',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 133,\n",
       "   'page': 7,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 134,\n",
       "   'page': 7,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 135,\n",
       "   'page': 7,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'heading1',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 136,\n",
       "   'page': 7,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 137,\n",
       "   'page': 7,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 138,\n",
       "   'page': 7,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 139,\n",
       "   'page': 7,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 140,\n",
       "   'page': 7,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'footer',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 141,\n",
       "   'page': 7,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'header',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 142,\n",
       "   'page': 8,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 143,\n",
       "   'page': 8,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'heading1',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 144,\n",
       "   'page': 8,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 145,\n",
       "   'page': 8,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'heading1',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 146,\n",
       "   'page': 8,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 147,\n",
       "   'page': 8,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 148,\n",
       "   'page': 8,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 149,\n",
       "   'page': 8,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 150,\n",
       "   'page': 8,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 151,\n",
       "   'page': 8,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 152,\n",
       "   'page': 8,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 153,\n",
       "   'page': 8,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 154,\n",
       "   'page': 8,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 155,\n",
       "   'page': 8,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'footer',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 156,\n",
       "   'page': 8,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'header',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 157,\n",
       "   'page': 9,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 158,\n",
       "   'page': 9,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 159,\n",
       "   'page': 9,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 160,\n",
       "   'page': 9,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 161,\n",
       "   'page': 9,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'list',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 162,\n",
       "   'page': 9,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 163,\n",
       "   'page': 9,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 164,\n",
       "   'page': 9,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 165,\n",
       "   'page': 9,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 166,\n",
       "   'page': 9,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 167,\n",
       "   'page': 9,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 168,\n",
       "   'page': 9,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 169,\n",
       "   'page': 9,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 170,\n",
       "   'page': 9,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 171,\n",
       "   'page': 9,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 172,\n",
       "   'page': 9,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'footer',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 173,\n",
       "   'page': 9,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'header',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 174,\n",
       "   'page': 10,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 175,\n",
       "   'page': 10,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 176,\n",
       "   'page': 10,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 177,\n",
       "   'page': 10,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 178,\n",
       "   'page': 10,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 179,\n",
       "   'page': 10,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 180,\n",
       "   'page': 10,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 181,\n",
       "   'page': 10,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 182,\n",
       "   'page': 10,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 183,\n",
       "   'page': 10,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 184,\n",
       "   'page': 10,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 185,\n",
       "   'page': 10,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 186,\n",
       "   'page': 10,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 187,\n",
       "   'page': 10,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 188,\n",
       "   'page': 10,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 189,\n",
       "   'page': 10,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 190,\n",
       "   'page': 10,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 191,\n",
       "   'page': 10,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 192,\n",
       "   'page': 10,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'footer',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 193,\n",
       "   'page': 10,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'header',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 0,\n",
       "   'page': 11,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'caption',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 1,\n",
       "   'page': 11,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 2,\n",
       "   'page': 11,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 3,\n",
       "   'page': 11,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 4,\n",
       "   'page': 11,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 5,\n",
       "   'page': 11,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 6,\n",
       "   'page': 11,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 7,\n",
       "   'page': 11,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 8,\n",
       "   'page': 11,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 9,\n",
       "   'page': 11,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 10,\n",
       "   'page': 11,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 11,\n",
       "   'page': 11,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'footer',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 12,\n",
       "   'page': 11,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'header',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 13,\n",
       "   'page': 12,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 14,\n",
       "   'page': 12,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 15,\n",
       "   'page': 12,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 16,\n",
       "   'page': 12,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 17,\n",
       "   'page': 12,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 18,\n",
       "   'page': 12,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 19,\n",
       "   'page': 12,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 20,\n",
       "   'page': 12,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 21,\n",
       "   'page': 12,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 22,\n",
       "   'page': 12,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'footer',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 23,\n",
       "   'page': 12,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'header',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 24,\n",
       "   'page': 13,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 25,\n",
       "   'page': 13,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 26,\n",
       "   'page': 13,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'footer',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 27,\n",
       "   'page': 13,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'header',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 28,\n",
       "   'page': 14,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 29,\n",
       "   'page': 14,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 30,\n",
       "   'page': 14,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'footer',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 31,\n",
       "   'page': 14,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'header',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 32,\n",
       "   'page': 15,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 33,\n",
       "   'page': 15,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 34,\n",
       "   'page': 15,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 35,\n",
       "   'page': 15,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 36,\n",
       "   'page': 15,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 37,\n",
       "   'page': 15,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 38,\n",
       "   'page': 15,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 39,\n",
       "   'page': 15,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 40,\n",
       "   'page': 15,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 41,\n",
       "   'page': 15,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 42,\n",
       "   'page': 15,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 43,\n",
       "   'page': 15,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 44,\n",
       "   'page': 15,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 45,\n",
       "   'page': 15,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 46,\n",
       "   'page': 15,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 47,\n",
       "   'page': 15,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 48,\n",
       "   'page': 15,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 49,\n",
       "   'page': 15,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 50,\n",
       "   'page': 15,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 51,\n",
       "   'page': 15,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'footer',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 52,\n",
       "   'page': 15,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'header',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 53,\n",
       "   'page': 16,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 54,\n",
       "   'page': 16,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'figure',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 55,\n",
       "   'page': 16,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'caption',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 56,\n",
       "   'page': 16,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'footer',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 57,\n",
       "   'page': 16,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'header',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 58,\n",
       "   'page': 17,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'heading1',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 59,\n",
       "   'page': 17,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 60,\n",
       "   'page': 17,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'table',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 61,\n",
       "   'page': 17,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'heading1',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 62,\n",
       "   'page': 17,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 63,\n",
       "   'page': 17,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 64,\n",
       "   'page': 17,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 65,\n",
       "   'page': 17,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 66,\n",
       "   'page': 17,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'list',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 67,\n",
       "   'page': 17,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 68,\n",
       "   'page': 17,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 69,\n",
       "   'page': 17,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 70,\n",
       "   'page': 17,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 71,\n",
       "   'page': 17,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 72,\n",
       "   'page': 17,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 73,\n",
       "   'page': 17,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 74,\n",
       "   'page': 17,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 75,\n",
       "   'page': 17,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 76,\n",
       "   'page': 17,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 77,\n",
       "   'page': 17,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 78,\n",
       "   'page': 17,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'footer',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 79,\n",
       "   'page': 17,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'header',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 80,\n",
       "   'page': 18,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'heading1',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 81,\n",
       "   'page': 18,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 82,\n",
       "   'page': 18,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 83,\n",
       "   'page': 18,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'list',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 84,\n",
       "   'page': 18,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 85,\n",
       "   'page': 18,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'list',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 86,\n",
       "   'page': 18,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 87,\n",
       "   'page': 18,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 88,\n",
       "   'page': 18,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 89,\n",
       "   'page': 18,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 90,\n",
       "   'page': 18,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 91,\n",
       "   'page': 18,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'heading1',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 92,\n",
       "   'page': 18,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 93,\n",
       "   'page': 18,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 94,\n",
       "   'page': 18,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'list',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 95,\n",
       "   'page': 18,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 96,\n",
       "   'page': 18,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 97,\n",
       "   'page': 18,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 98,\n",
       "   'page': 18,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 99,\n",
       "   'page': 18,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'footer',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 100,\n",
       "   'page': 18,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'header',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 101,\n",
       "   'page': 19,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'heading1',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 102,\n",
       "   'page': 19,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 103,\n",
       "   'page': 19,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 104,\n",
       "   'page': 19,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'table',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 105,\n",
       "   'page': 19,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'heading1',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 106,\n",
       "   'page': 19,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 107,\n",
       "   'page': 19,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'table',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 108,\n",
       "   'page': 19,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'heading1',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 109,\n",
       "   'page': 19,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 110,\n",
       "   'page': 19,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'footer',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 111,\n",
       "   'page': 19,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'header',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 112,\n",
       "   'page': 20,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'figure',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 113,\n",
       "   'page': 20,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'footer',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 114,\n",
       "   'page': 20,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'header',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 0,\n",
       "   'page': 21,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 1,\n",
       "   'page': 21,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'footer',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 2,\n",
       "   'page': 21,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'header',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 3,\n",
       "   'page': 22,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'figure',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 4,\n",
       "   'page': 22,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'figure',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 5,\n",
       "   'page': 22,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 6,\n",
       "   'page': 22,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 7,\n",
       "   'page': 22,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 8,\n",
       "   'page': 22,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 9,\n",
       "   'page': 22,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 10,\n",
       "   'page': 22,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 11,\n",
       "   'page': 22,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'footer',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 12,\n",
       "   'page': 22,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'header',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 13,\n",
       "   'page': 23,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 14,\n",
       "   'page': 23,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 15,\n",
       "   'page': 23,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 16,\n",
       "   'page': 23,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 17,\n",
       "   'page': 23,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 18,\n",
       "   'page': 23,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 19,\n",
       "   'page': 23,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 20,\n",
       "   'page': 23,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 21,\n",
       "   'page': 23,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'heading1',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 22,\n",
       "   'page': 23,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 23,\n",
       "   'page': 23,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 24,\n",
       "   'page': 23,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 25,\n",
       "   'page': 23,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 26,\n",
       "   'page': 23,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'paragraph',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 27,\n",
       "   'page': 23,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'footer',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 28,\n",
       "   'page': 23,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'header',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 29,\n",
       "   'page': 24,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'figure',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 30,\n",
       "   'page': 24,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'},\n",
       "  {'category': 'footer',\n",
       "   'date': '2025-01-23T10:53:10.481056',\n",
       "   'id': 31,\n",
       "   'page': 24,\n",
       "   'source': 'data/Aligning Instruction Tuning with Pre-training.pdf'}],\n",
       " 'included': [<IncludeEnum.documents: 'documents'>,\n",
       "  <IncludeEnum.metadatas: 'metadatas'>]}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "select_data(db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bitcomputer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
